{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Aging Process.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1tL-SGx8x8V1fJx_Uv_DmAsJU096a0QIN",
      "authorship_tag": "ABX9TyPc2lVZq3d72re26bN2Zqca",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thq4n/Aging-Process/blob/main/Aging_Process.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roGwXapftsO9"
      },
      "source": [
        ""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0K4o8kJo9m7",
        "outputId": "62b035b8-0028-4c59-d69c-3055e7d79e20"
      },
      "source": [
        "!mkdir data\n",
        "!cd data\n",
        "\n",
        "!wget https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/wiki_crop.tar"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-07 16:15:13--  https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/wiki_crop.tar\n",
            "Resolving data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)... 129.132.52.178, 2001:67c:10ec:36c2::178\n",
            "Connecting to data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)|129.132.52.178|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 811315200 (774M) [application/x-tar]\n",
            "Saving to: ‘wiki_crop.tar’\n",
            "\n",
            "wiki_crop.tar       100%[===================>] 773.73M  31.0MB/s    in 26s     \n",
            "\n",
            "2021-05-07 16:15:39 (30.0 MB/s) - ‘wiki_crop.tar’ saved [811315200/811315200]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65huIKKlpBtv"
      },
      "source": [
        "!cd data\n",
        "\n",
        "!tar -xvf wiki_crop.tar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXZWcmW9pD5K"
      },
      "source": [
        "from scipy.io import loadmat\n",
        "\n",
        "def load_data(wiki_dir, dataset = 'wiki'):\n",
        "  ## Load the wiki.mat file\n",
        "  meta = loadmat(os.path.join(wiki_dir, \"{}.mat\".format(dataset)))\n",
        "  \n",
        "  ## Load the list of all files\n",
        "  full_path = meta[dataset][0, 0][\"full_path\"][0]\n",
        "  \n",
        "  ## List of Matlab serial date numbers\n",
        "  dob = meta[dataset][0, 0][\"dob\"][0]\n",
        "  \n",
        "  ## List of years when photo was taken\n",
        "  photo_taken = meta[dataset][0, 0][\"photo_taken\"][0]  # year\n",
        "  \n",
        "  ## Calculate age for all dobs\n",
        "  age = [calculate_age(photo_taken[i], dob[i]) for i in range(len(dob))]\n",
        "  \n",
        "  ## Create a list of tuples containing a pair of an image path and age\n",
        "  images = []\n",
        "  age_list = []\n",
        "  for index, image_path in enumerate(full_path):\n",
        "    images.append(image_path[0])\n",
        "    age_list.append(age[index])\n",
        "  \n",
        "  ## Return a list of all images and respective age\n",
        "  return images, age_list"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aR1_dqlpHGs"
      },
      "source": [
        "from datetime import datetime\n",
        "\n",
        "def calculate_age(taken, dob):\n",
        "  birth = datetime.fromordinal(max(int(dob) - 366, 1))\n",
        "  \n",
        "  if birth.month < 7:\n",
        "    return taken - birth.year\n",
        "  else:\n",
        "    return taken - birth.year - 1"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AL-m7IKOpJcY"
      },
      "source": [
        "import math\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from keras import Input, Model\n",
        "from keras.applications import InceptionResNetV2\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.layers import Conv2D, Flatten, Dense, BatchNormalization\n",
        "from keras.layers import Reshape, concatenate, LeakyReLU, Lambda\n",
        "from tensorflow.keras.layers import Activation, UpSampling2D, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "from keras_preprocessing import image"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yI-lnJGWpKBL"
      },
      "source": [
        "def build_encoder():\n",
        "  \n",
        "  input_layer = Input(shape = (64, 64, 3))\n",
        "  \n",
        "  ## 1st Convolutional Block\n",
        "  enc = Conv2D(filters = 32, kernel_size = 5, strides = 2, padding = 'same')(input_layer)\n",
        "  # enc = BatchNormalization()(enc)\n",
        "  enc = LeakyReLU(alpha = 0.2)(enc)\n",
        "  \n",
        "  ## 2nd Convolutional Block\n",
        "  enc = Conv2D(filters = 64, kernel_size = 5, strides = 2, padding = 'same')(enc)\n",
        "  enc = BatchNormalization()(enc)\n",
        "  enc = LeakyReLU(alpha = 0.2)(enc)\n",
        "  \n",
        "  ## 3rd Convolutional Block\n",
        "  enc = Conv2D(filters = 128, kernel_size = 5, strides = 2, padding = 'same')(enc)\n",
        "  enc = BatchNormalization()(enc)\n",
        "  enc = LeakyReLU(alpha = 0.2)(enc)\n",
        "  \n",
        "  ## 4th Convolutional Block\n",
        "  enc = Conv2D(filters = 256, kernel_size = 5, strides = 2, padding = 'same')(enc)\n",
        "  enc = BatchNormalization()(enc)\n",
        "  enc = LeakyReLU(alpha = 0.2)(enc)\n",
        "  \n",
        "  ## Flatten layer\n",
        "  enc = Flatten()(enc)\n",
        "  \n",
        "  ## 1st Fully Connected Layer\n",
        "  enc = Dense(4096)(enc)\n",
        "  enc = BatchNormalization()(enc)\n",
        "  enc = LeakyReLU(alpha = 0.2)(enc)\n",
        "  \n",
        "  ## 2nd Fully Connected Layer\n",
        "  enc = Dense(100)(enc)\n",
        "  \n",
        "  \n",
        "  ## Create a model\n",
        "  model = Model(inputs = [input_layer], outputs = [enc])\n",
        "  return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnzAtDXvpPej"
      },
      "source": [
        "def build_generator():\n",
        "  \n",
        "  latent_dims = 100\n",
        "  num_classes = 6\n",
        "  \n",
        "  input_z_noise = Input(shape = (latent_dims, ))\n",
        "  input_label = Input(shape = (num_classes, ))\n",
        "  \n",
        "  x = concatenate([input_z_noise, input_label])\n",
        "  \n",
        "  \n",
        "  x = Dense(2048, input_dim = latent_dims + num_classes)(x)\n",
        "  x = LeakyReLU(alpha = 0.2)(x)\n",
        "  x = Dropout(0.2)(x)\n",
        "  \n",
        "  x = Dense(256 * 8 * 8)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = LeakyReLU(alpha = 0.2)(x)\n",
        "  x = Dropout(0.2)(x)\n",
        "  \n",
        "  x = Reshape((8, 8, 256))(x)\n",
        "  \n",
        "  x = UpSampling2D(size = (2, 2))(x)\n",
        "  x = Conv2D(filters = 128, kernel_size = 5, padding = 'same')(x)\n",
        "  x = BatchNormalization(momentum = 0.8)(x)\n",
        "  x = LeakyReLU(alpha = 0.2)(x)\n",
        "  \n",
        "  x = UpSampling2D(size = (2, 2))(x)\n",
        "  x = Conv2D(filters = 64, kernel_size = 5, padding = 'same')(x)\n",
        "  x = BatchNormalization(momentum = 0.8)(x)\n",
        "  x = LeakyReLU(alpha = 0.2)(x)\n",
        "  \n",
        "  x = UpSampling2D(size = (2, 2))(x)\n",
        "  x = Conv2D(filters = 3, kernel_size = 5, padding = 'same')(x)\n",
        "  x = Activation('tanh')(x)\n",
        "  \n",
        "  \n",
        "  model = Model(inputs = [input_z_noise, input_label], outputs = [x])\n",
        "  return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqT9FGI-pQ6N"
      },
      "source": [
        "def expand_label_input(x):\n",
        "  x = K.expand_dims(x, axis = 1)\n",
        "  x = K.expand_dims(x, axis = 1)\n",
        "  x = K.tile(x, [1, 32, 32, 1])\n",
        "  return x"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RvGVKA1pR14"
      },
      "source": [
        "def build_discriminator():\n",
        "  \n",
        "  input_shape = (64, 64, 3)\n",
        "  label_shape = (6, )\n",
        "  image_input = Input(shape = input_shape)\n",
        "  label_input = Input(shape = label_shape)\n",
        "  \n",
        "  x = Conv2D(64, kernel_size = 3, strides = 2, padding = 'same')(image_input)\n",
        "  x = LeakyReLU(alpha = 0.2)(x)\n",
        "  \n",
        "  label_input1 = Lambda(expand_label_input)(label_input)\n",
        "  x = concatenate([x, label_input1], axis = 3)\n",
        "  \n",
        "  \n",
        "  x = Conv2D(128, kernel_size = 3, strides = 2, padding = 'same')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = LeakyReLU(alpha = 0.2)(x)\n",
        "  \n",
        "  x = Conv2D(256, kernel_size = 3, strides = 2, padding = 'same')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = LeakyReLU(alpha = 0.2)(x)\n",
        "  \n",
        "  x = Conv2D(512, kernel_size = 3, strides = 2, padding = 'same')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = LeakyReLU(alpha = 0.2)(x)\n",
        "  \n",
        "  x = Flatten()(x)\n",
        "  x = Dense(1, activation = 'sigmoid')(x)\n",
        "  \n",
        "  \n",
        "  model = Model(inputs = [image_input, label_input], outputs = [x])\n",
        "  return model"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hG4Jel5FpVF_"
      },
      "source": [
        "def build_fr_combined_network(encoder, generator, fr_model):\n",
        "  input_image = Input(shape = (64, 64, 3))\n",
        "  input_label = Input(shape = (6, ))\n",
        "  \n",
        "  latent0 = encoder(input_image)\n",
        "  \n",
        "  gen_images = generator([latent0, input_label])\n",
        "  \n",
        "  fr_model.trainable = False\n",
        "  \n",
        "  resized_images = Lambda(lambda x: K.resize_images(gen_images, height_factor = 2,\n",
        "                                                    width_factor = 2, \n",
        "                                                    data_format = 'channels_last'))(gen_images)\n",
        "  \n",
        "  embeddings = fr_model(resized_images)\n",
        "  \n",
        "  \n",
        "  model = Model(inputs = [input_image, input_label],\n",
        "                outputs = [embeddings])\n",
        "  return model"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6AhrghMpXXd"
      },
      "source": [
        "def build_fr_model(input_shape):\n",
        "  \n",
        "  resnet_model = InceptionResNetV2(include_top = False, weights = 'imagenet',\n",
        "                                   input_shape = input_shape, pooling = 'avg')\n",
        "  image_input = resnet_model.input\n",
        "  x = resnet_model.layers[-1].output\n",
        "  out = Dense(128)(x)\n",
        "  embedder_model = Model(inputs = [image_input], outputs = [out])\n",
        "  \n",
        "  input_layer = Input(shape = input_shape)\n",
        "  \n",
        "  x = embedder_model(input_layer)\n",
        "  output = Lambda(lambda x: K.l2_normalize(x, axis = -1))(x)\n",
        "  \n",
        "  \n",
        "  model = Model(inputs = [input_layer], outputs = [output])\n",
        "  return model"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xzf2aubrpY1F"
      },
      "source": [
        "def build_image_resizer():\n",
        "  \n",
        "  input_layer = Input(shape = (64, 64, 3))\n",
        "  \n",
        "  resized_images = Lambda(lambda x: K.resize_images(x, height_factor = 3,\n",
        "                                                    width_factor = 3,\n",
        "                                                    data_format = 'channels_last'))(input_layer)\n",
        "  \n",
        "  model = Model(inputs = [input_layer],\n",
        "                outputs = [resized_images])\n",
        "  return model\n",
        "  \n",
        "def age_to_category(age_list):\n",
        "  \n",
        "  age_list1 = []\n",
        "  \n",
        "  for age in age_list:\n",
        "    if 0 < age <= 18:\n",
        "      age_category = 0\n",
        "    elif 18 < age <= 29:\n",
        "      age_category = 1\n",
        "    elif 29 < age <= 39:\n",
        "      age_category = 2\n",
        "    elif 39 < age <= 49:\n",
        "      age_category = 3\n",
        "    elif 49 < age <= 59:\n",
        "      age_category = 4\n",
        "    elif age >= 60:\n",
        "      age_category = 5\n",
        "      \n",
        "    age_list1.append(age_category)\n",
        "    \n",
        "  return age_list1\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def load_images(data_dir, image_paths, image_shape):\n",
        "\n",
        "\n",
        "  images_1 = None\n",
        "  \n",
        "  for i, image_path in enumerate(image_paths):\n",
        "    print(i)\n",
        "    #print()\n",
        "    try:\n",
        "      ## Load image\n",
        "      loaded_image = image.load_img(os.path.join(data_dir, image_path),\n",
        "                                    target_size = image_shape)\n",
        "      \n",
        "      \n",
        "      ## Convert PIL image to numpy ndarray\n",
        "      loaded_image = image.img_to_array(loaded_image)\n",
        "      \n",
        "      \n",
        "      ## Add another dimension (Add batch dimension)\n",
        "      loaded_image = np.expand_dims(loaded_image, axis = 0)\n",
        "      \n",
        "      \n",
        "      ## Concatenate all images into one tensor:\n",
        "      if images_1 is None:\n",
        "        images_1 = loaded_image\n",
        "      else:\n",
        "        images_1 = np.concatenate([images_1, loaded_image], axis = 0)\n",
        "        \n",
        "    except Exception as e:\n",
        "      print(\"Error: \", i, e)\n",
        "      \n",
        "  return images_1\n",
        "\n",
        "def euclidean_distance_loss(y_true, y_pred):\n",
        "  \n",
        "  \"\"\"\n",
        "  Euclidean distance\n",
        "  https://en.wikipedia.org/wiki/Euclidean_distance\n",
        "  y_true = TF / Theano tensor\n",
        "  y_pred = TF / Theano tensor of the same shape as y_true\n",
        "  returns float\n",
        "  \"\"\"\n",
        "  \n",
        "  return K.sqrt(K.sum(K.square(y_pred - y_true), axis = -1))\n",
        "\n",
        "def write_log(callback, name, value, batch_no):\n",
        "  summary = tf.Summary()\n",
        "  summary_value = summary.value.add()\n",
        "  summary_value.simple_value = value\n",
        "  summary_value.tag = name\n",
        "  callback.writer.add_summary(summary, batch_no)\n",
        "  callback.writer.flush()\n",
        "  \n",
        "def save_rgb_img(img, path):\n",
        "  \n",
        "  \"\"\"\n",
        "  Save an RGB image\n",
        "  \"\"\"\n",
        "  \n",
        "  fig = plt.figure()\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.imshow(img)\n",
        "  ax.axis(\"off\")\n",
        "  ax.set_title(\"Image\")\n",
        "  \n",
        "  plt.savefig(path)\n",
        "  plt.close()\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNf6flAJ80Xu"
      },
      "source": [
        "loaded_images = np.load('/content/drive/MyDrive/Đại học/Năm 3 - HK2/Học Sâu/Face_Aging_Process/Data/IMDB-Wiki/loaded_images.npy')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "m9CzckWl9eGp",
        "outputId": "b4cf96e0-4af5-4627-e141-ab8f21c83163"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "  \n",
        "  ## Define hyperparameters\n",
        "#   data_dir = \"data\"\n",
        "#   wiki_dir = os.path.join(data_dir, \"wiki_crop\")\n",
        "  wiki_dir = \"wiki_crop\"\n",
        "  epochs = 500\n",
        "  batch_size = 10\n",
        "  image_shape = (64, 64, 3)\n",
        "  z_shape = 100\n",
        "  TRAIN_GAN = True\n",
        "  TRAIN_ENCODER = False\n",
        "  TRAIN_GAN_WITH_FR = False\n",
        "  fr_image_shape = (192, 192, 3)\n",
        "  \n",
        "  \n",
        "  ## Define optimizers\n",
        "  dis_optimizer = Adam(lr = 0.0002, beta_1 = 0.5, beta_2 = 0.999, epsilon = 10e-8)\n",
        "  gen_optimizer = Adam(lr = 0.0002, beta_1 = 0.5, beta_2 = 0.999, epsilon = 10e-8)\n",
        "  adversarial_optimizer = Adam(lr = 0.0002, beta_1 = 0.5, beta_2 = 0.999, epsilon = 10e-8)\n",
        "  \n",
        "  \n",
        "  \"\"\"\n",
        "  Build and compile networks\n",
        "  \"\"\"\n",
        "  \n",
        "  ## Build and compile the discriminator network\n",
        "  discriminator = build_discriminator()\n",
        "  discriminator.compile(loss = ['binary_crossentropy'],\n",
        "                        optimizer = dis_optimizer)\n",
        "  \n",
        "  \n",
        "  ## Build and compile the generator network\n",
        "  generator = build_generator()\n",
        "  generator.compile(loss = ['binary_crossentropy'],\n",
        "                    optimizer = gen_optimizer)\n",
        "  \n",
        "  \n",
        "  ## Build and compile the adversarial model\n",
        "  discriminator.trainable = False\n",
        "  input_z_noise = Input(shape = (100, ))\n",
        "  input_label = Input(shape = (6, ))\n",
        "  recons_images = generator([input_z_noise, input_label])\n",
        "  valid = discriminator([recons_images, input_label])\n",
        "  adversarial_model = Model(inputs = [input_z_noise, input_label],\n",
        "                            outputs = [valid])\n",
        "  adversarial_model.compile(loss = ['binary_crossentropy'],\n",
        "                            optimizer = gen_optimizer)\n",
        "  \n",
        "  tensorboard = TensorBoard(log_dir = \"logs/{}\".format(time.time()))\n",
        "  tensorboard.set_model(generator)\n",
        "  tensorboard.set_model(discriminator)\n",
        "\n",
        "  try:\n",
        "      generator.load_weights('/content/drive/MyDrive/Đại học/Năm 3 - HK2/Học Sâu/Face_Aging_Process/Model/generator.h5')\n",
        "      discriminator.load_weights('/content/drive/MyDrive/Đại học/Năm 3 - HK2/Học Sâu/Face_Aging_Process/Model/discriminator.h5')\n",
        "      adversarial_model.load_weights('/content/drive/MyDrive/Đại học/Năm 3 - HK2/Học Sâu/Face_Aging_Process/Model/adversarial_model.h5')\n",
        "  except Exception as e:\n",
        "      print(\"Error: \", e)\n",
        "    \n",
        "  \n",
        "  \"\"\"\n",
        "  Load the dataset\n",
        "  \"\"\"\n",
        "  \n",
        "  images, age_list = load_data(wiki_dir = wiki_dir, dataset = \"wiki\")\n",
        "  age_cat = age_to_category(age_list)\n",
        "  final_age_cat = np.reshape(np.array(age_cat), [len(age_cat), 1])\n",
        "  classes = len(set(age_cat))\n",
        "  y = to_categorical(final_age_cat, num_classes = classes)\n",
        "  \n",
        "  \n",
        "\n",
        "\n",
        "  \n",
        "  \n",
        "  \n",
        "  ## Implement label smoothing\n",
        "  real_labels = np.ones((batch_size, 1), dtype = np.float32) * 0.9\n",
        "  fake_labels = np.zeros((batch_size, 1), dtype = np.float32) * 0.1\n",
        "  \n",
        "  \n",
        "  \"\"\"\n",
        "  Train the generator and the discriminator network\n",
        "  \"\"\"\n",
        "  \n",
        "  if TRAIN_GAN:\n",
        "    for epoch in range(epochs):\n",
        "      print(\"Epoch: {}\".format(epoch))\n",
        "      \n",
        "      gen_losses = []\n",
        "      dis_losses = []\n",
        "      \n",
        "      number_of_batches = int(len(loaded_images) / batch_size)\n",
        "      print(\"Number of batches: \", number_of_batches)\n",
        "      for index in range(number_of_batches):\n",
        "        print(\"Batch: {}\".format(index + 1),\"Epoch: {}\".format(epoch))\n",
        "        \n",
        "        images_batch = loaded_images[index * batch_size:(index + 1) * batch_size]\n",
        "        images_batch = images_batch / 127.5 - 1.0\n",
        "        images_batch = images_batch.astype(np.float32)\n",
        "        \n",
        "        y_batch = y[index * batch_size: (index + 1) * batch_size]\n",
        "        z_noise = np.random.normal(0, 1, size = (batch_size, z_shape))\n",
        "        \n",
        "        \n",
        "        \"\"\"\n",
        "        Train the discriminator network\n",
        "        \"\"\"\n",
        "        \n",
        "        ## Generate fake images\n",
        "        initial_recons_images = generator.predict_on_batch([z_noise, y_batch])\n",
        "        \n",
        "        d_loss_real = discriminator.train_on_batch([images_batch, y_batch], real_labels)\n",
        "        d_loss_fake = discriminator.train_on_batch([initial_recons_images, y_batch], fake_labels)\n",
        "        \n",
        "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "        print(\"d_loss: {}\".format(d_loss))\n",
        "        \n",
        "        \n",
        "        \"\"\"\n",
        "        Train the generator network\n",
        "        \"\"\"\n",
        "        \n",
        "        z_noise2 = np.random.normal(0, 1, size = (batch_size, z_shape))\n",
        "        random_labels = np.random.randint(0, 6, batch_size).reshape(-1, 1)\n",
        "        random_labels = to_categorical(random_labels, 6)\n",
        "        \n",
        "        g_loss = adversarial_model.train_on_batch([z_noise2, random_labels], np.array([[1]]*batch_size))\n",
        "        \n",
        "        print(\"g_loss: {}\".format(g_loss))\n",
        "        \n",
        "        \n",
        "        gen_losses.append(g_loss)\n",
        "        dis_losses.append(d_loss)\n",
        "        try:\n",
        "          if (index%1000==0):\n",
        "            generator.save_weights(\"/content/drive/MyDrive/Đại học/Năm 3 - HK2/Học Sâu/Face_Aging_Process/Model/generator.h5\")\n",
        "            discriminator.save_weights(\"/content/drive/MyDrive/Đại học/Năm 3 - HK2/Học Sâu/Face_Aging_Process/Model/discriminator.h5\")\n",
        "            adversarial_model.save_weights(\"/content/drive/MyDrive/Đại học/Năm 3 - HK2/Học Sâu/Face_Aging_Process/Model/adversarial_model.h5\")\n",
        "        except Exception as e:\n",
        "          print(\"Error: \", e)\n",
        "        \n",
        "      \n",
        "      ## Write losses to Tensorboard\n",
        "      #write_log(tensorboard, 'g_loss', np.mean(gen_losses), epoch)\n",
        "      #write_log(tensorboard, 'd_loss', np.mean(dis_losses), epoch)\n",
        "      \n",
        "      \n",
        "      \"\"\"\n",
        "      Generate images after every 10th epoch\n",
        "      \"\"\"\n",
        "      \n",
        "      if epoch % 10 == 0:\n",
        "        images_batch = loaded_images[0:batch_size]\n",
        "        images_batch = images_batch / 127.5 - 1.0\n",
        "        images_batch = images_batch.astype(np.float32)\n",
        "        \n",
        "        y_batch = y[0:batch_size]\n",
        "        z_noise = np.random.normal(0, 1, size = (batch_size, z_shape))\n",
        "        \n",
        "        gen_images = generator.predict_on_batch([z_noise, y_batch])\n",
        "        \n",
        "        for i, img in enumerate(gen_images[:5]):\n",
        "          save_rgb_img(img, path = \"/content/drive/MyDrive/Đại học/Năm 3 - HK2/Học Sâu/Face_Aging_Process/Results/img_{}_{}.png\".format(epoch, i))\n",
        "          \n",
        "        \n",
        "    ## Save networks\n",
        "    try:\n",
        "      generator.save_weights(\"/content/drive/MyDrive/Đại học/Năm 3 - HK2/Học Sâu/Face_Aging_Process/Model/generator.h5\")\n",
        "      discriminator.save_weights(\"/content/drive/MyDrive/Đại học/Năm 3 - HK2/Học Sâu/Face_Aging_Process/Model/discriminator.h5\")\n",
        "    except Exception as e:\n",
        "      print(\"Error: \", e)\n",
        "      \n",
        "  \n",
        "  \"\"\"\n",
        "  Train encoder\n",
        "  \"\"\"\n",
        "  \n",
        "  if TRAIN_ENCODER:\n",
        "    \n",
        "    ## Build and compile encoder\n",
        "    encoder = build_encoder()\n",
        "    encoder.compile(loss = euclidean_distance_loss,\n",
        "                    optimizer = 'adam')\n",
        "    \n",
        "    \n",
        "    ## Load the generator network's weights\n",
        "    try:\n",
        "      generator.load_weights(\"generator.h5\")\n",
        "    except Exception as e:\n",
        "      print(\"Error: \", e)\n",
        "      \n",
        "    \n",
        "    z_i = np.random.normal(0, 1, size = (5000, z_shape))\n",
        "    \n",
        "    y = np.random.randint(low = 0, high = 6, size = (5000, ),\n",
        "                          dtype = np.int64)\n",
        "    num_classes = len(set(y))\n",
        "    y = np.reshape(np.array(y), [len(y), 1])\n",
        "    y = to_categorical(y, num_classes = num_classes)\n",
        "    \n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "      print(\"Epoch: \", epoch)\n",
        "      \n",
        "      encoder_losses = []\n",
        "      \n",
        "      number_of_batches = int(z_i.shape[0] / batch_size)\n",
        "      print(\"Number of batches: \", number_of_batches)\n",
        "      \n",
        "      for index in range(number_of_batches):\n",
        "        print(\"Batch: \", index + 1)\n",
        "        \n",
        "        z_batch = z_i[index * batch_size: (index + 1) * batch_size]\n",
        "        y_batch = y[index * batch_size: (index + 1) * batch_size]\n",
        "        \n",
        "        generated_images = generator.predict_on_batch([z_batch, y_batch])\n",
        "        \n",
        "        \n",
        "        ## Train the encoder model\n",
        "        encoder_loss = encoder.train_on_batch(generated_images, z_batch)\n",
        "        print(\"Encoder loss: \", encoder_loss)\n",
        "        \n",
        "        encoder_losses.append(encoder_loss)\n",
        "        \n",
        "        \n",
        "      ## Write the encoder loss to Tensorboard\n",
        "      # write_log(tensorboard, \"encoder_loss\", np.mean(encoder_losses), epoch)\n",
        "      \n",
        "    ## Save the encoder model\n",
        "    encoder.save_weights(\"/content/drive/MyDrive/Đại học/Năm 3 - HK2/Học Sâu/Face_Aging_Process/Model/encoder.h5\")\n",
        "    \n",
        "  \n",
        "  \"\"\"\n",
        "  Optimize the encoder and the generator network\n",
        "  \"\"\"\n",
        "  \n",
        "  if TRAIN_GAN_WITH_FR:\n",
        "    \n",
        "    ## Load the encoder network\n",
        "    encoder = build_encoder()\n",
        "    encoder.load_weights(\"/content/drive/MyDrive/Đại học/Năm 3 - HK2/Học Sâu/Face_Aging_Process/Model/encoder.h5\")\n",
        "    \n",
        "    \n",
        "    ## Load the generator network\n",
        "    generator.load_weights(\"/content/drive/MyDrive/Đại học/Năm 3 - HK2/Học Sâu/Face_Aging_Process/Model/generator.h5\")\n",
        "    \n",
        "    image_resizer = build_image_resizer()\n",
        "    image_resizer.compile(loss = ['binary_crossentropy'],\n",
        "                          optimzer = 'adam')\n",
        "    \n",
        "    \n",
        "    ## Face recognition model\n",
        "    fr_model = build_fr_model(input_shape = fr_image_shape)\n",
        "    fr_model.compile(loss = ['binary_crossentropy'],\n",
        "                     optimizer = 'adam')\n",
        "    \n",
        "    ## Make the face recognition model as non-trainable\n",
        "    fr_model.trainable = False\n",
        "    \n",
        "    \n",
        "    ## Input layers\n",
        "    input_image = Input(shape = (64, 64, 3))\n",
        "    input_label = Input(shape = (6, ))\n",
        "    \n",
        "    \n",
        "    ## Use the encoder and the generator network\n",
        "    latent0 = encoder(input_image)\n",
        "    gen_images = generator([latent0, input_label])\n",
        "    \n",
        "    \n",
        "    ## Resize images to the desired shape\n",
        "    resized_images = Lambda(lambda x: K.resize_images(gen_images, height_factor = 3,\n",
        "                                                      width_factor = 3,\n",
        "                                                      data_format = 'channels_last'))(gen_images) \n",
        "    embeddings = fr_model(resized_images)\n",
        "    \n",
        "    \n",
        "    ## Create a Keras model and specify the inputs and outputs for the network\n",
        "    fr_adversarial_model = Model(inputs = [input_image, input_label],\n",
        "                                 outputs = [embeddings])\n",
        "    \n",
        "    \n",
        "    ## Compile the model\n",
        "    fr_adversarial_model.compile(loss = euclidean_distance_loss,\n",
        "                                 optimizer = adversarial_optimizer)\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "      print(\"Epoch: \", epoch)\n",
        "      \n",
        "      reconstruction_losses = []\n",
        "      \n",
        "      number_of_batches = int(len(loaded_images) / batch_size)\n",
        "      print(\"Number of batches: \", number_of_batches)\n",
        "      for index in range(number_of_batches):\n",
        "        print(\"Batch: \", index + 1, \"Epoch: \", epoch + 1)\n",
        "        \n",
        "        images_batch = loaded_images[index * batch_size: (index + 1) * batch_size]\n",
        "        images_batch = images_batch / 127.5 - 1.0\n",
        "        images_batch = images_batch.astype(np.float32)\n",
        "        \n",
        "        y_batch = y[index * batch_size: (index + 1) * batch_size]\n",
        "        \n",
        "        images_batch_resized = image_resizer.predict_on_batch(images_batch)\n",
        "        \n",
        "        real_embeddings = fr_model.predict_on_batch(images_batch_resized)\n",
        "        \n",
        "        reconstruction_loss = fr_adversarial_model.train_on_batch([images_batch, y_batch], real_embeddings)\n",
        "        \n",
        "        print(\"Reconstruction loss: \", reconstruction_loss)\n",
        "        \n",
        "        reconstruction_losses.append(reconstruction_loss)\n",
        "        \n",
        "        \n",
        "      ## Write the reconstruction loss to Tensorboard\n",
        "      #write_log(tensorboard, \"reconstruction_loss\", np.mean(reconstruction_losses), epoch)\n",
        "      \n",
        "      \n",
        "      \"\"\"\n",
        "      Generate images\n",
        "      \"\"\"\n",
        "      \n",
        "      if epoch % 10 == 0:\n",
        "        images_batch = loaded_images[0:batch_size]\n",
        "        images_batch = images_batch / 127.5 - 1.0\n",
        "        images_batch = images_batch.astype(np.float32)\n",
        "        \n",
        "        y_batch = y[0:batch_size]\n",
        "        z_noise = np.random.normal(0, 1, size = (batch_size, z_shape))\n",
        "        \n",
        "        gen_images = generator.predict_on_batch([z_noise, y_batch])\n",
        "        \n",
        "        for i, img in enumerate(gen_images[:5]):\n",
        "          save_rgb_image(img, path = \"/content/drive/MyDrive/Đại học/Năm 3 - HK2/Học Sâu/Face_Aging_Process/Results/img_{}_{}.png\".format(epoch, i))\n",
        "        \n",
        "        \n",
        "    ## Save improved weights for both of the networks\n",
        "    generator.save_weights(\"/content/drive/MyDrive/Đại học/Năm 3 - HK2/Học Sâu/Face_Aging_Process/Model/generator_optimized.h5\")\n",
        "    encoder.save_weights(\"/content/drive/MyDrive/Đại học/Năm 3 - HK2/Học Sâu/Face_Aging_Process/Model/encoder_optimized.h5\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "d_loss: 0.16254194780155728\n",
            "g_loss: 0.10679445415735245\n",
            "Batch: 4567 Epoch: 0\n",
            "d_loss: 0.1625420671043969\n",
            "g_loss: 0.10754568874835968\n",
            "Batch: 4568 Epoch: 0\n",
            "d_loss: 0.16254175655530645\n",
            "g_loss: 0.10720362514257431\n",
            "Batch: 4569 Epoch: 0\n",
            "d_loss: 0.16254180039565114\n",
            "g_loss: 0.10805513709783554\n",
            "Batch: 4570 Epoch: 0\n",
            "d_loss: 0.16254201921789502\n",
            "g_loss: 0.10702486336231232\n",
            "Batch: 4571 Epoch: 0\n",
            "d_loss: 0.16254199307794437\n",
            "g_loss: 0.10743342339992523\n",
            "Batch: 4572 Epoch: 0\n",
            "d_loss: 0.16254178642599015\n",
            "g_loss: 0.107722207903862\n",
            "Batch: 4573 Epoch: 0\n",
            "d_loss: 0.16254180124256834\n",
            "g_loss: 0.10720740258693695\n",
            "Batch: 4574 Epoch: 0\n",
            "d_loss: 0.162541675054932\n",
            "g_loss: 0.10690131038427353\n",
            "Batch: 4575 Epoch: 0\n",
            "d_loss: 0.16254194630354135\n",
            "g_loss: 0.10772600024938583\n",
            "Batch: 4576 Epoch: 0\n",
            "d_loss: 0.1625422427698524\n",
            "g_loss: 0.10694745928049088\n",
            "Batch: 4577 Epoch: 0\n",
            "d_loss: 0.16254310850261788\n",
            "g_loss: 0.10816521942615509\n",
            "Batch: 4578 Epoch: 0\n",
            "d_loss: 0.16254398861168085\n",
            "g_loss: 0.10637755692005157\n",
            "Batch: 4579 Epoch: 0\n",
            "d_loss: 0.1625431515366742\n",
            "g_loss: 0.10762582719326019\n",
            "Batch: 4580 Epoch: 0\n",
            "d_loss: 0.16254209437271783\n",
            "g_loss: 0.10752759873867035\n",
            "Batch: 4581 Epoch: 0\n",
            "d_loss: 0.1625421143978727\n",
            "g_loss: 0.107123002409935\n",
            "Batch: 4582 Epoch: 0\n",
            "d_loss: 0.16254185783534325\n",
            "g_loss: 0.10741148144006729\n",
            "Batch: 4583 Epoch: 0\n",
            "d_loss: 0.16254180419632291\n",
            "g_loss: 0.10729658603668213\n",
            "Batch: 4584 Epoch: 0\n",
            "d_loss: 0.1625419807707118\n",
            "g_loss: 0.10682956129312515\n",
            "Batch: 4585 Epoch: 0\n",
            "d_loss: 0.16254178677741038\n",
            "g_loss: 0.10713730752468109\n",
            "Batch: 4586 Epoch: 0\n",
            "d_loss: 0.1625417357390475\n",
            "g_loss: 0.10752326250076294\n",
            "Batch: 4587 Epoch: 0\n",
            "d_loss: 0.1625418100278324\n",
            "g_loss: 0.10697245597839355\n",
            "Batch: 4588 Epoch: 0\n",
            "d_loss: 0.16254190653411626\n",
            "g_loss: 0.10731916129589081\n",
            "Batch: 4589 Epoch: 0\n",
            "d_loss: 0.16254199709938177\n",
            "g_loss: 0.10682593286037445\n",
            "Batch: 4590 Epoch: 0\n",
            "d_loss: 0.16254203494831643\n",
            "g_loss: 0.10737347602844238\n",
            "Batch: 4591 Epoch: 0\n",
            "d_loss: 0.16254162079729895\n",
            "g_loss: 0.10775122791528702\n",
            "Batch: 4592 Epoch: 0\n",
            "d_loss: 0.16254341004088246\n",
            "g_loss: 0.10619671642780304\n",
            "Batch: 4593 Epoch: 0\n",
            "d_loss: 0.1625461235612562\n",
            "g_loss: 0.10894238948822021\n",
            "Batch: 4594 Epoch: 0\n",
            "d_loss: 0.16254629092058082\n",
            "g_loss: 0.10616090148687363\n",
            "Batch: 4595 Epoch: 0\n",
            "d_loss: 0.1625442621924691\n",
            "g_loss: 0.1071576252579689\n",
            "Batch: 4596 Epoch: 0\n",
            "d_loss: 0.16254171069659407\n",
            "g_loss: 0.10718442499637604\n",
            "Batch: 4597 Epoch: 0\n",
            "d_loss: 0.16254199607861608\n",
            "g_loss: 0.1066158264875412\n",
            "Batch: 4598 Epoch: 0\n",
            "d_loss: 0.162543052821988\n",
            "g_loss: 0.10812041908502579\n",
            "Batch: 4599 Epoch: 0\n",
            "d_loss: 0.16254367002096615\n",
            "g_loss: 0.10606317222118378\n",
            "Batch: 4600 Epoch: 0\n",
            "d_loss: 0.16254336781564405\n",
            "g_loss: 0.10787014663219452\n",
            "Batch: 4601 Epoch: 0\n",
            "d_loss: 0.16254233823738673\n",
            "g_loss: 0.10736362636089325\n",
            "Batch: 4602 Epoch: 0\n",
            "d_loss: 0.16254189940978137\n",
            "g_loss: 0.10649824142456055\n",
            "Batch: 4603 Epoch: 0\n",
            "d_loss: 0.16254216091321183\n",
            "g_loss: 0.10713136196136475\n",
            "Batch: 4604 Epoch: 0\n",
            "d_loss: 0.1625422198572366\n",
            "g_loss: 0.1063510924577713\n",
            "Batch: 4605 Epoch: 0\n",
            "d_loss: 0.16254326318815515\n",
            "g_loss: 0.10806579887866974\n",
            "Batch: 4606 Epoch: 0\n",
            "d_loss: 0.16254279754686962\n",
            "g_loss: 0.10658304393291473\n",
            "Batch: 4607 Epoch: 0\n",
            "d_loss: 0.16254172889752283\n",
            "g_loss: 0.10664091259241104\n",
            "Batch: 4608 Epoch: 0\n",
            "d_loss: 0.16254197738452802\n",
            "g_loss: 0.10756342113018036\n",
            "Batch: 4609 Epoch: 0\n",
            "d_loss: 0.16254200741748548\n",
            "g_loss: 0.10696148872375488\n",
            "Batch: 4610 Epoch: 0\n",
            "d_loss: 0.16254209697697064\n",
            "g_loss: 0.10753560066223145\n",
            "Batch: 4611 Epoch: 0\n",
            "d_loss: 0.16254202429082198\n",
            "g_loss: 0.10660532861948013\n",
            "Batch: 4612 Epoch: 0\n",
            "d_loss: 0.16254210312767015\n",
            "g_loss: 0.10720980167388916\n",
            "Batch: 4613 Epoch: 0\n",
            "d_loss: 0.16254213038700982\n",
            "g_loss: 0.10767630487680435\n",
            "Batch: 4614 Epoch: 0\n",
            "d_loss: 0.16254259184689346\n",
            "g_loss: 0.1062217503786087\n",
            "Batch: 4615 Epoch: 0\n",
            "d_loss: 0.16254257505761416\n",
            "g_loss: 0.10727188736200333\n",
            "Batch: 4616 Epoch: 0\n",
            "d_loss: 0.1625421013845454\n",
            "g_loss: 0.10650815069675446\n",
            "Batch: 4617 Epoch: 0\n",
            "d_loss: 0.16254191887827574\n",
            "g_loss: 0.10696013271808624\n",
            "Batch: 4618 Epoch: 0\n",
            "d_loss: 0.16254181031293768\n",
            "g_loss: 0.1070994958281517\n",
            "Batch: 4619 Epoch: 0\n",
            "d_loss: 0.1625447203380972\n",
            "g_loss: 0.10920532792806625\n",
            "Batch: 4620 Epoch: 0\n",
            "d_loss: 0.1625526890454836\n",
            "g_loss: 0.10463768243789673\n",
            "Batch: 4621 Epoch: 0\n",
            "d_loss: 0.16254981906018884\n",
            "g_loss: 0.10806180536746979\n",
            "Batch: 4622 Epoch: 0\n",
            "d_loss: 0.16254421242431505\n",
            "g_loss: 0.10663298517465591\n",
            "Batch: 4623 Epoch: 0\n",
            "d_loss: 0.1625422277001718\n",
            "g_loss: 0.10736242681741714\n",
            "Batch: 4624 Epoch: 0\n",
            "d_loss: 0.16254257161760677\n",
            "g_loss: 0.10664216428995132\n",
            "Batch: 4625 Epoch: 0\n",
            "d_loss: 0.16254230493508715\n",
            "g_loss: 0.10712748765945435\n",
            "Batch: 4626 Epoch: 0\n",
            "d_loss: 0.16254251762264005\n",
            "g_loss: 0.10637619346380234\n",
            "Batch: 4627 Epoch: 0\n",
            "d_loss: 0.16254268911961844\n",
            "g_loss: 0.1072290688753128\n",
            "Batch: 4628 Epoch: 0\n",
            "d_loss: 0.16254238871834303\n",
            "g_loss: 0.10710364580154419\n",
            "Batch: 4629 Epoch: 0\n",
            "d_loss: 0.16254181936341183\n",
            "g_loss: 0.10716414451599121\n",
            "Batch: 4630 Epoch: 0\n",
            "d_loss: 0.16254179436123195\n",
            "g_loss: 0.10652951151132584\n",
            "Batch: 4631 Epoch: 0\n",
            "d_loss: 0.16254261451287988\n",
            "g_loss: 0.10812391340732574\n",
            "Batch: 4632 Epoch: 0\n",
            "d_loss: 0.1625423312915686\n",
            "g_loss: 0.10709065198898315\n",
            "Batch: 4633 Epoch: 0\n",
            "d_loss: 0.16254206274696514\n",
            "g_loss: 0.10756251960992813\n",
            "Batch: 4634 Epoch: 0\n",
            "d_loss: 0.16254210604124353\n",
            "g_loss: 0.10661160945892334\n",
            "Batch: 4635 Epoch: 0\n",
            "d_loss: 0.162543164594517\n",
            "g_loss: 0.10848768800497055\n",
            "Batch: 4636 Epoch: 0\n",
            "d_loss: 0.16254287582069793\n",
            "g_loss: 0.10729451477527618\n",
            "Batch: 4637 Epoch: 0\n",
            "d_loss: 0.16254230370616085\n",
            "g_loss: 0.10621748864650726\n",
            "Batch: 4638 Epoch: 0\n",
            "d_loss: 0.16254298704832593\n",
            "g_loss: 0.10780741274356842\n",
            "Batch: 4639 Epoch: 0\n",
            "d_loss: 0.16254316523752266\n",
            "g_loss: 0.10624430328607559\n",
            "Batch: 4640 Epoch: 0\n",
            "d_loss: 0.16254282342386972\n",
            "g_loss: 0.1078445166349411\n",
            "Batch: 4641 Epoch: 0\n",
            "d_loss: 0.16254296988206818\n",
            "g_loss: 0.10625261068344116\n",
            "Batch: 4642 Epoch: 0\n",
            "d_loss: 0.16254447521027515\n",
            "g_loss: 0.10800270736217499\n",
            "Batch: 4643 Epoch: 0\n",
            "d_loss: 0.16254292777946233\n",
            "g_loss: 0.10673614591360092\n",
            "Batch: 4644 Epoch: 0\n",
            "d_loss: 0.1625417951197079\n",
            "g_loss: 0.10705532878637314\n",
            "Batch: 4645 Epoch: 0\n",
            "d_loss: 0.1625420641380657\n",
            "g_loss: 0.10707863420248032\n",
            "Batch: 4646 Epoch: 0\n",
            "d_loss: 0.16254170702455895\n",
            "g_loss: 0.10714361816644669\n",
            "Batch: 4647 Epoch: 0\n",
            "d_loss: 0.16254203042499427\n",
            "g_loss: 0.10731738805770874\n",
            "Batch: 4648 Epoch: 0\n",
            "d_loss: 0.16254208058175834\n",
            "g_loss: 0.10644189268350601\n",
            "Batch: 4649 Epoch: 0\n",
            "d_loss: 0.16254303851253127\n",
            "g_loss: 0.10818557441234589\n",
            "Batch: 4650 Epoch: 0\n",
            "d_loss: 0.16254352200293454\n",
            "g_loss: 0.10631934553384781\n",
            "Batch: 4651 Epoch: 0\n",
            "d_loss: 0.16254313341774917\n",
            "g_loss: 0.10778456926345825\n",
            "Batch: 4652 Epoch: 0\n",
            "d_loss: 0.16254332626182588\n",
            "g_loss: 0.10638871043920517\n",
            "Batch: 4653 Epoch: 0\n",
            "d_loss: 0.1625420930578798\n",
            "g_loss: 0.10708148777484894\n",
            "Batch: 4654 Epoch: 0\n",
            "d_loss: 0.16254188229345345\n",
            "g_loss: 0.10679743438959122\n",
            "Batch: 4655 Epoch: 0\n",
            "d_loss: 0.16254226796520754\n",
            "g_loss: 0.10748782008886337\n",
            "Batch: 4656 Epoch: 0\n",
            "d_loss: 0.16254254283722958\n",
            "g_loss: 0.10608772933483124\n",
            "Batch: 4657 Epoch: 0\n",
            "d_loss: 0.16254330260347416\n",
            "g_loss: 0.10784824937582016\n",
            "Batch: 4658 Epoch: 0\n",
            "d_loss: 0.16254297398289452\n",
            "g_loss: 0.106634721159935\n",
            "Batch: 4659 Epoch: 0\n",
            "d_loss: 0.16254236711676384\n",
            "g_loss: 0.10711845010519028\n",
            "Batch: 4660 Epoch: 0\n",
            "d_loss: 0.16254203547174484\n",
            "g_loss: 0.10651025921106339\n",
            "Batch: 4661 Epoch: 0\n",
            "d_loss: 0.16254191740635804\n",
            "g_loss: 0.10751360654830933\n",
            "Batch: 4662 Epoch: 0\n",
            "d_loss: 0.16254215280456208\n",
            "g_loss: 0.10658309608697891\n",
            "Batch: 4663 Epoch: 0\n",
            "d_loss: 0.16254187047199764\n",
            "g_loss: 0.1067451685667038\n",
            "Batch: 4664 Epoch: 0\n",
            "d_loss: 0.16254260058587988\n",
            "g_loss: 0.10831353813409805\n",
            "Batch: 4665 Epoch: 0\n",
            "d_loss: 0.16254352290205532\n",
            "g_loss: 0.10666640847921371\n",
            "Batch: 4666 Epoch: 0\n",
            "d_loss: 0.16254246742320078\n",
            "g_loss: 0.10739568620920181\n",
            "Batch: 4667 Epoch: 0\n",
            "d_loss: 0.16254215326428323\n",
            "g_loss: 0.10688126087188721\n",
            "Batch: 4668 Epoch: 0\n",
            "d_loss: 0.16254224422583263\n",
            "g_loss: 0.10764618217945099\n",
            "Batch: 4669 Epoch: 0\n",
            "d_loss: 0.16254204599817967\n",
            "g_loss: 0.10702359676361084\n",
            "Batch: 4670 Epoch: 0\n",
            "d_loss: 0.16254186729226205\n",
            "g_loss: 0.1076074093580246\n",
            "Batch: 4671 Epoch: 0\n",
            "d_loss: 0.16254170474172724\n",
            "g_loss: 0.10733191668987274\n",
            "Batch: 4672 Epoch: 0\n",
            "d_loss: 0.16254165815008292\n",
            "g_loss: 0.10729620605707169\n",
            "Batch: 4673 Epoch: 0\n",
            "d_loss: 0.16254168221938414\n",
            "g_loss: 0.1070873960852623\n",
            "Batch: 4674 Epoch: 0\n",
            "d_loss: 0.1625419044433869\n",
            "g_loss: 0.10743798315525055\n",
            "Batch: 4675 Epoch: 0\n",
            "d_loss: 0.16254165808570065\n",
            "g_loss: 0.10734552145004272\n",
            "Batch: 4676 Epoch: 0\n",
            "d_loss: 0.16254172010307144\n",
            "g_loss: 0.1078128069639206\n",
            "Batch: 4677 Epoch: 0\n",
            "d_loss: 0.16254197410644622\n",
            "g_loss: 0.10721240937709808\n",
            "Batch: 4678 Epoch: 0\n",
            "d_loss: 0.16254179673337887\n",
            "g_loss: 0.10756458342075348\n",
            "Batch: 4679 Epoch: 0\n",
            "d_loss: 0.16254255592396305\n",
            "g_loss: 0.10608544200658798\n",
            "Batch: 4680 Epoch: 0\n",
            "d_loss: 0.1625439866449696\n",
            "g_loss: 0.1083427220582962\n",
            "Batch: 4681 Epoch: 0\n",
            "d_loss: 0.16254453881532527\n",
            "g_loss: 0.10610606521368027\n",
            "Batch: 4682 Epoch: 0\n",
            "d_loss: 0.1625449993204171\n",
            "g_loss: 0.10863952338695526\n",
            "Batch: 4683 Epoch: 0\n",
            "d_loss: 0.1625434965619661\n",
            "g_loss: 0.10767586529254913\n",
            "Batch: 4684 Epoch: 0\n",
            "d_loss: 0.16254238011229916\n",
            "g_loss: 0.10815463960170746\n",
            "Batch: 4685 Epoch: 0\n",
            "d_loss: 0.1625419618426136\n",
            "g_loss: 0.10767994076013565\n",
            "Batch: 4686 Epoch: 0\n",
            "d_loss: 0.16254198746976556\n",
            "g_loss: 0.10828544944524765\n",
            "Batch: 4687 Epoch: 0\n",
            "d_loss: 0.16254206639282387\n",
            "g_loss: 0.107635498046875\n",
            "Batch: 4688 Epoch: 0\n",
            "d_loss: 0.16254215594564414\n",
            "g_loss: 0.10665824264287949\n",
            "Batch: 4689 Epoch: 0\n",
            "d_loss: 0.16254450897555728\n",
            "g_loss: 0.10888862609863281\n",
            "Batch: 4690 Epoch: 0\n",
            "d_loss: 0.16254436059331567\n",
            "g_loss: 0.10665524005889893\n",
            "Batch: 4691 Epoch: 0\n",
            "d_loss: 0.16254311183876524\n",
            "g_loss: 0.10777129232883453\n",
            "Batch: 4692 Epoch: 0\n",
            "d_loss: 0.16254199199336483\n",
            "g_loss: 0.1077367290854454\n",
            "Batch: 4693 Epoch: 0\n",
            "d_loss: 0.16254245388837774\n",
            "g_loss: 0.10639508068561554\n",
            "Batch: 4694 Epoch: 0\n",
            "d_loss: 0.16254279397090698\n",
            "g_loss: 0.10796479880809784\n",
            "Batch: 4695 Epoch: 0\n",
            "d_loss: 0.16254225560462743\n",
            "g_loss: 0.10710873454809189\n",
            "Batch: 4696 Epoch: 0\n",
            "d_loss: 0.1625424697826574\n",
            "g_loss: 0.10797067731618881\n",
            "Batch: 4697 Epoch: 0\n",
            "d_loss: 0.1625419483438506\n",
            "g_loss: 0.10747380554676056\n",
            "Batch: 4698 Epoch: 0\n",
            "d_loss: 0.1625416591336517\n",
            "g_loss: 0.10726337134838104\n",
            "Batch: 4699 Epoch: 0\n",
            "d_loss: 0.1625417642512872\n",
            "g_loss: 0.10743416845798492\n",
            "Batch: 4700 Epoch: 0\n",
            "d_loss: 0.16254203638861497\n",
            "g_loss: 0.10737719386816025\n",
            "Batch: 4701 Epoch: 0\n",
            "d_loss: 0.16254194516889697\n",
            "g_loss: 0.10706915706396103\n",
            "Batch: 4702 Epoch: 0\n",
            "d_loss: 0.1625420474527246\n",
            "g_loss: 0.10778504610061646\n",
            "Batch: 4703 Epoch: 0\n",
            "d_loss: 0.16254242421348408\n",
            "g_loss: 0.10657249391078949\n",
            "Batch: 4704 Epoch: 0\n",
            "d_loss: 0.16254239420975836\n",
            "g_loss: 0.107598677277565\n",
            "Batch: 4705 Epoch: 0\n",
            "d_loss: 0.16254228834319662\n",
            "g_loss: 0.10685640573501587\n",
            "Batch: 4706 Epoch: 0\n",
            "d_loss: 0.16254230478856613\n",
            "g_loss: 0.10825207084417343\n",
            "Batch: 4707 Epoch: 0\n",
            "d_loss: 0.1625434645975261\n",
            "g_loss: 0.10626473277807236\n",
            "Batch: 4708 Epoch: 0\n",
            "d_loss: 0.16254434151515085\n",
            "g_loss: 0.10850051790475845\n",
            "Batch: 4709 Epoch: 0\n",
            "d_loss: 0.1625441791424933\n",
            "g_loss: 0.10692045837640762\n",
            "Batch: 4710 Epoch: 0\n",
            "d_loss: 0.16254197280400717\n",
            "g_loss: 0.10729920864105225\n",
            "Batch: 4711 Epoch: 0\n",
            "d_loss: 0.16254284992018597\n",
            "g_loss: 0.10879433155059814\n",
            "Batch: 4712 Epoch: 0\n",
            "d_loss: 0.16254451016036597\n",
            "g_loss: 0.10670632123947144\n",
            "Batch: 4713 Epoch: 0\n",
            "d_loss: 0.16254338921970657\n",
            "g_loss: 0.10781748592853546\n",
            "Batch: 4714 Epoch: 0\n",
            "d_loss: 0.16254215383775517\n",
            "g_loss: 0.10850639641284943\n",
            "Batch: 4715 Epoch: 0\n",
            "d_loss: 0.1625437291740326\n",
            "g_loss: 0.10630965232849121\n",
            "Batch: 4716 Epoch: 0\n",
            "d_loss: 0.16254357383538576\n",
            "g_loss: 0.108101986348629\n",
            "Batch: 4717 Epoch: 0\n",
            "d_loss: 0.16254377603245018\n",
            "g_loss: 0.10621000826358795\n",
            "Batch: 4718 Epoch: 0\n",
            "d_loss: 0.16254243910050548\n",
            "g_loss: 0.10701155662536621\n",
            "Batch: 4719 Epoch: 0\n",
            "d_loss: 0.16254170175116656\n",
            "g_loss: 0.10704796016216278\n",
            "Batch: 4720 Epoch: 0\n",
            "d_loss: 0.1625432832791418\n",
            "g_loss: 0.10863886028528214\n",
            "Batch: 4721 Epoch: 0\n",
            "d_loss: 0.16254541505428932\n",
            "g_loss: 0.10598786175251007\n",
            "Batch: 4722 Epoch: 0\n",
            "d_loss: 0.1625470648134879\n",
            "g_loss: 0.1093752384185791\n",
            "Batch: 4723 Epoch: 0\n",
            "d_loss: 0.16254718552873726\n",
            "g_loss: 0.10589853674173355\n",
            "Batch: 4724 Epoch: 0\n",
            "d_loss: 0.16254580185163547\n",
            "g_loss: 0.10851385444402695\n",
            "Batch: 4725 Epoch: 0\n",
            "d_loss: 0.16254618748013172\n",
            "g_loss: 0.10618934780359268\n",
            "Batch: 4726 Epoch: 0\n",
            "d_loss: 0.1625424642341926\n",
            "g_loss: 0.1066650003194809\n",
            "Batch: 4727 Epoch: 0\n",
            "d_loss: 0.16254293705623013\n",
            "g_loss: 0.10677289962768555\n",
            "Batch: 4728 Epoch: 0\n",
            "d_loss: 0.16254250585366492\n",
            "g_loss: 0.10831160843372345\n",
            "Batch: 4729 Epoch: 0\n",
            "d_loss: 0.16254268553353768\n",
            "g_loss: 0.10712818801403046\n",
            "Batch: 4730 Epoch: 0\n",
            "d_loss: 0.16254170238350696\n",
            "g_loss: 0.10751845687627792\n",
            "Batch: 4731 Epoch: 0\n",
            "d_loss: 0.1625420144765357\n",
            "g_loss: 0.10838822275400162\n",
            "Batch: 4732 Epoch: 0\n",
            "d_loss: 0.1625420901283121\n",
            "g_loss: 0.1075950413942337\n",
            "Batch: 4733 Epoch: 0\n",
            "d_loss: 0.16254250473944865\n",
            "g_loss: 0.10702133178710938\n",
            "Batch: 4734 Epoch: 0\n",
            "d_loss: 0.16254238794851972\n",
            "g_loss: 0.10800991207361221\n",
            "Batch: 4735 Epoch: 0\n",
            "d_loss: 0.16254249443780822\n",
            "g_loss: 0.10683274269104004\n",
            "Batch: 4736 Epoch: 0\n",
            "d_loss: 0.16254295290659826\n",
            "g_loss: 0.10848844051361084\n",
            "Batch: 4737 Epoch: 0\n",
            "d_loss: 0.162544058090468\n",
            "g_loss: 0.10634913295507431\n",
            "Batch: 4738 Epoch: 0\n",
            "d_loss: 0.16254413057461647\n",
            "g_loss: 0.10826996713876724\n",
            "Batch: 4739 Epoch: 0\n",
            "d_loss: 0.16254315252664497\n",
            "g_loss: 0.1068464145064354\n",
            "Batch: 4740 Epoch: 0\n",
            "d_loss: 0.1625417766534767\n",
            "g_loss: 0.10696657747030258\n",
            "Batch: 4741 Epoch: 0\n",
            "d_loss: 0.16254159928971035\n",
            "g_loss: 0.10704654455184937\n",
            "Batch: 4742 Epoch: 0\n",
            "d_loss: 0.16254167272050069\n",
            "g_loss: 0.10719235241413116\n",
            "Batch: 4743 Epoch: 0\n",
            "d_loss: 0.162541954088411\n",
            "g_loss: 0.1074475646018982\n",
            "Batch: 4744 Epoch: 0\n",
            "d_loss: 0.16254197845853469\n",
            "g_loss: 0.10680141299962997\n",
            "Batch: 4745 Epoch: 0\n",
            "d_loss: 0.16254184764073187\n",
            "g_loss: 0.10703009366989136\n",
            "Batch: 4746 Epoch: 0\n",
            "d_loss: 0.162541746259663\n",
            "g_loss: 0.10784592479467392\n",
            "Batch: 4747 Epoch: 0\n",
            "d_loss: 0.16254259643447\n",
            "g_loss: 0.10660967975854874\n",
            "Batch: 4748 Epoch: 0\n",
            "d_loss: 0.16254238620639683\n",
            "g_loss: 0.10705585777759552\n",
            "Batch: 4749 Epoch: 0\n",
            "d_loss: 0.16254189351198534\n",
            "g_loss: 0.10744044929742813\n",
            "Batch: 4750 Epoch: 0\n",
            "d_loss: 0.16254167206862746\n",
            "g_loss: 0.107701875269413\n",
            "Batch: 4751 Epoch: 0\n",
            "d_loss: 0.16254168565221505\n",
            "g_loss: 0.10742435604333878\n",
            "Batch: 4752 Epoch: 0\n",
            "d_loss: 0.16254185270173593\n",
            "g_loss: 0.10707787424325943\n",
            "Batch: 4753 Epoch: 0\n",
            "d_loss: 0.16254177242857537\n",
            "g_loss: 0.10796976089477539\n",
            "Batch: 4754 Epoch: 0\n",
            "d_loss: 0.16254186546937177\n",
            "g_loss: 0.106961190700531\n",
            "Batch: 4755 Epoch: 0\n",
            "d_loss: 0.16254233313959787\n",
            "g_loss: 0.10798396915197372\n",
            "Batch: 4756 Epoch: 0\n",
            "d_loss: 0.1625435237818138\n",
            "g_loss: 0.10636202991008759\n",
            "Batch: 4757 Epoch: 0\n",
            "d_loss: 0.1625440691175939\n",
            "g_loss: 0.10804911702871323\n",
            "Batch: 4758 Epoch: 0\n",
            "d_loss: 0.162542341471557\n",
            "g_loss: 0.10726146399974823\n",
            "Batch: 4759 Epoch: 0\n",
            "d_loss: 0.16254179619812703\n",
            "g_loss: 0.10763458907604218\n",
            "Batch: 4760 Epoch: 0\n",
            "d_loss: 0.16254218158296396\n",
            "g_loss: 0.10752550512552261\n",
            "Batch: 4761 Epoch: 0\n",
            "d_loss: 0.16254193995887078\n",
            "g_loss: 0.10817158222198486\n",
            "Batch: 4762 Epoch: 0\n",
            "d_loss: 0.16254193878862822\n",
            "g_loss: 0.10767002403736115\n",
            "Batch: 4763 Epoch: 0\n",
            "d_loss: 0.16254179177561667\n",
            "g_loss: 0.10676071792840958\n",
            "Batch: 4764 Epoch: 0\n",
            "d_loss: 0.16254214822207302\n",
            "g_loss: 0.10788289457559586\n",
            "Batch: 4765 Epoch: 0\n",
            "d_loss: 0.16254190016991998\n",
            "g_loss: 0.10764746367931366\n",
            "Batch: 4766 Epoch: 0\n",
            "d_loss: 0.16254174717480652\n",
            "g_loss: 0.10732366889715195\n",
            "Batch: 4767 Epoch: 0\n",
            "d_loss: 0.16254177531281044\n",
            "g_loss: 0.10726459324359894\n",
            "Batch: 4768 Epoch: 0\n",
            "d_loss: 0.1625419704032396\n",
            "g_loss: 0.10762478411197662\n",
            "Batch: 4769 Epoch: 0\n",
            "d_loss: 0.1625416680030085\n",
            "g_loss: 0.10810290277004242\n",
            "Batch: 4770 Epoch: 0\n",
            "d_loss: 0.16254388575944034\n",
            "g_loss: 0.10981850326061249\n",
            "Batch: 4771 Epoch: 0\n",
            "d_loss: 0.16256122629264524\n",
            "g_loss: 0.10324107110500336\n",
            "Batch: 4772 Epoch: 0\n",
            "d_loss: 0.1625719823494265\n",
            "g_loss: 0.11120723187923431\n",
            "Batch: 4773 Epoch: 0\n",
            "d_loss: 0.1625766028795823\n",
            "g_loss: 0.10374538600444794\n",
            "Batch: 4774 Epoch: 0\n",
            "d_loss: 0.1625662573765254\n",
            "g_loss: 0.10994265228509903\n",
            "Batch: 4775 Epoch: 0\n",
            "d_loss: 0.16255281838321878\n",
            "g_loss: 0.1070394515991211\n",
            "Batch: 4776 Epoch: 0\n",
            "d_loss: 0.16255049422782264\n",
            "g_loss: 0.11070263385772705\n",
            "Batch: 4777 Epoch: 0\n",
            "d_loss: 0.16255800802679232\n",
            "g_loss: 0.10596971213817596\n",
            "Batch: 4778 Epoch: 0\n",
            "d_loss: 0.16255954114899396\n",
            "g_loss: 0.11083409935235977\n",
            "Batch: 4779 Epoch: 0\n",
            "d_loss: 0.1625665895584092\n",
            "g_loss: 0.10362319648265839\n",
            "Batch: 4780 Epoch: 0\n",
            "d_loss: 0.1625609461165567\n",
            "g_loss: 0.10849650204181671\n",
            "Batch: 4781 Epoch: 0\n",
            "d_loss: 0.1625614241249238\n",
            "g_loss: 0.10305808484554291\n",
            "Batch: 4782 Epoch: 0\n",
            "d_loss: 0.16256106574362406\n",
            "g_loss: 0.10869906097650528\n",
            "Batch: 4783 Epoch: 0\n",
            "d_loss: 0.16255008155071948\n",
            "g_loss: 0.1078447699546814\n",
            "Batch: 4784 Epoch: 0\n",
            "d_loss: 0.16254227298070134\n",
            "g_loss: 0.10688702762126923\n",
            "Batch: 4785 Epoch: 0\n",
            "d_loss: 0.16254656998982853\n",
            "g_loss: 0.10824604332447052\n",
            "Batch: 4786 Epoch: 0\n",
            "d_loss: 0.1625450724320956\n",
            "g_loss: 0.10615787655115128\n",
            "Batch: 4787 Epoch: 0\n",
            "d_loss: 0.16254526723989926\n",
            "g_loss: 0.1067032665014267\n",
            "Batch: 4788 Epoch: 0\n",
            "d_loss: 0.16254222695378218\n",
            "g_loss: 0.10698141902685165\n",
            "Batch: 4789 Epoch: 0\n",
            "d_loss: 0.16254460830784012\n",
            "g_loss: 0.10473678261041641\n",
            "Batch: 4790 Epoch: 0\n",
            "d_loss: 0.16255550454268786\n",
            "g_loss: 0.10873185098171234\n",
            "Batch: 4791 Epoch: 0\n",
            "d_loss: 0.1625492642696642\n",
            "g_loss: 0.10529770702123642\n",
            "Batch: 4792 Epoch: 0\n",
            "d_loss: 0.16254537819885684\n",
            "g_loss: 0.10639496147632599\n",
            "Batch: 4793 Epoch: 0\n",
            "d_loss: 0.1625434171190392\n",
            "g_loss: 0.10775578022003174\n",
            "Batch: 4794 Epoch: 0\n",
            "d_loss: 0.1625435203718979\n",
            "g_loss: 0.10636456310749054\n",
            "Batch: 4795 Epoch: 0\n",
            "d_loss: 0.16254275036119736\n",
            "g_loss: 0.10660000145435333\n",
            "Batch: 4796 Epoch: 0\n",
            "d_loss: 0.16254249470491544\n",
            "g_loss: 0.1066594272851944\n",
            "Batch: 4797 Epoch: 0\n",
            "d_loss: 0.16254206333261578\n",
            "g_loss: 0.10689053684473038\n",
            "Batch: 4798 Epoch: 0\n",
            "d_loss: 0.16254184102313474\n",
            "g_loss: 0.10698257386684418\n",
            "Batch: 4799 Epoch: 0\n",
            "d_loss: 0.16254210283654658\n",
            "g_loss: 0.10648615658283234\n",
            "Batch: 4800 Epoch: 0\n",
            "d_loss: 0.16254245891580865\n",
            "g_loss: 0.10705067962408066\n",
            "Batch: 4801 Epoch: 0\n",
            "d_loss: 0.16254225865497318\n",
            "g_loss: 0.10712017863988876\n",
            "Batch: 4802 Epoch: 0\n",
            "d_loss: 0.1625431764510239\n",
            "g_loss: 0.10824333131313324\n",
            "Batch: 4803 Epoch: 0\n",
            "d_loss: 0.1625430285645706\n",
            "g_loss: 0.10673703998327255\n",
            "Batch: 4804 Epoch: 0\n",
            "d_loss: 0.16254220946060371\n",
            "g_loss: 0.10737110674381256\n",
            "Batch: 4805 Epoch: 0\n",
            "d_loss: 0.1625416779759874\n",
            "g_loss: 0.10788004100322723\n",
            "Batch: 4806 Epoch: 0\n",
            "d_loss: 0.16254177333412656\n",
            "g_loss: 0.10765837132930756\n",
            "Batch: 4807 Epoch: 0\n",
            "d_loss: 0.16254185083773365\n",
            "g_loss: 0.10735651105642319\n",
            "Batch: 4808 Epoch: 0\n",
            "d_loss: 0.1625416602340124\n",
            "g_loss: 0.10712919384241104\n",
            "Batch: 4809 Epoch: 0\n",
            "d_loss: 0.16254201419279468\n",
            "g_loss: 0.10660971701145172\n",
            "Batch: 4810 Epoch: 0\n",
            "d_loss: 0.16254251085190674\n",
            "g_loss: 0.10774896293878555\n",
            "Batch: 4811 Epoch: 0\n",
            "d_loss: 0.1625444713864752\n",
            "g_loss: 0.1059526652097702\n",
            "Batch: 4812 Epoch: 0\n",
            "d_loss: 0.16254451536518388\n",
            "g_loss: 0.1080380454659462\n",
            "Batch: 4813 Epoch: 0\n",
            "d_loss: 0.1625445614903498\n",
            "g_loss: 0.10612143576145172\n",
            "Batch: 4814 Epoch: 0\n",
            "d_loss: 0.16254464674877767\n",
            "g_loss: 0.10785119235515594\n",
            "Batch: 4815 Epoch: 0\n",
            "d_loss: 0.16254451778255685\n",
            "g_loss: 0.10576687008142471\n",
            "Batch: 4816 Epoch: 0\n",
            "d_loss: 0.16254566313519803\n",
            "g_loss: 0.10823267698287964\n",
            "Batch: 4817 Epoch: 0\n",
            "d_loss: 0.1625452944663195\n",
            "g_loss: 0.10591930150985718\n",
            "Batch: 4818 Epoch: 0\n",
            "d_loss: 0.16254296745148622\n",
            "g_loss: 0.10657918453216553\n",
            "Batch: 4819 Epoch: 0\n",
            "d_loss: 0.16254184789964654\n",
            "g_loss: 0.10695688426494598\n",
            "Batch: 4820 Epoch: 0\n",
            "d_loss: 0.1625418603841453\n",
            "g_loss: 0.10697752237319946\n",
            "Batch: 4821 Epoch: 0\n",
            "d_loss: 0.16254226605130384\n",
            "g_loss: 0.1069536805152893\n",
            "Batch: 4822 Epoch: 0\n",
            "d_loss: 0.1625421356486001\n",
            "g_loss: 0.10602064430713654\n",
            "Batch: 4823 Epoch: 0\n",
            "d_loss: 0.16254237007551353\n",
            "g_loss: 0.10713259875774384\n",
            "Batch: 4824 Epoch: 0\n",
            "d_loss: 0.162541775434363\n",
            "g_loss: 0.10686962306499481\n",
            "Batch: 4825 Epoch: 0\n",
            "d_loss: 0.16254189408014952\n",
            "g_loss: 0.10680575668811798\n",
            "Batch: 4826 Epoch: 0\n",
            "d_loss: 0.1625416982534773\n",
            "g_loss: 0.1064458116889\n",
            "Batch: 4827 Epoch: 0\n",
            "d_loss: 0.16254258259851895\n",
            "g_loss: 0.1078682690858841\n",
            "Batch: 4828 Epoch: 0\n",
            "d_loss: 0.16254371507771737\n",
            "g_loss: 0.10618257522583008\n",
            "Batch: 4829 Epoch: 0\n",
            "d_loss: 0.16254368282326226\n",
            "g_loss: 0.10795365273952484\n",
            "Batch: 4830 Epoch: 0\n",
            "d_loss: 0.162543263160849\n",
            "g_loss: 0.10658565908670425\n",
            "Batch: 4831 Epoch: 0\n",
            "d_loss: 0.16254271413365018\n",
            "g_loss: 0.10790999233722687\n",
            "Batch: 4832 Epoch: 0\n",
            "d_loss: 0.16254277077320012\n",
            "g_loss: 0.10626368224620819\n",
            "Batch: 4833 Epoch: 0\n",
            "d_loss: 0.16254226407388472\n",
            "g_loss: 0.10703299939632416\n",
            "Batch: 4834 Epoch: 0\n",
            "d_loss: 0.1625423860270203\n",
            "g_loss: 0.10769443213939667\n",
            "Batch: 4835 Epoch: 0\n",
            "d_loss: 0.16254214824982682\n",
            "g_loss: 0.1065475195646286\n",
            "Batch: 4836 Epoch: 0\n",
            "d_loss: 0.16254296714566152\n",
            "g_loss: 0.1081678718328476\n",
            "Batch: 4837 Epoch: 0\n",
            "d_loss: 0.16254444773250043\n",
            "g_loss: 0.10569139569997787\n",
            "Batch: 4838 Epoch: 0\n",
            "d_loss: 0.16254351622053065\n",
            "g_loss: 0.10720936954021454\n",
            "Batch: 4839 Epoch: 0\n",
            "d_loss: 0.16254242065443947\n",
            "g_loss: 0.10817229747772217\n",
            "Batch: 4840 Epoch: 0\n",
            "d_loss: 0.16254375750056482\n",
            "g_loss: 0.1061176285147667\n",
            "Batch: 4841 Epoch: 0\n",
            "d_loss: 0.16254788295084666\n",
            "g_loss: 0.10367511212825775\n",
            "Batch: 4842 Epoch: 0\n",
            "d_loss: 0.16258273316145733\n",
            "g_loss: 0.11216995865106583\n",
            "Batch: 4843 Epoch: 0\n",
            "d_loss: 0.1625720114637872\n",
            "g_loss: 0.10570206493139267\n",
            "Batch: 4844 Epoch: 0\n",
            "d_loss: 0.16255932492439484\n",
            "g_loss: 0.11014672368764877\n",
            "Batch: 4845 Epoch: 0\n",
            "d_loss: 0.1625475702915793\n",
            "g_loss: 0.10794749110937119\n",
            "Batch: 4846 Epoch: 0\n",
            "d_loss: 0.1625458738132295\n",
            "g_loss: 0.10647394508123398\n",
            "Batch: 4847 Epoch: 0\n",
            "d_loss: 0.16259624947872453\n",
            "g_loss: 0.11251987516880035\n",
            "Batch: 4848 Epoch: 0\n",
            "d_loss: 0.16268506579886832\n",
            "g_loss: 0.10158608108758926\n",
            "Batch: 4849 Epoch: 0\n",
            "d_loss: 0.16259046082289075\n",
            "g_loss: 0.10842392593622208\n",
            "Batch: 4850 Epoch: 0\n",
            "d_loss: 0.16254554794601717\n",
            "g_loss: 0.10746400058269501\n",
            "Batch: 4851 Epoch: 0\n",
            "d_loss: 0.16284234692626853\n",
            "g_loss: 0.09480579942464828\n",
            "Batch: 4852 Epoch: 0\n",
            "d_loss: 0.1639151883471328\n",
            "g_loss: 0.1121894121170044\n",
            "Batch: 4853 Epoch: 0\n",
            "d_loss: 0.16316260594131649\n",
            "g_loss: 0.10048184543848038\n",
            "Batch: 4854 Epoch: 0\n",
            "d_loss: 0.16271886145800352\n",
            "g_loss: 0.10710930824279785\n",
            "Batch: 4855 Epoch: 0\n",
            "d_loss: 0.16254699411288698\n",
            "g_loss: 0.1094837412238121\n",
            "Batch: 4856 Epoch: 0\n",
            "d_loss: 0.1625458624238263\n",
            "g_loss: 0.10788238048553467\n",
            "Batch: 4857 Epoch: 0\n",
            "d_loss: 0.16255566971653934\n",
            "g_loss: 0.10463859885931015\n",
            "Batch: 4858 Epoch: 0\n",
            "d_loss: 0.16255076603397356\n",
            "g_loss: 0.10735505819320679\n",
            "Batch: 4859 Epoch: 0\n",
            "d_loss: 0.1625435243454092\n",
            "g_loss: 0.10656686872243881\n",
            "Batch: 4860 Epoch: 0\n",
            "d_loss: 0.1625482972124246\n",
            "g_loss: 0.10735126584768295\n",
            "Batch: 4861 Epoch: 0\n",
            "d_loss: 0.1625437513992125\n",
            "g_loss: 0.10780253261327744\n",
            "Batch: 4862 Epoch: 0\n",
            "d_loss: 0.1625454087096827\n",
            "g_loss: 0.10562630742788315\n",
            "Batch: 4863 Epoch: 0\n",
            "d_loss: 0.16254685302161676\n",
            "g_loss: 0.1077994704246521\n",
            "Batch: 4864 Epoch: 0\n",
            "d_loss: 0.1625552781480124\n",
            "g_loss: 0.11024428904056549\n",
            "Batch: 4865 Epoch: 0\n",
            "d_loss: 0.16257900436757922\n",
            "g_loss: 0.10357548296451569\n",
            "Batch: 4866 Epoch: 0\n",
            "d_loss: 0.16256621113272018\n",
            "g_loss: 0.10659030824899673\n",
            "Batch: 4867 Epoch: 0\n",
            "d_loss: 0.16254269035891866\n",
            "g_loss: 0.10692334175109863\n",
            "Batch: 4868 Epoch: 0\n",
            "d_loss: 0.16254276372200138\n",
            "g_loss: 0.10744373500347137\n",
            "Batch: 4869 Epoch: 0\n",
            "d_loss: 0.1625548141463895\n",
            "g_loss: 0.10554424673318863\n",
            "Batch: 4870 Epoch: 0\n",
            "d_loss: 0.16254397271947596\n",
            "g_loss: 0.10511226952075958\n",
            "Batch: 4871 Epoch: 0\n",
            "d_loss: 0.16254243130910595\n",
            "g_loss: 0.10569550096988678\n",
            "Batch: 4872 Epoch: 0\n",
            "d_loss: 0.162542613203442\n",
            "g_loss: 0.1062692180275917\n",
            "Batch: 4873 Epoch: 0\n",
            "d_loss: 0.162542580254609\n",
            "g_loss: 0.106606125831604\n",
            "Batch: 4874 Epoch: 0\n",
            "d_loss: 0.16254239639468437\n",
            "g_loss: 0.10619942843914032\n",
            "Batch: 4875 Epoch: 0\n",
            "d_loss: 0.1625421315128932\n",
            "g_loss: 0.10621608793735504\n",
            "Batch: 4876 Epoch: 0\n",
            "d_loss: 0.1625420751154678\n",
            "g_loss: 0.10654260963201523\n",
            "Batch: 4877 Epoch: 0\n",
            "d_loss: 0.16254211962903753\n",
            "g_loss: 0.10618346929550171\n",
            "Batch: 4878 Epoch: 0\n",
            "d_loss: 0.162542738515981\n",
            "g_loss: 0.10658787190914154\n",
            "Batch: 4879 Epoch: 0\n",
            "d_loss: 0.1625423644189823\n",
            "g_loss: 0.10661119222640991\n",
            "Batch: 4880 Epoch: 0\n",
            "d_loss: 0.16254275381531613\n",
            "g_loss: 0.10682584345340729\n",
            "Batch: 4881 Epoch: 0\n",
            "d_loss: 0.16254339615836955\n",
            "g_loss: 0.10554958879947662\n",
            "Batch: 4882 Epoch: 0\n",
            "d_loss: 0.16254314565418326\n",
            "g_loss: 0.10662571340799332\n",
            "Batch: 4883 Epoch: 0\n",
            "d_loss: 0.1625419009195923\n",
            "g_loss: 0.10666229575872421\n",
            "Batch: 4884 Epoch: 0\n",
            "d_loss: 0.16254306233172144\n",
            "g_loss: 0.10547056049108505\n",
            "Batch: 4885 Epoch: 0\n",
            "d_loss: 0.1625430975765525\n",
            "g_loss: 0.10620150715112686\n",
            "Batch: 4886 Epoch: 0\n",
            "d_loss: 0.16254193686059892\n",
            "g_loss: 0.10610263049602509\n",
            "Batch: 4887 Epoch: 0\n",
            "d_loss: 0.1625420248551137\n",
            "g_loss: 0.1059459000825882\n",
            "Batch: 4888 Epoch: 0\n",
            "d_loss: 0.1625419827553074\n",
            "g_loss: 0.10637466609477997\n",
            "Batch: 4889 Epoch: 0\n",
            "d_loss: 0.16254219708908124\n",
            "g_loss: 0.10603068023920059\n",
            "Batch: 4890 Epoch: 0\n",
            "d_loss: 0.16254196631838624\n",
            "g_loss: 0.10579738765954971\n",
            "Batch: 4891 Epoch: 0\n",
            "d_loss: 0.16254171740236245\n",
            "g_loss: 0.10583287477493286\n",
            "Batch: 4892 Epoch: 0\n",
            "d_loss: 0.16254293488767502\n",
            "g_loss: 0.10580547899007797\n",
            "Batch: 4893 Epoch: 0\n",
            "d_loss: 0.16254283124197855\n",
            "g_loss: 0.10652905702590942\n",
            "Batch: 4894 Epoch: 0\n",
            "d_loss: 0.16254176461974623\n",
            "g_loss: 0.10656745731830597\n",
            "Batch: 4895 Epoch: 0\n",
            "d_loss: 0.16254217056416564\n",
            "g_loss: 0.10599236190319061\n",
            "Batch: 4896 Epoch: 0\n",
            "d_loss: 0.16254219351551313\n",
            "g_loss: 0.10632725805044174\n",
            "Batch: 4897 Epoch: 0\n",
            "d_loss: 0.1625427732192648\n",
            "g_loss: 0.10554486513137817\n",
            "Batch: 4898 Epoch: 0\n",
            "d_loss: 0.16254296829185932\n",
            "g_loss: 0.10632135719060898\n",
            "Batch: 4899 Epoch: 0\n",
            "d_loss: 0.1625418884070342\n",
            "g_loss: 0.10658009350299835\n",
            "Batch: 4900 Epoch: 0\n",
            "d_loss: 0.16254188439732076\n",
            "g_loss: 0.10629256069660187\n",
            "Batch: 4901 Epoch: 0\n",
            "d_loss: 0.16254183692799984\n",
            "g_loss: 0.10637463629245758\n",
            "Batch: 4902 Epoch: 0\n",
            "d_loss: 0.1625416926707075\n",
            "g_loss: 0.10635379701852798\n",
            "Batch: 4903 Epoch: 0\n",
            "d_loss: 0.1625417174888355\n",
            "g_loss: 0.10608043521642685\n",
            "Batch: 4904 Epoch: 0\n",
            "d_loss: 0.1625418867112316\n",
            "g_loss: 0.10630055516958237\n",
            "Batch: 4905 Epoch: 0\n",
            "d_loss: 0.1625418054112302\n",
            "g_loss: 0.10650328546762466\n",
            "Batch: 4906 Epoch: 0\n",
            "d_loss: 0.1625417472723356\n",
            "g_loss: 0.10655419528484344\n",
            "Batch: 4907 Epoch: 0\n",
            "d_loss: 0.16254168967914495\n",
            "g_loss: 0.10667365789413452\n",
            "Batch: 4908 Epoch: 0\n",
            "d_loss: 0.16254186963141137\n",
            "g_loss: 0.10640128701925278\n",
            "Batch: 4909 Epoch: 0\n",
            "d_loss: 0.16254168715410344\n",
            "g_loss: 0.10656247287988663\n",
            "Batch: 4910 Epoch: 0\n",
            "d_loss: 0.16254193008911955\n",
            "g_loss: 0.10633298009634018\n",
            "Batch: 4911 Epoch: 0\n",
            "d_loss: 0.16254182540781414\n",
            "g_loss: 0.10669112205505371\n",
            "Batch: 4912 Epoch: 0\n",
            "d_loss: 0.16254190393873102\n",
            "g_loss: 0.10619886219501495\n",
            "Batch: 4913 Epoch: 0\n",
            "d_loss: 0.16254182338275314\n",
            "g_loss: 0.10613662004470825\n",
            "Batch: 4914 Epoch: 0\n",
            "d_loss: 0.16254197421778827\n",
            "g_loss: 0.10594604164361954\n",
            "Batch: 4915 Epoch: 0\n",
            "d_loss: 0.16254188659255675\n",
            "g_loss: 0.10636603832244873\n",
            "Batch: 4916 Epoch: 0\n",
            "d_loss: 0.16254168976151817\n",
            "g_loss: 0.10626459121704102\n",
            "Batch: 4917 Epoch: 0\n",
            "d_loss: 0.16254229511203278\n",
            "g_loss: 0.10574033111333847\n",
            "Batch: 4918 Epoch: 0\n",
            "d_loss: 0.16254241573307127\n",
            "g_loss: 0.10634732246398926\n",
            "Batch: 4919 Epoch: 0\n",
            "d_loss: 0.16254179855032191\n",
            "g_loss: 0.10629099607467651\n",
            "Batch: 4920 Epoch: 0\n",
            "d_loss: 0.1625418272249135\n",
            "g_loss: 0.10640034824609756\n",
            "Batch: 4921 Epoch: 0\n",
            "d_loss: 0.1625418040122426\n",
            "g_loss: 0.10664043575525284\n",
            "Batch: 4922 Epoch: 0\n",
            "d_loss: 0.1625416928336776\n",
            "g_loss: 0.10673163086175919\n",
            "Batch: 4923 Epoch: 0\n",
            "d_loss: 0.16254177893006272\n",
            "g_loss: 0.1063193827867508\n",
            "Batch: 4924 Epoch: 0\n",
            "d_loss: 0.16254178223707783\n",
            "g_loss: 0.1062183529138565\n",
            "Batch: 4925 Epoch: 0\n",
            "d_loss: 0.16254188648301948\n",
            "g_loss: 0.10626967251300812\n",
            "Batch: 4926 Epoch: 0\n",
            "d_loss: 0.16254182660560446\n",
            "g_loss: 0.10655803978443146\n",
            "Batch: 4927 Epoch: 0\n",
            "d_loss: 0.16254184067253163\n",
            "g_loss: 0.10652611404657364\n",
            "Batch: 4928 Epoch: 0\n",
            "d_loss: 0.1625417086400276\n",
            "g_loss: 0.10646386444568634\n",
            "Batch: 4929 Epoch: 0\n",
            "d_loss: 0.16254166443523133\n",
            "g_loss: 0.10628006607294083\n",
            "Batch: 4930 Epoch: 0\n",
            "d_loss: 0.16254200447239242\n",
            "g_loss: 0.10718788206577301\n",
            "Batch: 4931 Epoch: 0\n",
            "d_loss: 0.16254196147913547\n",
            "g_loss: 0.10631600767374039\n",
            "Batch: 4932 Epoch: 0\n",
            "d_loss: 0.162541736468242\n",
            "g_loss: 0.10642793029546738\n",
            "Batch: 4933 Epoch: 0\n",
            "d_loss: 0.16254176682605248\n",
            "g_loss: 0.10634265840053558\n",
            "Batch: 4934 Epoch: 0\n",
            "d_loss: 0.16254182541882756\n",
            "g_loss: 0.10646767914295197\n",
            "Batch: 4935 Epoch: 0\n",
            "d_loss: 0.16254170680341673\n",
            "g_loss: 0.1068047508597374\n",
            "Batch: 4936 Epoch: 0\n",
            "d_loss: 0.1625418700446417\n",
            "g_loss: 0.10668770223855972\n",
            "Batch: 4937 Epoch: 0\n",
            "d_loss: 0.1625421415708388\n",
            "g_loss: 0.10650146007537842\n",
            "Batch: 4938 Epoch: 0\n",
            "d_loss: 0.16254172263784028\n",
            "g_loss: 0.10639860481023788\n",
            "Batch: 4939 Epoch: 0\n",
            "d_loss: 0.16254224332177358\n",
            "g_loss: 0.10708688199520111\n",
            "Batch: 4940 Epoch: 0\n",
            "d_loss: 0.16254208378127544\n",
            "g_loss: 0.10642258822917938\n",
            "Batch: 4941 Epoch: 0\n",
            "d_loss: 0.16254185348058314\n",
            "g_loss: 0.10663728415966034\n",
            "Batch: 4942 Epoch: 0\n",
            "d_loss: 0.1625420130534252\n",
            "g_loss: 0.10728861391544342\n",
            "Batch: 4943 Epoch: 0\n",
            "d_loss: 0.162541735345485\n",
            "g_loss: 0.10691872984170914\n",
            "Batch: 4944 Epoch: 0\n",
            "d_loss: 0.16254200055414003\n",
            "g_loss: 0.10651975870132446\n",
            "Batch: 4945 Epoch: 0\n",
            "d_loss: 0.16254211935529383\n",
            "g_loss: 0.10708175599575043\n",
            "Batch: 4946 Epoch: 0\n",
            "d_loss: 0.16254177801172176\n",
            "g_loss: 0.10686121135950089\n",
            "Batch: 4947 Epoch: 0\n",
            "d_loss: 0.16254170735561502\n",
            "g_loss: 0.10663402080535889\n",
            "Batch: 4948 Epoch: 0\n",
            "d_loss: 0.16254171156275277\n",
            "g_loss: 0.10679411888122559\n",
            "Batch: 4949 Epoch: 0\n",
            "d_loss: 0.16254170405463952\n",
            "g_loss: 0.10681228339672089\n",
            "Batch: 4950 Epoch: 0\n",
            "d_loss: 0.16254170502774912\n",
            "g_loss: 0.10668565332889557\n",
            "Batch: 4951 Epoch: 0\n",
            "d_loss: 0.16254173557454266\n",
            "g_loss: 0.10652446746826172\n",
            "Batch: 4952 Epoch: 0\n",
            "d_loss: 0.16254201464257534\n",
            "g_loss: 0.1072140708565712\n",
            "Batch: 4953 Epoch: 0\n",
            "d_loss: 0.1625419717769887\n",
            "g_loss: 0.1069306954741478\n",
            "Batch: 4954 Epoch: 0\n",
            "d_loss: 0.16254182596172484\n",
            "g_loss: 0.10659603774547577\n",
            "Batch: 4955 Epoch: 0\n",
            "d_loss: 0.1625420069747392\n",
            "g_loss: 0.10673544555902481\n",
            "Batch: 4956 Epoch: 0\n",
            "d_loss: 0.16254173618185774\n",
            "g_loss: 0.1068793311715126\n",
            "Batch: 4957 Epoch: 0\n",
            "d_loss: 0.1625416876795498\n",
            "g_loss: 0.10681666433811188\n",
            "Batch: 4958 Epoch: 0\n",
            "d_loss: 0.16254200869512658\n",
            "g_loss: 0.10662659257650375\n",
            "Batch: 4959 Epoch: 0\n",
            "d_loss: 0.16254170294190828\n",
            "g_loss: 0.10645558685064316\n",
            "Batch: 4960 Epoch: 0\n",
            "d_loss: 0.16254194137868438\n",
            "g_loss: 0.10679157078266144\n",
            "Batch: 4961 Epoch: 0\n",
            "d_loss: 0.16254176460514458\n",
            "g_loss: 0.10706665366888046\n",
            "Batch: 4962 Epoch: 0\n",
            "d_loss: 0.1625418363102682\n",
            "g_loss: 0.10678883641958237\n",
            "Batch: 4963 Epoch: 0\n",
            "d_loss: 0.1625418144206634\n",
            "g_loss: 0.10673670470714569\n",
            "Batch: 4964 Epoch: 0\n",
            "d_loss: 0.16254164309882668\n",
            "g_loss: 0.10682325065135956\n",
            "Batch: 4965 Epoch: 0\n",
            "d_loss: 0.16254201754033204\n",
            "g_loss: 0.10704885423183441\n",
            "Batch: 4966 Epoch: 0\n",
            "d_loss: 0.16254198562175048\n",
            "g_loss: 0.10684958845376968\n",
            "Batch: 4967 Epoch: 0\n",
            "d_loss: 0.162541983535597\n",
            "g_loss: 0.10636122524738312\n",
            "Batch: 4968 Epoch: 0\n",
            "d_loss: 0.1625419547351754\n",
            "g_loss: 0.10669974237680435\n",
            "Batch: 4969 Epoch: 0\n",
            "d_loss: 0.1625417640375204\n",
            "g_loss: 0.10725583881139755\n",
            "Batch: 4970 Epoch: 0\n",
            "d_loss: 0.16254185213695393\n",
            "g_loss: 0.107029989361763\n",
            "Batch: 4971 Epoch: 0\n",
            "d_loss: 0.1625417770254316\n",
            "g_loss: 0.10684551298618317\n",
            "Batch: 4972 Epoch: 0\n",
            "d_loss: 0.16254166210385534\n",
            "g_loss: 0.10676046460866928\n",
            "Batch: 4973 Epoch: 0\n",
            "d_loss: 0.16254165629724326\n",
            "g_loss: 0.10702246427536011\n",
            "Batch: 4974 Epoch: 0\n",
            "d_loss: 0.16254185448737246\n",
            "g_loss: 0.10689890384674072\n",
            "Batch: 4975 Epoch: 0\n",
            "d_loss: 0.16254191304930288\n",
            "g_loss: 0.1071789488196373\n",
            "Batch: 4976 Epoch: 0\n",
            "d_loss: 0.1625417344586353\n",
            "g_loss: 0.10713903605937958\n",
            "Batch: 4977 Epoch: 0\n",
            "d_loss: 0.16254194608598027\n",
            "g_loss: 0.10648179054260254\n",
            "Batch: 4978 Epoch: 0\n",
            "d_loss: 0.1625417513118137\n",
            "g_loss: 0.10663614422082901\n",
            "Batch: 4979 Epoch: 0\n",
            "d_loss: 0.16254164267953541\n",
            "g_loss: 0.10707511007785797\n",
            "Batch: 4980 Epoch: 0\n",
            "d_loss: 0.16254167325693913\n",
            "g_loss: 0.10684110969305038\n",
            "Batch: 4981 Epoch: 0\n",
            "d_loss: 0.16254169029733845\n",
            "g_loss: 0.10682453960180283\n",
            "Batch: 4982 Epoch: 0\n",
            "d_loss: 0.16254176103468865\n",
            "g_loss: 0.10721689462661743\n",
            "Batch: 4983 Epoch: 0\n",
            "d_loss: 0.1625418894587014\n",
            "g_loss: 0.10665497928857803\n",
            "Batch: 4984 Epoch: 0\n",
            "d_loss: 0.1625418509332377\n",
            "g_loss: 0.1069936528801918\n",
            "Batch: 4985 Epoch: 0\n",
            "d_loss: 0.16254178391014307\n",
            "g_loss: 0.10687465965747833\n",
            "Batch: 4986 Epoch: 0\n",
            "d_loss: 0.162541708564369\n",
            "g_loss: 0.10677698999643326\n",
            "Batch: 4987 Epoch: 0\n",
            "d_loss: 0.16254185182498304\n",
            "g_loss: 0.1067168116569519\n",
            "Batch: 4988 Epoch: 0\n",
            "d_loss: 0.16254168460197604\n",
            "g_loss: 0.10683736950159073\n",
            "Batch: 4989 Epoch: 0\n",
            "d_loss: 0.16254175818619387\n",
            "g_loss: 0.10697028785943985\n",
            "Batch: 4990 Epoch: 0\n",
            "d_loss: 0.16254181820467295\n",
            "g_loss: 0.10685696452856064\n",
            "Batch: 4991 Epoch: 0\n",
            "d_loss: 0.16254164001770732\n",
            "g_loss: 0.1067257896065712\n",
            "Batch: 4992 Epoch: 0\n",
            "d_loss: 0.16254174844185343\n",
            "g_loss: 0.10711727291345596\n",
            "Batch: 4993 Epoch: 0\n",
            "d_loss: 0.16254171551202035\n",
            "g_loss: 0.10708679258823395\n",
            "Batch: 4994 Epoch: 0\n",
            "d_loss: 0.16254170300366866\n",
            "g_loss: 0.10719572007656097\n",
            "Batch: 4995 Epoch: 0\n",
            "d_loss: 0.16254181798916534\n",
            "g_loss: 0.1068287342786789\n",
            "Batch: 4996 Epoch: 0\n",
            "d_loss: 0.16254176432786238\n",
            "g_loss: 0.10704829543828964\n",
            "Batch: 4997 Epoch: 0\n",
            "d_loss: 0.16254176159266365\n",
            "g_loss: 0.10685575008392334\n",
            "Batch: 4998 Epoch: 0\n",
            "d_loss: 0.16254164444766417\n",
            "g_loss: 0.10701839625835419\n",
            "Batch: 4999 Epoch: 0\n",
            "d_loss: 0.16254172874454298\n",
            "g_loss: 0.10680381953716278\n",
            "Batch: 5000 Epoch: 0\n",
            "d_loss: 0.16254196829747514\n",
            "g_loss: 0.10738879442214966\n",
            "Batch: 5001 Epoch: 0\n",
            "d_loss: 0.1625422482481227\n",
            "g_loss: 0.10657814890146255\n",
            "Batch: 5002 Epoch: 0\n",
            "d_loss: 0.1625420564020743\n",
            "g_loss: 0.10675527155399323\n",
            "Batch: 5003 Epoch: 0\n",
            "d_loss: 0.16254175951132765\n",
            "g_loss: 0.10696160793304443\n",
            "Batch: 5004 Epoch: 0\n",
            "d_loss: 0.1625422362401423\n",
            "g_loss: 0.1074080690741539\n",
            "Batch: 5005 Epoch: 0\n",
            "d_loss: 0.16254242758227377\n",
            "g_loss: 0.10661660134792328\n",
            "Batch: 5006 Epoch: 0\n",
            "d_loss: 0.1625421945176626\n",
            "g_loss: 0.10656049102544785\n",
            "Batch: 5007 Epoch: 0\n",
            "d_loss: 0.1625421739835815\n",
            "g_loss: 0.10724304616451263\n",
            "Batch: 5008 Epoch: 0\n",
            "d_loss: 0.16254204014258988\n",
            "g_loss: 0.1072138324379921\n",
            "Batch: 5009 Epoch: 0\n",
            "d_loss: 0.16254175785976344\n",
            "g_loss: 0.10666773468255997\n",
            "Batch: 5010 Epoch: 0\n",
            "d_loss: 0.16254238449541702\n",
            "g_loss: 0.10733969509601593\n",
            "Batch: 5011 Epoch: 0\n",
            "d_loss: 0.1625423552296965\n",
            "g_loss: 0.10665395110845566\n",
            "Batch: 5012 Epoch: 0\n",
            "d_loss: 0.16254234126704148\n",
            "g_loss: 0.10698499530553818\n",
            "Batch: 5013 Epoch: 0\n",
            "d_loss: 0.1625417586354132\n",
            "g_loss: 0.10720851272344589\n",
            "Batch: 5014 Epoch: 0\n",
            "d_loss: 0.16254223471614893\n",
            "g_loss: 0.10658702999353409\n",
            "Batch: 5015 Epoch: 0\n",
            "d_loss: 0.16254172618219087\n",
            "g_loss: 0.10659301280975342\n",
            "Batch: 5016 Epoch: 0\n",
            "d_loss: 0.1625419975723048\n",
            "g_loss: 0.10671311616897583\n",
            "Batch: 5017 Epoch: 0\n",
            "d_loss: 0.16254163818492628\n",
            "g_loss: 0.10701406002044678\n",
            "Batch: 5018 Epoch: 0\n",
            "d_loss: 0.16254180832593335\n",
            "g_loss: 0.10723312944173813\n",
            "Batch: 5019 Epoch: 0\n",
            "d_loss: 0.16254169761585047\n",
            "g_loss: 0.10677821934223175\n",
            "Batch: 5020 Epoch: 0\n",
            "d_loss: 0.16254177273854253\n",
            "g_loss: 0.10641364753246307\n",
            "Batch: 5021 Epoch: 0\n",
            "d_loss: 0.16254228218407718\n",
            "g_loss: 0.1073235422372818\n",
            "Batch: 5022 Epoch: 0\n",
            "d_loss: 0.16254218893281092\n",
            "g_loss: 0.10674276202917099\n",
            "Batch: 5023 Epoch: 0\n",
            "d_loss: 0.16254183382933718\n",
            "g_loss: 0.10701262950897217\n",
            "Batch: 5024 Epoch: 0\n",
            "d_loss: 0.16254177244543655\n",
            "g_loss: 0.10709445178508759\n",
            "Batch: 5025 Epoch: 0\n",
            "d_loss: 0.1625416422211856\n",
            "g_loss: 0.10733145475387573\n",
            "Batch: 5026 Epoch: 0\n",
            "d_loss: 0.1625417909008533\n",
            "g_loss: 0.10677915811538696\n",
            "Batch: 5027 Epoch: 0\n",
            "d_loss: 0.16254181709905424\n",
            "g_loss: 0.10718856751918793\n",
            "Batch: 5028 Epoch: 0\n",
            "d_loss: 0.16254190880957964\n",
            "g_loss: 0.1070556491613388\n",
            "Batch: 5029 Epoch: 0\n",
            "d_loss: 0.16254191738073587\n",
            "g_loss: 0.1074666976928711\n",
            "Batch: 5030 Epoch: 0\n",
            "d_loss: 0.16254177622006694\n",
            "g_loss: 0.10711243003606796\n",
            "Batch: 5031 Epoch: 0\n",
            "d_loss: 0.1625418752456227\n",
            "g_loss: 0.10751696676015854\n",
            "Batch: 5032 Epoch: 0\n",
            "d_loss: 0.16254185122967613\n",
            "g_loss: 0.10694591701030731\n",
            "Batch: 5033 Epoch: 0\n",
            "d_loss: 0.16254169906834193\n",
            "g_loss: 0.10711957514286041\n",
            "Batch: 5034 Epoch: 0\n",
            "d_loss: 0.16254164312640285\n",
            "g_loss: 0.1071900874376297\n",
            "Batch: 5035 Epoch: 0\n",
            "d_loss: 0.16254178382932594\n",
            "g_loss: 0.10751621425151825\n",
            "Batch: 5036 Epoch: 0\n",
            "d_loss: 0.16254184317506315\n",
            "g_loss: 0.10732551664113998\n",
            "Batch: 5037 Epoch: 0\n",
            "d_loss: 0.16254169106319694\n",
            "g_loss: 0.10704968869686127\n",
            "Batch: 5038 Epoch: 0\n",
            "d_loss: 0.16254211680610808\n",
            "g_loss: 0.10767750442028046\n",
            "Batch: 5039 Epoch: 0\n",
            "d_loss: 0.16254175320396058\n",
            "g_loss: 0.10806766897439957\n",
            "Batch: 5040 Epoch: 0\n",
            "d_loss: 0.16254342671781075\n",
            "g_loss: 0.10661564022302628\n",
            "Batch: 5041 Epoch: 0\n",
            "d_loss: 0.16254312922178826\n",
            "g_loss: 0.10776261985301971\n",
            "Batch: 5042 Epoch: 0\n",
            "d_loss: 0.16254240693454136\n",
            "g_loss: 0.10686276108026505\n",
            "Batch: 5043 Epoch: 0\n",
            "d_loss: 0.1625423976757503\n",
            "g_loss: 0.10763605684041977\n",
            "Batch: 5044 Epoch: 0\n",
            "d_loss: 0.16254199548027515\n",
            "g_loss: 0.10721510648727417\n",
            "Batch: 5045 Epoch: 0\n",
            "d_loss: 0.16254180127505435\n",
            "g_loss: 0.10757344961166382\n",
            "Batch: 5046 Epoch: 0\n",
            "d_loss: 0.1625418153719025\n",
            "g_loss: 0.10737581551074982\n",
            "Batch: 5047 Epoch: 0\n",
            "d_loss: 0.16254178559934473\n",
            "g_loss: 0.10775184631347656\n",
            "Batch: 5048 Epoch: 0\n",
            "d_loss: 0.1625417337947539\n",
            "g_loss: 0.10720065981149673\n",
            "Batch: 5049 Epoch: 0\n",
            "d_loss: 0.16254168276952896\n",
            "g_loss: 0.1070743054151535\n",
            "Batch: 5050 Epoch: 0\n",
            "d_loss: 0.16254181564848835\n",
            "g_loss: 0.10752668231725693\n",
            "Batch: 5051 Epoch: 0\n",
            "d_loss: 0.1625417317910518\n",
            "g_loss: 0.10698463767766953\n",
            "Batch: 5052 Epoch: 0\n",
            "d_loss: 0.16254191944604202\n",
            "g_loss: 0.10786890983581543\n",
            "Batch: 5053 Epoch: 0\n",
            "d_loss: 0.16254205369199326\n",
            "g_loss: 0.10706021636724472\n",
            "Batch: 5054 Epoch: 0\n",
            "d_loss: 0.16254178212618342\n",
            "g_loss: 0.10745115578174591\n",
            "Batch: 5055 Epoch: 0\n",
            "d_loss: 0.16254166534018566\n",
            "g_loss: 0.10735274851322174\n",
            "Batch: 5056 Epoch: 0\n",
            "d_loss: 0.16254202243079874\n",
            "g_loss: 0.10757394134998322\n",
            "Batch: 5057 Epoch: 0\n",
            "d_loss: 0.1625416032187914\n",
            "g_loss: 0.10771051794290543\n",
            "Batch: 5058 Epoch: 0\n",
            "d_loss: 0.16254211321270162\n",
            "g_loss: 0.10703147947788239\n",
            "Batch: 5059 Epoch: 0\n",
            "d_loss: 0.16254175073260058\n",
            "g_loss: 0.10751663148403168\n",
            "Batch: 5060 Epoch: 0\n",
            "d_loss: 0.16254169381617345\n",
            "g_loss: 0.10754956305027008\n",
            "Batch: 5061 Epoch: 0\n",
            "d_loss: 0.1625416817526002\n",
            "g_loss: 0.10743175446987152\n",
            "Batch: 5062 Epoch: 0\n",
            "d_loss: 0.16254163658535248\n",
            "g_loss: 0.10732811689376831\n",
            "Batch: 5063 Epoch: 0\n",
            "d_loss: 0.16254172090141594\n",
            "g_loss: 0.10730216652154922\n",
            "Batch: 5064 Epoch: 0\n",
            "d_loss: 0.16254163265357846\n",
            "g_loss: 0.1073005199432373\n",
            "Batch: 5065 Epoch: 0\n",
            "d_loss: 0.16254172341423612\n",
            "g_loss: 0.10692833364009857\n",
            "Batch: 5066 Epoch: 0\n",
            "d_loss: 0.1625418049193641\n",
            "g_loss: 0.1073206439614296\n",
            "Batch: 5067 Epoch: 0\n",
            "d_loss: 0.1625416955585024\n",
            "g_loss: 0.10712319612503052\n",
            "Batch: 5068 Epoch: 0\n",
            "d_loss: 0.16254184466953348\n",
            "g_loss: 0.10666157305240631\n",
            "Batch: 5069 Epoch: 0\n",
            "d_loss: 0.1625423285366452\n",
            "g_loss: 0.10768727958202362\n",
            "Batch: 5070 Epoch: 0\n",
            "d_loss: 0.16254208246174073\n",
            "g_loss: 0.1072697639465332\n",
            "Batch: 5071 Epoch: 0\n",
            "d_loss: 0.16254168017799486\n",
            "g_loss: 0.10738521814346313\n",
            "Batch: 5072 Epoch: 0\n",
            "d_loss: 0.16254165060810521\n",
            "g_loss: 0.10735750198364258\n",
            "Batch: 5073 Epoch: 0\n",
            "d_loss: 0.1625416932226571\n",
            "g_loss: 0.10756748914718628\n",
            "Batch: 5074 Epoch: 0\n",
            "d_loss: 0.16254204987058074\n",
            "g_loss: 0.10671322047710419\n",
            "Batch: 5075 Epoch: 0\n",
            "d_loss: 0.16254177055066066\n",
            "g_loss: 0.10699792206287384\n",
            "Batch: 5076 Epoch: 0\n",
            "d_loss: 0.16254197600822096\n",
            "g_loss: 0.10756399482488632\n",
            "Batch: 5077 Epoch: 0\n",
            "d_loss: 0.16254190090180032\n",
            "g_loss: 0.1071440577507019\n",
            "Batch: 5078 Epoch: 0\n",
            "d_loss: 0.1625416941718214\n",
            "g_loss: 0.10728578269481659\n",
            "Batch: 5079 Epoch: 0\n",
            "d_loss: 0.16254174501207075\n",
            "g_loss: 0.10739278793334961\n",
            "Batch: 5080 Epoch: 0\n",
            "d_loss: 0.16254163377777786\n",
            "g_loss: 0.10727711021900177\n",
            "Batch: 5081 Epoch: 0\n",
            "d_loss: 0.16254183404493006\n",
            "g_loss: 0.10745222866535187\n",
            "Batch: 5082 Epoch: 0\n",
            "d_loss: 0.1625416807014517\n",
            "g_loss: 0.10706549882888794\n",
            "Batch: 5083 Epoch: 0\n",
            "d_loss: 0.16254193700397224\n",
            "g_loss: 0.10642595589160919\n",
            "Batch: 5084 Epoch: 0\n",
            "d_loss: 0.16254257401807592\n",
            "g_loss: 0.10767227411270142\n",
            "Batch: 5085 Epoch: 0\n",
            "d_loss: 0.16254204028133756\n",
            "g_loss: 0.10700104385614395\n",
            "Batch: 5086 Epoch: 0\n",
            "d_loss: 0.16254166873503806\n",
            "g_loss: 0.10672836005687714\n",
            "Batch: 5087 Epoch: 0\n",
            "d_loss: 0.1625417268965279\n",
            "g_loss: 0.10701058059930801\n",
            "Batch: 5088 Epoch: 0\n",
            "d_loss: 0.1625417558400386\n",
            "g_loss: 0.10698449611663818\n",
            "Batch: 5089 Epoch: 0\n",
            "d_loss: 0.16254160054539568\n",
            "g_loss: 0.10697729885578156\n",
            "Batch: 5090 Epoch: 0\n",
            "d_loss: 0.16254170701190418\n",
            "g_loss: 0.10707256942987442\n",
            "Batch: 5091 Epoch: 0\n",
            "d_loss: 0.1625416327613891\n",
            "g_loss: 0.10697325319051743\n",
            "Batch: 5092 Epoch: 0\n",
            "d_loss: 0.1625416464598075\n",
            "g_loss: 0.10680460929870605\n",
            "Batch: 5093 Epoch: 0\n",
            "d_loss: 0.16254169489197068\n",
            "g_loss: 0.10709431022405624\n",
            "Batch: 5094 Epoch: 0\n",
            "d_loss: 0.16254169759039172\n",
            "g_loss: 0.1069067120552063\n",
            "Batch: 5095 Epoch: 0\n",
            "d_loss: 0.1625416910754396\n",
            "g_loss: 0.1069943904876709\n",
            "Batch: 5096 Epoch: 0\n",
            "d_loss: 0.16254179815342695\n",
            "g_loss: 0.10733485221862793\n",
            "Batch: 5097 Epoch: 0\n",
            "d_loss: 0.16254181470885953\n",
            "g_loss: 0.10694222152233124\n",
            "Batch: 5098 Epoch: 0\n",
            "d_loss: 0.16254166295760797\n",
            "g_loss: 0.10659144818782806\n",
            "Batch: 5099 Epoch: 0\n",
            "d_loss: 0.16254200618094217\n",
            "g_loss: 0.1073165312409401\n",
            "Batch: 5100 Epoch: 0\n",
            "d_loss: 0.16254185343067462\n",
            "g_loss: 0.10693359375\n",
            "Batch: 5101 Epoch: 0\n",
            "d_loss: 0.16254193241543646\n",
            "g_loss: 0.10744129121303558\n",
            "Batch: 5102 Epoch: 0\n",
            "d_loss: 0.1625417827365112\n",
            "g_loss: 0.10716092586517334\n",
            "Batch: 5103 Epoch: 0\n",
            "d_loss: 0.1625419375956909\n",
            "g_loss: 0.10680367052555084\n",
            "Batch: 5104 Epoch: 0\n",
            "d_loss: 0.1625422871872999\n",
            "g_loss: 0.1073981299996376\n",
            "Batch: 5105 Epoch: 0\n",
            "d_loss: 0.16254200258430274\n",
            "g_loss: 0.10702043771743774\n",
            "Batch: 5106 Epoch: 0\n",
            "d_loss: 0.16254175237823176\n",
            "g_loss: 0.10672803223133087\n",
            "Batch: 5107 Epoch: 0\n",
            "d_loss: 0.16254181242962318\n",
            "g_loss: 0.10665051639080048\n",
            "Batch: 5108 Epoch: 0\n",
            "d_loss: 0.16254187165827716\n",
            "g_loss: 0.1070951372385025\n",
            "Batch: 5109 Epoch: 0\n",
            "d_loss: 0.1625420649956908\n",
            "g_loss: 0.1066783219575882\n",
            "Batch: 5110 Epoch: 0\n",
            "d_loss: 0.16254198888838545\n",
            "g_loss: 0.10718097537755966\n",
            "Batch: 5111 Epoch: 0\n",
            "d_loss: 0.16254169338019864\n",
            "g_loss: 0.10723558813333511\n",
            "Batch: 5112 Epoch: 0\n",
            "d_loss: 0.16254203378235843\n",
            "g_loss: 0.10621573776006699\n",
            "Batch: 5113 Epoch: 0\n",
            "d_loss: 0.1625424080962503\n",
            "g_loss: 0.10727360099554062\n",
            "Batch: 5114 Epoch: 0\n",
            "d_loss: 0.1625417495941619\n",
            "g_loss: 0.10761229693889618\n",
            "Batch: 5115 Epoch: 0\n",
            "d_loss: 0.162541867923089\n",
            "g_loss: 0.10715807974338531\n",
            "Batch: 5116 Epoch: 0\n",
            "d_loss: 0.1625416945323792\n",
            "g_loss: 0.10666420310735703\n",
            "Batch: 5117 Epoch: 0\n",
            "d_loss: 0.16254185512488561\n",
            "g_loss: 0.10722517967224121\n",
            "Batch: 5118 Epoch: 0\n",
            "d_loss: 0.16254175021430228\n",
            "g_loss: 0.10697758197784424\n",
            "Batch: 5119 Epoch: 0\n",
            "d_loss: 0.16254177229367173\n",
            "g_loss: 0.10775189101696014\n",
            "Batch: 5120 Epoch: 0\n",
            "d_loss: 0.16254229981829837\n",
            "g_loss: 0.10643734782934189\n",
            "Batch: 5121 Epoch: 0\n",
            "d_loss: 0.16254260118542874\n",
            "g_loss: 0.10732896625995636\n",
            "Batch: 5122 Epoch: 0\n",
            "d_loss: 0.16254203582498405\n",
            "g_loss: 0.10714278370141983\n",
            "Batch: 5123 Epoch: 0\n",
            "d_loss: 0.1625417640428637\n",
            "g_loss: 0.10733968019485474\n",
            "Batch: 5124 Epoch: 0\n",
            "d_loss: 0.1625417494734478\n",
            "g_loss: 0.10690206289291382\n",
            "Batch: 5125 Epoch: 0\n",
            "d_loss: 0.16254168935523694\n",
            "g_loss: 0.10717184841632843\n",
            "Batch: 5126 Epoch: 0\n",
            "d_loss: 0.16254168841633998\n",
            "g_loss: 0.10698749125003815\n",
            "Batch: 5127 Epoch: 0\n",
            "d_loss: 0.16254173292291796\n",
            "g_loss: 0.10717527568340302\n",
            "Batch: 5128 Epoch: 0\n",
            "d_loss: 0.162541851572783\n",
            "g_loss: 0.10691328346729279\n",
            "Batch: 5129 Epoch: 0\n",
            "d_loss: 0.16254180910284788\n",
            "g_loss: 0.10729818046092987\n",
            "Batch: 5130 Epoch: 0\n",
            "d_loss: 0.16254162958382778\n",
            "g_loss: 0.10730987787246704\n",
            "Batch: 5131 Epoch: 0\n",
            "d_loss: 0.16254167635959504\n",
            "g_loss: 0.10719481855630875\n",
            "Batch: 5132 Epoch: 0\n",
            "d_loss: 0.16254166720214158\n",
            "g_loss: 0.10706327110528946\n",
            "Batch: 5133 Epoch: 0\n",
            "d_loss: 0.16254175041564167\n",
            "g_loss: 0.10732923448085785\n",
            "Batch: 5134 Epoch: 0\n",
            "d_loss: 0.1625416896602374\n",
            "g_loss: 0.10707912594079971\n",
            "Batch: 5135 Epoch: 0\n",
            "d_loss: 0.16254165066034432\n",
            "g_loss: 0.10702139139175415\n",
            "Batch: 5136 Epoch: 0\n",
            "d_loss: 0.16254195873075616\n",
            "g_loss: 0.10678748041391373\n",
            "Batch: 5137 Epoch: 0\n",
            "d_loss: 0.16254180605675117\n",
            "g_loss: 0.10734386742115021\n",
            "Batch: 5138 Epoch: 0\n",
            "d_loss: 0.16254172007685241\n",
            "g_loss: 0.10711796581745148\n",
            "Batch: 5139 Epoch: 0\n",
            "d_loss: 0.1625416296113542\n",
            "g_loss: 0.10725414752960205\n",
            "Batch: 5140 Epoch: 0\n",
            "d_loss: 0.1625418387876465\n",
            "g_loss: 0.10730782896280289\n",
            "Batch: 5141 Epoch: 0\n",
            "d_loss: 0.16254176454120284\n",
            "g_loss: 0.10703746229410172\n",
            "Batch: 5142 Epoch: 0\n",
            "d_loss: 0.16254163358279072\n",
            "g_loss: 0.10691136121749878\n",
            "Batch: 5143 Epoch: 0\n",
            "d_loss: 0.16254198613817294\n",
            "g_loss: 0.10740087926387787\n",
            "Batch: 5144 Epoch: 0\n",
            "d_loss: 0.16254188114499613\n",
            "g_loss: 0.10685950517654419\n",
            "Batch: 5145 Epoch: 0\n",
            "d_loss: 0.16254177999225305\n",
            "g_loss: 0.10676666349172592\n",
            "Batch: 5146 Epoch: 0\n",
            "d_loss: 0.1625425225174908\n",
            "g_loss: 0.10771559178829193\n",
            "Batch: 5147 Epoch: 0\n",
            "d_loss: 0.1625417772614952\n",
            "g_loss: 0.1076001301407814\n",
            "Batch: 5148 Epoch: 0\n",
            "d_loss: 0.16254191314443744\n",
            "g_loss: 0.10681827366352081\n",
            "Batch: 5149 Epoch: 0\n",
            "d_loss: 0.16254204755165347\n",
            "g_loss: 0.10749032348394394\n",
            "Batch: 5150 Epoch: 0\n",
            "d_loss: 0.16254197094622214\n",
            "g_loss: 0.1068553775548935\n",
            "Batch: 5151 Epoch: 0\n",
            "d_loss: 0.1625423453510848\n",
            "g_loss: 0.10764580965042114\n",
            "Batch: 5152 Epoch: 0\n",
            "d_loss: 0.16254204609160894\n",
            "g_loss: 0.10701723396778107\n",
            "Batch: 5153 Epoch: 0\n",
            "d_loss: 0.16254169134640506\n",
            "g_loss: 0.10666586458683014\n",
            "Batch: 5154 Epoch: 0\n",
            "d_loss: 0.16254223982157612\n",
            "g_loss: 0.10745410621166229\n",
            "Batch: 5155 Epoch: 0\n",
            "d_loss: 0.16254220832077237\n",
            "g_loss: 0.10686688125133514\n",
            "Batch: 5156 Epoch: 0\n",
            "d_loss: 0.16254168955904902\n",
            "g_loss: 0.10673880577087402\n",
            "Batch: 5157 Epoch: 0\n",
            "d_loss: 0.1625418668799128\n",
            "g_loss: 0.10735833644866943\n",
            "Batch: 5158 Epoch: 0\n",
            "d_loss: 0.16254228539361293\n",
            "g_loss: 0.10636810213327408\n",
            "Batch: 5159 Epoch: 0\n",
            "d_loss: 0.16254325560585414\n",
            "g_loss: 0.10787361860275269\n",
            "Batch: 5160 Epoch: 0\n",
            "d_loss: 0.16254247143335476\n",
            "g_loss: 0.10711636394262314\n",
            "Batch: 5161 Epoch: 0\n",
            "d_loss: 0.16254234593465355\n",
            "g_loss: 0.10691328346729279\n",
            "Batch: 5162 Epoch: 0\n",
            "d_loss: 0.16254208102127166\n",
            "g_loss: 0.10711359977722168\n",
            "Batch: 5163 Epoch: 0\n",
            "d_loss: 0.16254177978787254\n",
            "g_loss: 0.10667940229177475\n",
            "Batch: 5164 Epoch: 0\n",
            "d_loss: 0.16254167507122474\n",
            "g_loss: 0.1064203754067421\n",
            "Batch: 5165 Epoch: 0\n",
            "d_loss: 0.16254203991491067\n",
            "g_loss: 0.10726414620876312\n",
            "Batch: 5166 Epoch: 0\n",
            "d_loss: 0.1625419266973509\n",
            "g_loss: 0.10708983242511749\n",
            "Batch: 5167 Epoch: 0\n",
            "d_loss: 0.1625418245739354\n",
            "g_loss: 0.10687375068664551\n",
            "Batch: 5168 Epoch: 0\n",
            "d_loss: 0.162542016464144\n",
            "g_loss: 0.10743944346904755\n",
            "Batch: 5169 Epoch: 0\n",
            "d_loss: 0.16254270250855285\n",
            "g_loss: 0.106450155377388\n",
            "Batch: 5170 Epoch: 0\n",
            "d_loss: 0.16254314898611\n",
            "g_loss: 0.10767225921154022\n",
            "Batch: 5171 Epoch: 0\n",
            "d_loss: 0.16254189733898272\n",
            "g_loss: 0.1075170636177063\n",
            "Batch: 5172 Epoch: 0\n",
            "d_loss: 0.16254240902710393\n",
            "g_loss: 0.10656851530075073\n",
            "Batch: 5173 Epoch: 0\n",
            "d_loss: 0.16254305875372665\n",
            "g_loss: 0.10794180631637573\n",
            "Batch: 5174 Epoch: 0\n",
            "d_loss: 0.16254318163137071\n",
            "g_loss: 0.1067996472120285\n",
            "Batch: 5175 Epoch: 0\n",
            "d_loss: 0.1625423312650014\n",
            "g_loss: 0.10718017816543579\n",
            "Batch: 5176 Epoch: 0\n",
            "d_loss: 0.1625420341312207\n",
            "g_loss: 0.10753802955150604\n",
            "Batch: 5177 Epoch: 0\n",
            "d_loss: 0.1625419710234084\n",
            "g_loss: 0.1071561947464943\n",
            "Batch: 5178 Epoch: 0\n",
            "d_loss: 0.1625422247904993\n",
            "g_loss: 0.10750750452280045\n",
            "Batch: 5179 Epoch: 0\n",
            "d_loss: 0.16254186625121037\n",
            "g_loss: 0.10694502294063568\n",
            "Batch: 5180 Epoch: 0\n",
            "d_loss: 0.16254194300610436\n",
            "g_loss: 0.10751152038574219\n",
            "Batch: 5181 Epoch: 0\n",
            "d_loss: 0.16254198625548355\n",
            "g_loss: 0.10683965682983398\n",
            "Batch: 5182 Epoch: 0\n",
            "d_loss: 0.1625428810140761\n",
            "g_loss: 0.10795991122722626\n",
            "Batch: 5183 Epoch: 0\n",
            "d_loss: 0.16254317983464261\n",
            "g_loss: 0.10645810514688492\n",
            "Batch: 5184 Epoch: 0\n",
            "d_loss: 0.16254365326629028\n",
            "g_loss: 0.10772880166769028\n",
            "Batch: 5185 Epoch: 0\n",
            "d_loss: 0.16254244045861554\n",
            "g_loss: 0.10696303844451904\n",
            "Batch: 5186 Epoch: 0\n",
            "d_loss: 0.1625417930315507\n",
            "g_loss: 0.1067405715584755\n",
            "Batch: 5187 Epoch: 0\n",
            "d_loss: 0.1625417913921865\n",
            "g_loss: 0.10699982941150665\n",
            "Batch: 5188 Epoch: 0\n",
            "d_loss: 0.16254173420503548\n",
            "g_loss: 0.10734057426452637\n",
            "Batch: 5189 Epoch: 0\n",
            "d_loss: 0.1625418955002118\n",
            "g_loss: 0.10714147239923477\n",
            "Batch: 5190 Epoch: 0\n",
            "d_loss: 0.16254203583021365\n",
            "g_loss: 0.10738740861415863\n",
            "Batch: 5191 Epoch: 0\n",
            "d_loss: 0.16254205226677243\n",
            "g_loss: 0.10664238780736923\n",
            "Batch: 5192 Epoch: 0\n",
            "d_loss: 0.1625422227152029\n",
            "g_loss: 0.10761499404907227\n",
            "Batch: 5193 Epoch: 0\n",
            "d_loss: 0.16254180537722362\n",
            "g_loss: 0.10704197734594345\n",
            "Batch: 5194 Epoch: 0\n",
            "d_loss: 0.16254192549961033\n",
            "g_loss: 0.10644171386957169\n",
            "Batch: 5195 Epoch: 0\n",
            "d_loss: 0.16254311575655578\n",
            "g_loss: 0.10779814422130585\n",
            "Batch: 5196 Epoch: 0\n",
            "d_loss: 0.16254234199728046\n",
            "g_loss: 0.10728269815444946\n",
            "Batch: 5197 Epoch: 0\n",
            "d_loss: 0.1625420295890052\n",
            "g_loss: 0.1063375473022461\n",
            "Batch: 5198 Epoch: 0\n",
            "d_loss: 0.16254319070738177\n",
            "g_loss: 0.10777173936367035\n",
            "Batch: 5199 Epoch: 0\n",
            "d_loss: 0.16254258499672147\n",
            "g_loss: 0.10676015913486481\n",
            "Batch: 5200 Epoch: 0\n",
            "d_loss: 0.16254186722407837\n",
            "g_loss: 0.10647062957286835\n",
            "Batch: 5201 Epoch: 0\n",
            "d_loss: 0.1625419262617669\n",
            "g_loss: 0.10694779455661774\n",
            "Batch: 5202 Epoch: 0\n",
            "d_loss: 0.16254199892621557\n",
            "g_loss: 0.10786113888025284\n",
            "Batch: 5203 Epoch: 0\n",
            "d_loss: 0.1625418795550786\n",
            "g_loss: 0.10745374858379364\n",
            "Batch: 5204 Epoch: 0\n",
            "d_loss: 0.16254235574898956\n",
            "g_loss: 0.10642281919717789\n",
            "Batch: 5205 Epoch: 0\n",
            "d_loss: 0.16254323937251058\n",
            "g_loss: 0.10766434669494629\n",
            "Batch: 5206 Epoch: 0\n",
            "d_loss: 0.16254290898021395\n",
            "g_loss: 0.10636401176452637\n",
            "Batch: 5207 Epoch: 0\n",
            "d_loss: 0.16254279013269013\n",
            "g_loss: 0.107449971139431\n",
            "Batch: 5208 Epoch: 0\n",
            "d_loss: 0.16254204330853383\n",
            "g_loss: 0.10683848708868027\n",
            "Batch: 5209 Epoch: 0\n",
            "d_loss: 0.1625418196879025\n",
            "g_loss: 0.10691312700510025\n",
            "Batch: 5210 Epoch: 0\n",
            "d_loss: 0.16254183539758316\n",
            "g_loss: 0.10742173343896866\n",
            "Batch: 5211 Epoch: 0\n",
            "d_loss: 0.16254208627187694\n",
            "g_loss: 0.10652045905590057\n",
            "Batch: 5212 Epoch: 0\n",
            "d_loss: 0.1625420153637691\n",
            "g_loss: 0.1069352775812149\n",
            "Batch: 5213 Epoch: 0\n",
            "d_loss: 0.16254168551464687\n",
            "g_loss: 0.10686786472797394\n",
            "Batch: 5214 Epoch: 0\n",
            "d_loss: 0.16254195229031865\n",
            "g_loss: 0.10743796825408936\n",
            "Batch: 5215 Epoch: 0\n",
            "d_loss: 0.16254178962221033\n",
            "g_loss: 0.10679425299167633\n",
            "Batch: 5216 Epoch: 0\n",
            "d_loss: 0.16254182522167326\n",
            "g_loss: 0.10731501877307892\n",
            "Batch: 5217 Epoch: 0\n",
            "d_loss: 0.16254186664641423\n",
            "g_loss: 0.10681909322738647\n",
            "Batch: 5218 Epoch: 0\n",
            "d_loss: 0.16254177936449565\n",
            "g_loss: 0.1073051244020462\n",
            "Batch: 5219 Epoch: 0\n",
            "d_loss: 0.1625416718262258\n",
            "g_loss: 0.10714831203222275\n",
            "Batch: 5220 Epoch: 0\n",
            "d_loss: 0.16254173153861018\n",
            "g_loss: 0.1068650335073471\n",
            "Batch: 5221 Epoch: 0\n",
            "d_loss: 0.16254180973460564\n",
            "g_loss: 0.1072862520813942\n",
            "Batch: 5222 Epoch: 0\n",
            "d_loss: 0.16254228261733772\n",
            "g_loss: 0.10632570087909698\n",
            "Batch: 5223 Epoch: 0\n",
            "d_loss: 0.16254295213927605\n",
            "g_loss: 0.10795214027166367\n",
            "Batch: 5224 Epoch: 0\n",
            "d_loss: 0.16254247600708993\n",
            "g_loss: 0.10727812349796295\n",
            "Batch: 5225 Epoch: 0\n",
            "d_loss: 0.16254171271793894\n",
            "g_loss: 0.10743937641382217\n",
            "Batch: 5226 Epoch: 0\n",
            "d_loss: 0.16254201299812365\n",
            "g_loss: 0.10681086778640747\n",
            "Batch: 5227 Epoch: 0\n",
            "d_loss: 0.16254207798208853\n",
            "g_loss: 0.1076866164803505\n",
            "Batch: 5228 Epoch: 0\n",
            "d_loss: 0.16254207334409188\n",
            "g_loss: 0.10698375850915909\n",
            "Batch: 5229 Epoch: 0\n",
            "d_loss: 0.16254168592521268\n",
            "g_loss: 0.1071929931640625\n",
            "Batch: 5230 Epoch: 0\n",
            "d_loss: 0.16254167130792752\n",
            "g_loss: 0.10749558359384537\n",
            "Batch: 5231 Epoch: 0\n",
            "d_loss: 0.16254192482539054\n",
            "g_loss: 0.1068437248468399\n",
            "Batch: 5232 Epoch: 0\n",
            "d_loss: 0.16254195449684516\n",
            "g_loss: 0.10708141326904297\n",
            "Batch: 5233 Epoch: 0\n",
            "d_loss: 0.16254171053501665\n",
            "g_loss: 0.10719496011734009\n",
            "Batch: 5234 Epoch: 0\n",
            "d_loss: 0.16254165996348036\n",
            "g_loss: 0.10699008405208588\n",
            "Batch: 5235 Epoch: 0\n",
            "d_loss: 0.16254188449942575\n",
            "g_loss: 0.10761050134897232\n",
            "Batch: 5236 Epoch: 0\n",
            "d_loss: 0.16254219249394453\n",
            "g_loss: 0.10660676658153534\n",
            "Batch: 5237 Epoch: 0\n",
            "d_loss: 0.1625424181769759\n",
            "g_loss: 0.10759977996349335\n",
            "Batch: 5238 Epoch: 0\n",
            "d_loss: 0.16254216223212836\n",
            "g_loss: 0.10673846304416656\n",
            "Batch: 5239 Epoch: 0\n",
            "d_loss: 0.1625418653167756\n",
            "g_loss: 0.10682167857885361\n",
            "Batch: 5240 Epoch: 0\n",
            "d_loss: 0.162541716237115\n",
            "g_loss: 0.10692622512578964\n",
            "Batch: 5241 Epoch: 0\n",
            "d_loss: 0.162541803143597\n",
            "g_loss: 0.10706070810556412\n",
            "Batch: 5242 Epoch: 0\n",
            "d_loss: 0.16254178665128904\n",
            "g_loss: 0.10685370862483978\n",
            "Batch: 5243 Epoch: 0\n",
            "d_loss: 0.1625416412806402\n",
            "g_loss: 0.10676848888397217\n",
            "Batch: 5244 Epoch: 0\n",
            "d_loss: 0.162541849247269\n",
            "g_loss: 0.10729143768548965\n",
            "Batch: 5245 Epoch: 0\n",
            "d_loss: 0.16254192305063953\n",
            "g_loss: 0.10674138367176056\n",
            "Batch: 5246 Epoch: 0\n",
            "d_loss: 0.16254201130153945\n",
            "g_loss: 0.10726821422576904\n",
            "Batch: 5247 Epoch: 0\n",
            "d_loss: 0.16254219313039897\n",
            "g_loss: 0.10688313096761703\n",
            "Batch: 5248 Epoch: 0\n",
            "d_loss: 0.1625418038703259\n",
            "g_loss: 0.10726208984851837\n",
            "Batch: 5249 Epoch: 0\n",
            "d_loss: 0.16254171319559418\n",
            "g_loss: 0.1068003922700882\n",
            "Batch: 5250 Epoch: 0\n",
            "d_loss: 0.16254213722468336\n",
            "g_loss: 0.10757754743099213\n",
            "Batch: 5251 Epoch: 0\n",
            "d_loss: 0.1625420425836097\n",
            "g_loss: 0.10645446926355362\n",
            "Batch: 5252 Epoch: 0\n",
            "d_loss: 0.16254189262385665\n",
            "g_loss: 0.10695304721593857\n",
            "Batch: 5253 Epoch: 0\n",
            "d_loss: 0.16254186239824264\n",
            "g_loss: 0.10771197080612183\n",
            "Batch: 5254 Epoch: 0\n",
            "d_loss: 0.1625421631559547\n",
            "g_loss: 0.10673830658197403\n",
            "Batch: 5255 Epoch: 0\n",
            "d_loss: 0.1625419233798766\n",
            "g_loss: 0.10736719518899918\n",
            "Batch: 5256 Epoch: 0\n",
            "d_loss: 0.1625419220249782\n",
            "g_loss: 0.10716907680034637\n",
            "Batch: 5257 Epoch: 0\n",
            "d_loss: 0.1625417465800183\n",
            "g_loss: 0.10710708051919937\n",
            "Batch: 5258 Epoch: 0\n",
            "d_loss: 0.16254168325628626\n",
            "g_loss: 0.10702340304851532\n",
            "Batch: 5259 Epoch: 0\n",
            "d_loss: 0.16254174508311792\n",
            "g_loss: 0.10690667480230331\n",
            "Batch: 5260 Epoch: 0\n",
            "d_loss: 0.16254173002660366\n",
            "g_loss: 0.10717091709375381\n",
            "Batch: 5261 Epoch: 0\n",
            "d_loss: 0.1625416827217947\n",
            "g_loss: 0.1069088727235794\n",
            "Batch: 5262 Epoch: 0\n",
            "d_loss: 0.16254178634925864\n",
            "g_loss: 0.10733342170715332\n",
            "Batch: 5263 Epoch: 0\n",
            "d_loss: 0.1625422207821572\n",
            "g_loss: 0.10648323595523834\n",
            "Batch: 5264 Epoch: 0\n",
            "d_loss: 0.16254217817745342\n",
            "g_loss: 0.10738261044025421\n",
            "Batch: 5265 Epoch: 0\n",
            "d_loss: 0.16254187797788688\n",
            "g_loss: 0.10683266818523407\n",
            "Batch: 5266 Epoch: 0\n",
            "d_loss: 0.16254166830983507\n",
            "g_loss: 0.10660374164581299\n",
            "Batch: 5267 Epoch: 0\n",
            "d_loss: 0.1625418312448872\n",
            "g_loss: 0.10710422694683075\n",
            "Batch: 5268 Epoch: 0\n",
            "d_loss: 0.1625416544429399\n",
            "g_loss: 0.10694883018732071\n",
            "Batch: 5269 Epoch: 0\n",
            "d_loss: 0.16254174244885178\n",
            "g_loss: 0.10721573978662491\n",
            "Batch: 5270 Epoch: 0\n",
            "d_loss: 0.16254233988970412\n",
            "g_loss: 0.10631054639816284\n",
            "Batch: 5271 Epoch: 0\n",
            "d_loss: 0.16254281660961567\n",
            "g_loss: 0.10736161470413208\n",
            "Batch: 5272 Epoch: 0\n",
            "d_loss: 0.16254207047533242\n",
            "g_loss: 0.107136070728302\n",
            "Batch: 5273 Epoch: 0\n",
            "d_loss: 0.16254165330142456\n",
            "g_loss: 0.10717198997735977\n",
            "Batch: 5274 Epoch: 0\n",
            "d_loss: 0.16254174120914655\n",
            "g_loss: 0.1072927713394165\n",
            "Batch: 5275 Epoch: 0\n",
            "d_loss: 0.16254175785822156\n",
            "g_loss: 0.10694818198680878\n",
            "Batch: 5276 Epoch: 0\n",
            "d_loss: 0.16254166898640676\n",
            "g_loss: 0.10667556524276733\n",
            "Batch: 5277 Epoch: 0\n",
            "d_loss: 0.16254178803681896\n",
            "g_loss: 0.10686514526605606\n",
            "Batch: 5278 Epoch: 0\n",
            "d_loss: 0.16254175757174494\n",
            "g_loss: 0.10729316622018814\n",
            "Batch: 5279 Epoch: 0\n",
            "d_loss: 0.1625416799167141\n",
            "g_loss: 0.10772989690303802\n",
            "Batch: 5280 Epoch: 0\n",
            "d_loss: 0.16254245761357566\n",
            "g_loss: 0.10666687786579132\n",
            "Batch: 5281 Epoch: 0\n",
            "d_loss: 0.16254187715163937\n",
            "g_loss: 0.1069965586066246\n",
            "Batch: 5282 Epoch: 0\n",
            "d_loss: 0.1625418600932491\n",
            "g_loss: 0.10716024786233902\n",
            "Batch: 5283 Epoch: 0\n",
            "d_loss: 0.1625419270584274\n",
            "g_loss: 0.10739614069461823\n",
            "Batch: 5284 Epoch: 0\n",
            "d_loss: 0.16254211275802533\n",
            "g_loss: 0.10643094778060913\n",
            "Batch: 5285 Epoch: 0\n",
            "d_loss: 0.16254183022298463\n",
            "g_loss: 0.10695646703243256\n",
            "Batch: 5286 Epoch: 0\n",
            "d_loss: 0.162542029137839\n",
            "g_loss: 0.10622859001159668\n",
            "Batch: 5287 Epoch: 0\n",
            "d_loss: 0.16254214531147682\n",
            "g_loss: 0.10684635490179062\n",
            "Batch: 5288 Epoch: 0\n",
            "d_loss: 0.16254178919010798\n",
            "g_loss: 0.10696391761302948\n",
            "Batch: 5289 Epoch: 0\n",
            "d_loss: 0.1625416821141883\n",
            "g_loss: 0.10686849057674408\n",
            "Batch: 5290 Epoch: 0\n",
            "d_loss: 0.16254166805085646\n",
            "g_loss: 0.10688422620296478\n",
            "Batch: 5291 Epoch: 0\n",
            "d_loss: 0.16254183134343236\n",
            "g_loss: 0.10718109458684921\n",
            "Batch: 5292 Epoch: 0\n",
            "d_loss: 0.1625421764860988\n",
            "g_loss: 0.10615180432796478\n",
            "Batch: 5293 Epoch: 0\n",
            "d_loss: 0.1625424556977748\n",
            "g_loss: 0.10753043740987778\n",
            "Batch: 5294 Epoch: 0\n",
            "d_loss: 0.16254186540821536\n",
            "g_loss: 0.1072610393166542\n",
            "Batch: 5295 Epoch: 0\n",
            "d_loss: 0.16254193789486493\n",
            "g_loss: 0.10657201707363129\n",
            "Batch: 5296 Epoch: 0\n",
            "d_loss: 0.1625417397604565\n",
            "g_loss: 0.10686210542917252\n",
            "Batch: 5297 Epoch: 0\n",
            "d_loss: 0.1625417407807177\n",
            "g_loss: 0.10722881555557251\n",
            "Batch: 5298 Epoch: 0\n",
            "d_loss: 0.16254203894398245\n",
            "g_loss: 0.10665921121835709\n",
            "Batch: 5299 Epoch: 0\n",
            "d_loss: 0.1625421858289755\n",
            "g_loss: 0.10770247131586075\n",
            "Batch: 5300 Epoch: 0\n",
            "d_loss: 0.16254250000362447\n",
            "g_loss: 0.10664510726928711\n",
            "Batch: 5301 Epoch: 0\n",
            "d_loss: 0.16254212771265486\n",
            "g_loss: 0.10726259648799896\n",
            "Batch: 5302 Epoch: 0\n",
            "d_loss: 0.16254179915262057\n",
            "g_loss: 0.10727302730083466\n",
            "Batch: 5303 Epoch: 0\n",
            "d_loss: 0.16254186129103232\n",
            "g_loss: 0.10714907944202423\n",
            "Batch: 5304 Epoch: 0\n",
            "d_loss: 0.1625416961158166\n",
            "g_loss: 0.10741619020700455\n",
            "Batch: 5305 Epoch: 0\n",
            "d_loss: 0.1625420601734504\n",
            "g_loss: 0.10703352838754654\n",
            "Batch: 5306 Epoch: 0\n",
            "d_loss: 0.16254215803603245\n",
            "g_loss: 0.10798501968383789\n",
            "Batch: 5307 Epoch: 0\n",
            "d_loss: 0.16254263726759177\n",
            "g_loss: 0.10651373863220215\n",
            "Batch: 5308 Epoch: 0\n",
            "d_loss: 0.1625420983681778\n",
            "g_loss: 0.10695818811655045\n",
            "Batch: 5309 Epoch: 0\n",
            "d_loss: 0.1625417122793209\n",
            "g_loss: 0.10735134035348892\n",
            "Batch: 5310 Epoch: 0\n",
            "d_loss: 0.16254209881311965\n",
            "g_loss: 0.10747501999139786\n",
            "Batch: 5311 Epoch: 0\n",
            "d_loss: 0.16254175478254496\n",
            "g_loss: 0.10699893534183502\n",
            "Batch: 5312 Epoch: 0\n",
            "d_loss: 0.1625418885997547\n",
            "g_loss: 0.10764922201633453\n",
            "Batch: 5313 Epoch: 0\n",
            "d_loss: 0.1625417266513267\n",
            "g_loss: 0.10735287517309189\n",
            "Batch: 5314 Epoch: 0\n",
            "d_loss: 0.16254179896608179\n",
            "g_loss: 0.10719247907400131\n",
            "Batch: 5315 Epoch: 0\n",
            "d_loss: 0.16254164888881206\n",
            "g_loss: 0.10727562755346298\n",
            "Batch: 5316 Epoch: 0\n",
            "d_loss: 0.1625416801413877\n",
            "g_loss: 0.10723211616277695\n",
            "Batch: 5317 Epoch: 0\n",
            "d_loss: 0.1625417900327335\n",
            "g_loss: 0.1068962961435318\n",
            "Batch: 5318 Epoch: 0\n",
            "d_loss: 0.16254179852445816\n",
            "g_loss: 0.10731148719787598\n",
            "Batch: 5319 Epoch: 0\n",
            "d_loss: 0.16254179826977122\n",
            "g_loss: 0.10748624801635742\n",
            "Batch: 5320 Epoch: 0\n",
            "d_loss: 0.16254205381481768\n",
            "g_loss: 0.1068090945482254\n",
            "Batch: 5321 Epoch: 0\n",
            "d_loss: 0.16254249905166773\n",
            "g_loss: 0.10735048353672028\n",
            "Batch: 5322 Epoch: 0\n",
            "d_loss: 0.1625417580918338\n",
            "g_loss: 0.10754504054784775\n",
            "Batch: 5323 Epoch: 0\n",
            "d_loss: 0.1625419925253695\n",
            "g_loss: 0.10684527456760406\n",
            "Batch: 5324 Epoch: 0\n",
            "d_loss: 0.16254178334008174\n",
            "g_loss: 0.10725732892751694\n",
            "Batch: 5325 Epoch: 0\n",
            "d_loss: 0.16254203596948003\n",
            "g_loss: 0.10663668066263199\n",
            "Batch: 5326 Epoch: 0\n",
            "d_loss: 0.1625426637244729\n",
            "g_loss: 0.10784927755594254\n",
            "Batch: 5327 Epoch: 0\n",
            "d_loss: 0.16254262283025156\n",
            "g_loss: 0.10648483037948608\n",
            "Batch: 5328 Epoch: 0\n",
            "d_loss: 0.1625422320977492\n",
            "g_loss: 0.10720326751470566\n",
            "Batch: 5329 Epoch: 0\n",
            "d_loss: 0.16254191706222798\n",
            "g_loss: 0.10661637783050537\n",
            "Batch: 5330 Epoch: 0\n",
            "d_loss: 0.16254194704794145\n",
            "g_loss: 0.1067851185798645\n",
            "Batch: 5331 Epoch: 0\n",
            "d_loss: 0.16254230395347946\n",
            "g_loss: 0.10784704983234406\n",
            "Batch: 5332 Epoch: 0\n",
            "d_loss: 0.16254218255498643\n",
            "g_loss: 0.1071576252579689\n",
            "Batch: 5333 Epoch: 0\n",
            "d_loss: 0.16254213069743884\n",
            "g_loss: 0.10644839704036713\n",
            "Batch: 5334 Epoch: 0\n",
            "d_loss: 0.16254453855344764\n",
            "g_loss: 0.1090896874666214\n",
            "Batch: 5335 Epoch: 0\n",
            "d_loss: 0.16254620452893676\n",
            "g_loss: 0.1062997430562973\n",
            "Batch: 5336 Epoch: 0\n",
            "d_loss: 0.16254326001811847\n",
            "g_loss: 0.10737790912389755\n",
            "Batch: 5337 Epoch: 0\n",
            "d_loss: 0.16254230342838127\n",
            "g_loss: 0.1078103557229042\n",
            "Batch: 5338 Epoch: 0\n",
            "d_loss: 0.16254303533420256\n",
            "g_loss: 0.10647889226675034\n",
            "Batch: 5339 Epoch: 0\n",
            "d_loss: 0.16254230525758118\n",
            "g_loss: 0.1060776337981224\n",
            "Batch: 5340 Epoch: 0\n",
            "d_loss: 0.16254316767943777\n",
            "g_loss: 0.10793628543615341\n",
            "Batch: 5341 Epoch: 0\n",
            "d_loss: 0.16254375770743223\n",
            "g_loss: 0.10597740113735199\n",
            "Batch: 5342 Epoch: 0\n",
            "d_loss: 0.16254364676282762\n",
            "g_loss: 0.10790228843688965\n",
            "Batch: 5343 Epoch: 0\n",
            "d_loss: 0.16254270836244444\n",
            "g_loss: 0.10684913396835327\n",
            "Batch: 5344 Epoch: 0\n",
            "d_loss: 0.16254197503943857\n",
            "g_loss: 0.10730345547199249\n",
            "Batch: 5345 Epoch: 0\n",
            "d_loss: 0.16254191720950928\n",
            "g_loss: 0.10670294612646103\n",
            "Batch: 5346 Epoch: 0\n",
            "d_loss: 0.16254173605334188\n",
            "g_loss: 0.10697142034769058\n",
            "Batch: 5347 Epoch: 0\n",
            "d_loss: 0.1625417638344402\n",
            "g_loss: 0.10687895864248276\n",
            "Batch: 5348 Epoch: 0\n",
            "d_loss: 0.16254178166004607\n",
            "g_loss: 0.10715963691473007\n",
            "Batch: 5349 Epoch: 0\n",
            "d_loss: 0.16254182514074245\n",
            "g_loss: 0.10718132555484772\n",
            "Batch: 5350 Epoch: 0\n",
            "d_loss: 0.1625417659413415\n",
            "g_loss: 0.10712222754955292\n",
            "Batch: 5351 Epoch: 0\n",
            "d_loss: 0.1625416917527076\n",
            "g_loss: 0.10747377574443817\n",
            "Batch: 5352 Epoch: 0\n",
            "d_loss: 0.16254210935098712\n",
            "g_loss: 0.10661132633686066\n",
            "Batch: 5353 Epoch: 0\n",
            "d_loss: 0.1625419758748663\n",
            "g_loss: 0.10716183483600616\n",
            "Batch: 5354 Epoch: 0\n",
            "d_loss: 0.16254186127420667\n",
            "g_loss: 0.10683058202266693\n",
            "Batch: 5355 Epoch: 0\n",
            "d_loss: 0.1625418247305177\n",
            "g_loss: 0.10696627199649811\n",
            "Batch: 5356 Epoch: 0\n",
            "d_loss: 0.16254167663154107\n",
            "g_loss: 0.10710889101028442\n",
            "Batch: 5357 Epoch: 0\n",
            "d_loss: 0.1625418695111307\n",
            "g_loss: 0.10768290609121323\n",
            "Batch: 5358 Epoch: 0\n",
            "d_loss: 0.1625418564568477\n",
            "g_loss: 0.10721349716186523\n",
            "Batch: 5359 Epoch: 0\n",
            "d_loss: 0.16254167636653705\n",
            "g_loss: 0.10684487968683243\n",
            "Batch: 5360 Epoch: 0\n",
            "d_loss: 0.1625418098953233\n",
            "g_loss: 0.1071721538901329\n",
            "Batch: 5361 Epoch: 0\n",
            "d_loss: 0.16254173579470432\n",
            "g_loss: 0.10719870030879974\n",
            "Batch: 5362 Epoch: 0\n",
            "d_loss: 0.1625417027841891\n",
            "g_loss: 0.10690927505493164\n",
            "Batch: 5363 Epoch: 0\n",
            "d_loss: 0.16254166693713756\n",
            "g_loss: 0.1068706139922142\n",
            "Batch: 5364 Epoch: 0\n",
            "d_loss: 0.16254192147484758\n",
            "g_loss: 0.1076250672340393\n",
            "Batch: 5365 Epoch: 0\n",
            "d_loss: 0.16254211071090197\n",
            "g_loss: 0.10667024552822113\n",
            "Batch: 5366 Epoch: 0\n",
            "d_loss: 0.1625417658005901\n",
            "g_loss: 0.10692699998617172\n",
            "Batch: 5367 Epoch: 0\n",
            "d_loss: 0.16254194501167518\n",
            "g_loss: 0.10643372684717178\n",
            "Batch: 5368 Epoch: 0\n",
            "d_loss: 0.16254269096437923\n",
            "g_loss: 0.10786934942007065\n",
            "Batch: 5369 Epoch: 0\n",
            "d_loss: 0.16254289858948567\n",
            "g_loss: 0.10649879276752472\n",
            "Batch: 5370 Epoch: 0\n",
            "d_loss: 0.16254285701609206\n",
            "g_loss: 0.10781741142272949\n",
            "Batch: 5371 Epoch: 0\n",
            "d_loss: 0.1625429887071732\n",
            "g_loss: 0.10639913380146027\n",
            "Batch: 5372 Epoch: 0\n",
            "d_loss: 0.1625435827021562\n",
            "g_loss: 0.10855019092559814\n",
            "Batch: 5373 Epoch: 0\n",
            "d_loss: 0.1625442540886155\n",
            "g_loss: 0.10662305355072021\n",
            "Batch: 5374 Epoch: 0\n",
            "d_loss: 0.16254270431470985\n",
            "g_loss: 0.10763359069824219\n",
            "Batch: 5375 Epoch: 0\n",
            "d_loss: 0.16254370206475954\n",
            "g_loss: 0.10843195021152496\n",
            "Batch: 5376 Epoch: 0\n",
            "d_loss: 0.16254222588779754\n",
            "g_loss: 0.10740077495574951\n",
            "Batch: 5377 Epoch: 0\n",
            "d_loss: 0.16254197405977777\n",
            "g_loss: 0.10735931247472763\n",
            "Batch: 5378 Epoch: 0\n",
            "d_loss: 0.16254227187637582\n",
            "g_loss: 0.10732857882976532\n",
            "Batch: 5379 Epoch: 0\n",
            "d_loss: 0.16254166138237736\n",
            "g_loss: 0.10734240710735321\n",
            "Batch: 5380 Epoch: 0\n",
            "d_loss: 0.16254191409974794\n",
            "g_loss: 0.10774107277393341\n",
            "Batch: 5381 Epoch: 0\n",
            "d_loss: 0.16254213774352877\n",
            "g_loss: 0.10670449584722519\n",
            "Batch: 5382 Epoch: 0\n",
            "d_loss: 0.16254228857315667\n",
            "g_loss: 0.10775084793567657\n",
            "Batch: 5383 Epoch: 0\n",
            "d_loss: 0.1625419736101037\n",
            "g_loss: 0.10718051344156265\n",
            "Batch: 5384 Epoch: 0\n",
            "d_loss: 0.16254167524630247\n",
            "g_loss: 0.10707747936248779\n",
            "Batch: 5385 Epoch: 0\n",
            "d_loss: 0.1625419155638852\n",
            "g_loss: 0.10788420587778091\n",
            "Batch: 5386 Epoch: 0\n",
            "d_loss: 0.16254185299946755\n",
            "g_loss: 0.10731835663318634\n",
            "Batch: 5387 Epoch: 0\n",
            "d_loss: 0.162541869544782\n",
            "g_loss: 0.10796445608139038\n",
            "Batch: 5388 Epoch: 0\n",
            "d_loss: 0.1625435406354967\n",
            "g_loss: 0.10587606579065323\n",
            "Batch: 5389 Epoch: 0\n",
            "d_loss: 0.16254286912842986\n",
            "g_loss: 0.1073114275932312\n",
            "Batch: 5390 Epoch: 0\n",
            "d_loss: 0.1625417216301912\n",
            "g_loss: 0.10741255432367325\n",
            "Batch: 5391 Epoch: 0\n",
            "d_loss: 0.16254184004519345\n",
            "g_loss: 0.10681544244289398\n",
            "Batch: 5392 Epoch: 0\n",
            "d_loss: 0.16254215055759147\n",
            "g_loss: 0.10795500129461288\n",
            "Batch: 5393 Epoch: 0\n",
            "d_loss: 0.16254213991571476\n",
            "g_loss: 0.10692956298589706\n",
            "Batch: 5394 Epoch: 0\n",
            "d_loss: 0.16254192787478416\n",
            "g_loss: 0.10744906961917877\n",
            "Batch: 5395 Epoch: 0\n",
            "d_loss: 0.16254164418646866\n",
            "g_loss: 0.10747120529413223\n",
            "Batch: 5396 Epoch: 0\n",
            "d_loss: 0.16254227252075992\n",
            "g_loss: 0.10650209337472916\n",
            "Batch: 5397 Epoch: 0\n",
            "d_loss: 0.16254242031053678\n",
            "g_loss: 0.10768761485815048\n",
            "Batch: 5398 Epoch: 0\n",
            "d_loss: 0.16254216786813203\n",
            "g_loss: 0.10693813860416412\n",
            "Batch: 5399 Epoch: 0\n",
            "d_loss: 0.162542075309986\n",
            "g_loss: 0.10765435546636581\n",
            "Batch: 5400 Epoch: 0\n",
            "d_loss: 0.16254227741323035\n",
            "g_loss: 0.10638648271560669\n",
            "Batch: 5401 Epoch: 0\n",
            "d_loss: 0.16254411748753483\n",
            "g_loss: 0.10829170048236847\n",
            "Batch: 5402 Epoch: 0\n",
            "d_loss: 0.16254307539988133\n",
            "g_loss: 0.1066441684961319\n",
            "Batch: 5403 Epoch: 0\n",
            "d_loss: 0.16254206184718356\n",
            "g_loss: 0.10711017996072769\n",
            "Batch: 5404 Epoch: 0\n",
            "d_loss: 0.16254311828496526\n",
            "g_loss: 0.10656134784221649\n",
            "Batch: 5405 Epoch: 0\n",
            "d_loss: 0.16254262744837433\n",
            "g_loss: 0.10770630836486816\n",
            "Batch: 5406 Epoch: 0\n",
            "d_loss: 0.16254397960958045\n",
            "g_loss: 0.10568177700042725\n",
            "Batch: 5407 Epoch: 0\n",
            "d_loss: 0.1625451317742943\n",
            "g_loss: 0.10821547359228134\n",
            "Batch: 5408 Epoch: 0\n",
            "d_loss: 0.16254513774094903\n",
            "g_loss: 0.1056651845574379\n",
            "Batch: 5409 Epoch: 0\n",
            "d_loss: 0.1625441777098331\n",
            "g_loss: 0.10730518400669098\n",
            "Batch: 5410 Epoch: 0\n",
            "d_loss: 0.162542821987806\n",
            "g_loss: 0.10656122863292694\n",
            "Batch: 5411 Epoch: 0\n",
            "d_loss: 0.16254240377973872\n",
            "g_loss: 0.10776692628860474\n",
            "Batch: 5412 Epoch: 0\n",
            "d_loss: 0.16254348188959966\n",
            "g_loss: 0.10545198619365692\n",
            "Batch: 5413 Epoch: 0\n",
            "d_loss: 0.1625436419436852\n",
            "g_loss: 0.10703035444021225\n",
            "Batch: 5414 Epoch: 0\n",
            "d_loss: 0.16254270463691256\n",
            "g_loss: 0.10613838583230972\n",
            "Batch: 5415 Epoch: 0\n",
            "d_loss: 0.16254354116042435\n",
            "g_loss: 0.10830287635326385\n",
            "Batch: 5416 Epoch: 0\n",
            "d_loss: 0.16254395613337635\n",
            "g_loss: 0.10656385123729706\n",
            "Batch: 5417 Epoch: 0\n",
            "d_loss: 0.16254285292345116\n",
            "g_loss: 0.10772806406021118\n",
            "Batch: 5418 Epoch: 0\n",
            "d_loss: 0.16254219688235594\n",
            "g_loss: 0.10675179958343506\n",
            "Batch: 5419 Epoch: 0\n",
            "d_loss: 0.16254250919530477\n",
            "g_loss: 0.10710781812667847\n",
            "Batch: 5420 Epoch: 0\n",
            "d_loss: 0.16254179608121433\n",
            "g_loss: 0.10676641762256622\n",
            "Batch: 5421 Epoch: 0\n",
            "d_loss: 0.1625418289675764\n",
            "g_loss: 0.10683691501617432\n",
            "Batch: 5422 Epoch: 0\n",
            "d_loss: 0.16254179566795557\n",
            "g_loss: 0.10686985403299332\n",
            "Batch: 5423 Epoch: 0\n",
            "d_loss: 0.1625417941206848\n",
            "g_loss: 0.10748197883367538\n",
            "Batch: 5424 Epoch: 0\n",
            "d_loss: 0.1625421091437076\n",
            "g_loss: 0.10661888122558594\n",
            "Batch: 5425 Epoch: 0\n",
            "d_loss: 0.16254215305235675\n",
            "g_loss: 0.10745994001626968\n",
            "Batch: 5426 Epoch: 0\n",
            "d_loss: 0.1625423516029656\n",
            "g_loss: 0.10652617365121841\n",
            "Batch: 5427 Epoch: 0\n",
            "d_loss: 0.1625420921045304\n",
            "g_loss: 0.10718973726034164\n",
            "Batch: 5428 Epoch: 0\n",
            "d_loss: 0.16254186745969434\n",
            "g_loss: 0.10660401731729507\n",
            "Batch: 5429 Epoch: 0\n",
            "d_loss: 0.16254219560830308\n",
            "g_loss: 0.10766489803791046\n",
            "Batch: 5430 Epoch: 0\n",
            "d_loss: 0.16254244870183499\n",
            "g_loss: 0.10648719221353531\n",
            "Batch: 5431 Epoch: 0\n",
            "d_loss: 0.16254235880877133\n",
            "g_loss: 0.10725685209035873\n",
            "Batch: 5432 Epoch: 0\n",
            "d_loss: 0.1625423037585847\n",
            "g_loss: 0.10685213655233383\n",
            "Batch: 5433 Epoch: 0\n",
            "d_loss: 0.1625417491617469\n",
            "g_loss: 0.10696730762720108\n",
            "Batch: 5434 Epoch: 0\n",
            "d_loss: 0.1625416750351718\n",
            "g_loss: 0.10684424638748169\n",
            "Batch: 5435 Epoch: 0\n",
            "d_loss: 0.16254170396659617\n",
            "g_loss: 0.10731692612171173\n",
            "Batch: 5436 Epoch: 0\n",
            "d_loss: 0.16254170525908762\n",
            "g_loss: 0.10709750652313232\n",
            "Batch: 5437 Epoch: 0\n",
            "d_loss: 0.1625420750178037\n",
            "g_loss: 0.10672776401042938\n",
            "Batch: 5438 Epoch: 0\n",
            "d_loss: 0.16254210626463816\n",
            "g_loss: 0.10775698721408844\n",
            "Batch: 5439 Epoch: 0\n",
            "d_loss: 0.16254297174353383\n",
            "g_loss: 0.10630416870117188\n",
            "Batch: 5440 Epoch: 0\n",
            "d_loss: 0.16254299540644013\n",
            "g_loss: 0.10746681690216064\n",
            "Batch: 5441 Epoch: 0\n",
            "d_loss: 0.16254218114383434\n",
            "g_loss: 0.10678732395172119\n",
            "Batch: 5442 Epoch: 0\n",
            "d_loss: 0.1625424925275567\n",
            "g_loss: 0.10803709924221039\n",
            "Batch: 5443 Epoch: 0\n",
            "d_loss: 0.16254364296817414\n",
            "g_loss: 0.10565248876810074\n",
            "Batch: 5444 Epoch: 0\n",
            "d_loss: 0.16254337331945123\n",
            "g_loss: 0.10733131319284439\n",
            "Batch: 5445 Epoch: 0\n",
            "d_loss: 0.16254274633434562\n",
            "g_loss: 0.10625581443309784\n",
            "Batch: 5446 Epoch: 0\n",
            "d_loss: 0.16254176429995937\n",
            "g_loss: 0.10618486255407333\n",
            "Batch: 5447 Epoch: 0\n",
            "d_loss: 0.1625417351527787\n",
            "g_loss: 0.10585086047649384\n",
            "Batch: 5448 Epoch: 0\n",
            "d_loss: 0.16254197443159768\n",
            "g_loss: 0.10668960958719254\n",
            "Batch: 5449 Epoch: 0\n",
            "d_loss: 0.1625421801596545\n",
            "g_loss: 0.10608191788196564\n",
            "Batch: 5450 Epoch: 0\n",
            "d_loss: 0.16254210536465052\n",
            "g_loss: 0.10713400691747665\n",
            "Batch: 5451 Epoch: 0\n",
            "d_loss: 0.16254198398834063\n",
            "g_loss: 0.1073642149567604\n",
            "Batch: 5452 Epoch: 0\n",
            "d_loss: 0.16254203139440904\n",
            "g_loss: 0.10650543123483658\n",
            "Batch: 5453 Epoch: 0\n",
            "d_loss: 0.16254194254288024\n",
            "g_loss: 0.1073746308684349\n",
            "Batch: 5454 Epoch: 0\n",
            "d_loss: 0.1625419861242534\n",
            "g_loss: 0.10654979944229126\n",
            "Batch: 5455 Epoch: 0\n",
            "d_loss: 0.1625423406505675\n",
            "g_loss: 0.10777343809604645\n",
            "Batch: 5456 Epoch: 0\n",
            "d_loss: 0.16254174470419258\n",
            "g_loss: 0.10785195976495743\n",
            "Batch: 5457 Epoch: 0\n",
            "d_loss: 0.16254298462016692\n",
            "g_loss: 0.1059974804520607\n",
            "Batch: 5458 Epoch: 0\n",
            "d_loss: 0.16254501152214118\n",
            "g_loss: 0.10840113461017609\n",
            "Batch: 5459 Epoch: 0\n",
            "d_loss: 0.16254411875515018\n",
            "g_loss: 0.10633628070354462\n",
            "Batch: 5460 Epoch: 0\n",
            "d_loss: 0.1625428049688935\n",
            "g_loss: 0.10750651359558105\n",
            "Batch: 5461 Epoch: 0\n",
            "d_loss: 0.1625427302555167\n",
            "g_loss: 0.10666738450527191\n",
            "Batch: 5462 Epoch: 0\n",
            "d_loss: 0.16254256566368497\n",
            "g_loss: 0.1071486696600914\n",
            "Batch: 5463 Epoch: 0\n",
            "d_loss: 0.16254273291990984\n",
            "g_loss: 0.10763730108737946\n",
            "Batch: 5464 Epoch: 0\n",
            "d_loss: 0.16254239088144118\n",
            "g_loss: 0.10712926089763641\n",
            "Batch: 5465 Epoch: 0\n",
            "d_loss: 0.1625427038945091\n",
            "g_loss: 0.10717926174402237\n",
            "Batch: 5466 Epoch: 0\n",
            "d_loss: 0.16254180615030833\n",
            "g_loss: 0.10685274749994278\n",
            "Batch: 5467 Epoch: 0\n",
            "d_loss: 0.16254606798948856\n",
            "g_loss: 0.1050182580947876\n",
            "Batch: 5468 Epoch: 0\n",
            "d_loss: 0.1625544569553128\n",
            "g_loss: 0.10894117504358292\n",
            "Batch: 5469 Epoch: 0\n",
            "d_loss: 0.1625470827467126\n",
            "g_loss: 0.10652635991573334\n",
            "Batch: 5470 Epoch: 0\n",
            "d_loss: 0.16254346469250436\n",
            "g_loss: 0.10814851522445679\n",
            "Batch: 5471 Epoch: 0\n",
            "d_loss: 0.162542581113847\n",
            "g_loss: 0.10722772777080536\n",
            "Batch: 5472 Epoch: 0\n",
            "d_loss: 0.16254180751623437\n",
            "g_loss: 0.10739143192768097\n",
            "Batch: 5473 Epoch: 0\n",
            "d_loss: 0.16254294040804496\n",
            "g_loss: 0.1057661771774292\n",
            "Batch: 5474 Epoch: 0\n",
            "d_loss: 0.16254410372174277\n",
            "g_loss: 0.10756554454565048\n",
            "Batch: 5475 Epoch: 0\n",
            "d_loss: 0.1625457540443236\n",
            "g_loss: 0.10560379922389984\n",
            "Batch: 5476 Epoch: 0\n",
            "d_loss: 0.16254460759870426\n",
            "g_loss: 0.10764074325561523\n",
            "Batch: 5477 Epoch: 0\n",
            "d_loss: 0.16254305633816557\n",
            "g_loss: 0.10673186928033829\n",
            "Batch: 5478 Epoch: 0\n",
            "d_loss: 0.16254208975095708\n",
            "g_loss: 0.10681222379207611\n",
            "Batch: 5479 Epoch: 0\n",
            "d_loss: 0.1625420459758189\n",
            "g_loss: 0.10568270832300186\n",
            "Batch: 5480 Epoch: 0\n",
            "d_loss: 0.16254512789184616\n",
            "g_loss: 0.10854382812976837\n",
            "Batch: 5481 Epoch: 0\n",
            "d_loss: 0.1625487657703033\n",
            "g_loss: 0.10563027858734131\n",
            "Batch: 5482 Epoch: 0\n",
            "d_loss: 0.16254690271783545\n",
            "g_loss: 0.10866592824459076\n",
            "Batch: 5483 Epoch: 0\n",
            "d_loss: 0.1625473642941273\n",
            "g_loss: 0.1052311435341835\n",
            "Batch: 5484 Epoch: 0\n",
            "d_loss: 0.1625512069803392\n",
            "g_loss: 0.10903420299291611\n",
            "Batch: 5485 Epoch: 0\n",
            "d_loss: 0.16254869131397953\n",
            "g_loss: 0.10558520257472992\n",
            "Batch: 5486 Epoch: 0\n",
            "d_loss: 0.16254657596275734\n",
            "g_loss: 0.10854624211788177\n",
            "Batch: 5487 Epoch: 0\n",
            "d_loss: 0.16254980752454173\n",
            "g_loss: 0.10481305420398712\n",
            "Batch: 5488 Epoch: 0\n",
            "d_loss: 0.16255026853797006\n",
            "g_loss: 0.10888390243053436\n",
            "Batch: 5489 Epoch: 0\n",
            "d_loss: 0.16254977840966944\n",
            "g_loss: 0.10584549605846405\n",
            "Batch: 5490 Epoch: 0\n",
            "d_loss: 0.16254460604916687\n",
            "g_loss: 0.10784262418746948\n",
            "Batch: 5491 Epoch: 0\n",
            "d_loss: 0.16254293778047213\n",
            "g_loss: 0.10663839429616928\n",
            "Batch: 5492 Epoch: 0\n",
            "d_loss: 0.16254213699062348\n",
            "g_loss: 0.10656815767288208\n",
            "Batch: 5493 Epoch: 0\n",
            "d_loss: 0.16254786675709454\n",
            "g_loss: 0.10953754186630249\n",
            "Batch: 5494 Epoch: 0\n",
            "d_loss: 0.16255446121745365\n",
            "g_loss: 0.10416622459888458\n",
            "Batch: 5495 Epoch: 0\n",
            "d_loss: 0.1625510295088901\n",
            "g_loss: 0.10770611464977264\n",
            "Batch: 5496 Epoch: 0\n",
            "d_loss: 0.16255167387706848\n",
            "g_loss: 0.10802185535430908\n",
            "Batch: 5497 Epoch: 0\n",
            "d_loss: 0.16254489964641294\n",
            "g_loss: 0.10589055716991425\n",
            "Batch: 5498 Epoch: 0\n",
            "d_loss: 0.1625447990337605\n",
            "g_loss: 0.10782363265752792\n",
            "Batch: 5499 Epoch: 0\n",
            "d_loss: 0.16254401061884494\n",
            "g_loss: 0.10630514472723007\n",
            "Batch: 5500 Epoch: 0\n",
            "d_loss: 0.162542047489886\n",
            "g_loss: 0.10655917227268219\n",
            "Batch: 5501 Epoch: 0\n",
            "d_loss: 0.16254214798790656\n",
            "g_loss: 0.10756935924291611\n",
            "Batch: 5502 Epoch: 0\n",
            "d_loss: 0.1625429847812967\n",
            "g_loss: 0.10609761625528336\n",
            "Batch: 5503 Epoch: 0\n",
            "d_loss: 0.16254332606073518\n",
            "g_loss: 0.10777692496776581\n",
            "Batch: 5504 Epoch: 0\n",
            "d_loss: 0.16254210377557854\n",
            "g_loss: 0.10752332210540771\n",
            "Batch: 5505 Epoch: 0\n",
            "d_loss: 0.16254226826099938\n",
            "g_loss: 0.10733375698328018\n",
            "Batch: 5506 Epoch: 0\n",
            "d_loss: 0.16254237025792406\n",
            "g_loss: 0.10645313560962677\n",
            "Batch: 5507 Epoch: 0\n",
            "d_loss: 0.16254263972335536\n",
            "g_loss: 0.10772164911031723\n",
            "Batch: 5508 Epoch: 0\n",
            "d_loss: 0.1625422093274338\n",
            "g_loss: 0.10679332911968231\n",
            "Batch: 5509 Epoch: 0\n",
            "d_loss: 0.16254217818217143\n",
            "g_loss: 0.10682864487171173\n",
            "Batch: 5510 Epoch: 0\n",
            "d_loss: 0.162541951674136\n",
            "g_loss: 0.10675841569900513\n",
            "Batch: 5511 Epoch: 0\n",
            "d_loss: 0.16254182283292096\n",
            "g_loss: 0.10667784512042999\n",
            "Batch: 5512 Epoch: 0\n",
            "d_loss: 0.1625417928130659\n",
            "g_loss: 0.1072099357843399\n",
            "Batch: 5513 Epoch: 0\n",
            "d_loss: 0.16254227069156713\n",
            "g_loss: 0.10619165003299713\n",
            "Batch: 5514 Epoch: 0\n",
            "d_loss: 0.16254286210048008\n",
            "g_loss: 0.10759575664997101\n",
            "Batch: 5515 Epoch: 0\n",
            "d_loss: 0.16254258192272175\n",
            "g_loss: 0.10635305941104889\n",
            "Batch: 5516 Epoch: 0\n",
            "d_loss: 0.16254174729381532\n",
            "g_loss: 0.10618488490581512\n",
            "Batch: 5517 Epoch: 0\n",
            "d_loss: 0.1625426248506514\n",
            "g_loss: 0.10774203389883041\n",
            "Batch: 5518 Epoch: 0\n",
            "d_loss: 0.16254268385566917\n",
            "g_loss: 0.10662098973989487\n",
            "Batch: 5519 Epoch: 0\n",
            "d_loss: 0.1625419112621529\n",
            "g_loss: 0.10715590417385101\n",
            "Batch: 5520 Epoch: 0\n",
            "d_loss: 0.1625417298808003\n",
            "g_loss: 0.10708160698413849\n",
            "Batch: 5521 Epoch: 0\n",
            "d_loss: 0.16254167290076538\n",
            "g_loss: 0.10736259073019028\n",
            "Batch: 5522 Epoch: 0\n",
            "d_loss: 0.16254268980971176\n",
            "g_loss: 0.10576436668634415\n",
            "Batch: 5523 Epoch: 0\n",
            "d_loss: 0.1625446506021362\n",
            "g_loss: 0.10824255645275116\n",
            "Batch: 5524 Epoch: 0\n",
            "d_loss: 0.1625442022566972\n",
            "g_loss: 0.1064179316163063\n",
            "Batch: 5525 Epoch: 0\n",
            "d_loss: 0.16254268393193883\n",
            "g_loss: 0.10755733400583267\n",
            "Batch: 5526 Epoch: 0\n",
            "d_loss: 0.16254231037409994\n",
            "g_loss: 0.10674506425857544\n",
            "Batch: 5527 Epoch: 0\n",
            "d_loss: 0.162542310007332\n",
            "g_loss: 0.10785020887851715\n",
            "Batch: 5528 Epoch: 0\n",
            "d_loss: 0.16254249242118846\n",
            "g_loss: 0.10684233903884888\n",
            "Batch: 5529 Epoch: 0\n",
            "d_loss: 0.16254176193056225\n",
            "g_loss: 0.10716816037893295\n",
            "Batch: 5530 Epoch: 0\n",
            "d_loss: 0.1625417294842606\n",
            "g_loss: 0.10750529915094376\n",
            "Batch: 5531 Epoch: 0\n",
            "d_loss: 0.1625427431950044\n",
            "g_loss: 0.10556789487600327\n",
            "Batch: 5532 Epoch: 0\n",
            "d_loss: 0.16254234827285785\n",
            "g_loss: 0.10637178272008896\n",
            "Batch: 5533 Epoch: 0\n",
            "d_loss: 0.16254178983886902\n",
            "g_loss: 0.10714147239923477\n",
            "Batch: 5534 Epoch: 0\n",
            "d_loss: 0.16254213234557113\n",
            "g_loss: 0.10751340538263321\n",
            "Batch: 5535 Epoch: 0\n",
            "d_loss: 0.16254220607048353\n",
            "g_loss: 0.10673423111438751\n",
            "Batch: 5536 Epoch: 0\n",
            "d_loss: 0.16254201748368757\n",
            "g_loss: 0.10686056315898895\n",
            "Batch: 5537 Epoch: 0\n",
            "d_loss: 0.1625416985108572\n",
            "g_loss: 0.10774626582860947\n",
            "Batch: 5538 Epoch: 0\n",
            "d_loss: 0.16254268277639028\n",
            "g_loss: 0.106142558157444\n",
            "Batch: 5539 Epoch: 0\n",
            "d_loss: 0.1625426580168181\n",
            "g_loss: 0.10715649276971817\n",
            "Batch: 5540 Epoch: 0\n",
            "d_loss: 0.16254204142641981\n",
            "g_loss: 0.10717076063156128\n",
            "Batch: 5541 Epoch: 0\n",
            "d_loss: 0.16254189244528305\n",
            "g_loss: 0.10728120803833008\n",
            "Batch: 5542 Epoch: 0\n",
            "d_loss: 0.16254220717821966\n",
            "g_loss: 0.10627542436122894\n",
            "Batch: 5543 Epoch: 0\n",
            "d_loss: 0.16254256387621524\n",
            "g_loss: 0.10764709860086441\n",
            "Batch: 5544 Epoch: 0\n",
            "d_loss: 0.16254292564093475\n",
            "g_loss: 0.10638941824436188\n",
            "Batch: 5545 Epoch: 0\n",
            "d_loss: 0.16254257852273213\n",
            "g_loss: 0.1075601801276207\n",
            "Batch: 5546 Epoch: 0\n",
            "d_loss: 0.1625435783682434\n",
            "g_loss: 0.10557079315185547\n",
            "Batch: 5547 Epoch: 0\n",
            "d_loss: 0.16254666124364547\n",
            "g_loss: 0.10876494646072388\n",
            "Batch: 5548 Epoch: 0\n",
            "d_loss: 0.16254722212676143\n",
            "g_loss: 0.1055891290307045\n",
            "Batch: 5549 Epoch: 0\n",
            "d_loss: 0.16254406178269676\n",
            "g_loss: 0.10712648928165436\n",
            "Batch: 5550 Epoch: 0\n",
            "d_loss: 0.16254247290000734\n",
            "g_loss: 0.10657435655593872\n",
            "Batch: 5551 Epoch: 0\n",
            "d_loss: 0.16254208736451403\n",
            "g_loss: 0.10603346675634384\n",
            "Batch: 5552 Epoch: 0\n",
            "d_loss: 0.16254483380369322\n",
            "g_loss: 0.10861195623874664\n",
            "Batch: 5553 Epoch: 0\n",
            "d_loss: 0.16254695794972207\n",
            "g_loss: 0.10519576072692871\n",
            "Batch: 5554 Epoch: 0\n",
            "d_loss: 0.16254663349005938\n",
            "g_loss: 0.1077282652258873\n",
            "Batch: 5555 Epoch: 0\n",
            "d_loss: 0.16254375422745682\n",
            "g_loss: 0.10739599168300629\n",
            "Batch: 5556 Epoch: 0\n",
            "d_loss: 0.1625432798680535\n",
            "g_loss: 0.10513961315155029\n",
            "Batch: 5557 Epoch: 0\n",
            "d_loss: 0.16254621318138618\n",
            "g_loss: 0.10808086395263672\n",
            "Batch: 5558 Epoch: 0\n",
            "d_loss: 0.16254272936587455\n",
            "g_loss: 0.1072608083486557\n",
            "Batch: 5559 Epoch: 0\n",
            "d_loss: 0.16254237726877108\n",
            "g_loss: 0.10575469583272934\n",
            "Batch: 5560 Epoch: 0\n",
            "d_loss: 0.16254389665438396\n",
            "g_loss: 0.1062469333410263\n",
            "Batch: 5561 Epoch: 0\n",
            "d_loss: 0.16254260585623825\n",
            "g_loss: 0.10631315410137177\n",
            "Batch: 5562 Epoch: 0\n",
            "d_loss: 0.16254172736487504\n",
            "g_loss: 0.10612475872039795\n",
            "Batch: 5563 Epoch: 0\n",
            "d_loss: 0.1625424573329468\n",
            "g_loss: 0.10652468353509903\n",
            "Batch: 5564 Epoch: 0\n",
            "d_loss: 0.16254189476670433\n",
            "g_loss: 0.1061599999666214\n",
            "Batch: 5565 Epoch: 0\n",
            "d_loss: 0.16254222193578016\n",
            "g_loss: 0.10718939453363419\n",
            "Batch: 5566 Epoch: 0\n",
            "d_loss: 0.16254260781268925\n",
            "g_loss: 0.10602235794067383\n",
            "Batch: 5567 Epoch: 0\n",
            "d_loss: 0.1625423530527783\n",
            "g_loss: 0.10700700432062149\n",
            "Batch: 5568 Epoch: 0\n",
            "d_loss: 0.16254190549018688\n",
            "g_loss: 0.10637948662042618\n",
            "Batch: 5569 Epoch: 0\n",
            "d_loss: 0.16254171354367486\n",
            "g_loss: 0.10654376447200775\n",
            "Batch: 5570 Epoch: 0\n",
            "d_loss: 0.16254196690822198\n",
            "g_loss: 0.10608859360218048\n",
            "Batch: 5571 Epoch: 0\n",
            "d_loss: 0.1625421768724209\n",
            "g_loss: 0.10718552768230438\n",
            "Batch: 5572 Epoch: 0\n",
            "d_loss: 0.16254257621033474\n",
            "g_loss: 0.10578346252441406\n",
            "Batch: 5573 Epoch: 0\n",
            "d_loss: 0.16254253141178054\n",
            "g_loss: 0.10679332166910172\n",
            "Batch: 5574 Epoch: 0\n",
            "d_loss: 0.16254205632149166\n",
            "g_loss: 0.10640527307987213\n",
            "Batch: 5575 Epoch: 0\n",
            "d_loss: 0.16254169715107025\n",
            "g_loss: 0.10603167861700058\n",
            "Batch: 5576 Epoch: 0\n",
            "d_loss: 0.16254224767028802\n",
            "g_loss: 0.10710415989160538\n",
            "Batch: 5577 Epoch: 0\n",
            "d_loss: 0.1625417107856748\n",
            "g_loss: 0.1072532907128334\n",
            "Batch: 5578 Epoch: 0\n",
            "d_loss: 0.16254209941997289\n",
            "g_loss: 0.10641700029373169\n",
            "Batch: 5579 Epoch: 0\n",
            "d_loss: 0.16254214426296443\n",
            "g_loss: 0.10730557143688202\n",
            "Batch: 5580 Epoch: 0\n",
            "d_loss: 0.16254419689384036\n",
            "g_loss: 0.10508619248867035\n",
            "Batch: 5581 Epoch: 0\n",
            "d_loss: 0.16254631815236564\n",
            "g_loss: 0.10857037454843521\n",
            "Batch: 5582 Epoch: 0\n",
            "d_loss: 0.16254566890208366\n",
            "g_loss: 0.10635100305080414\n",
            "Batch: 5583 Epoch: 0\n",
            "d_loss: 0.1625453513295838\n",
            "g_loss: 0.10885554552078247\n",
            "Batch: 5584 Epoch: 0\n",
            "d_loss: 0.16254524390468816\n",
            "g_loss: 0.1069275289773941\n",
            "Batch: 5585 Epoch: 0\n",
            "d_loss: 0.16254266703875686\n",
            "g_loss: 0.1071682721376419\n",
            "Batch: 5586 Epoch: 0\n",
            "d_loss: 0.16254186932840042\n",
            "g_loss: 0.10685129463672638\n",
            "Batch: 5587 Epoch: 0\n",
            "d_loss: 0.16254172806084455\n",
            "g_loss: 0.10651092231273651\n",
            "Batch: 5588 Epoch: 0\n",
            "d_loss: 0.16254210472686736\n",
            "g_loss: 0.10715115070343018\n",
            "Batch: 5589 Epoch: 0\n",
            "d_loss: 0.16254181646256427\n",
            "g_loss: 0.10764789581298828\n",
            "Batch: 5590 Epoch: 0\n",
            "d_loss: 0.16254175739381083\n",
            "g_loss: 0.10711236298084259\n",
            "Batch: 5591 Epoch: 0\n",
            "d_loss: 0.1625416484199036\n",
            "g_loss: 0.10719840228557587\n",
            "Batch: 5592 Epoch: 0\n",
            "d_loss: 0.16254164024334017\n",
            "g_loss: 0.10709476470947266\n",
            "Batch: 5593 Epoch: 0\n",
            "d_loss: 0.16254169775409366\n",
            "g_loss: 0.1074945330619812\n",
            "Batch: 5594 Epoch: 0\n",
            "d_loss: 0.16254189703361988\n",
            "g_loss: 0.10732467472553253\n",
            "Batch: 5595 Epoch: 0\n",
            "d_loss: 0.16254198152579136\n",
            "g_loss: 0.1065639853477478\n",
            "Batch: 5596 Epoch: 0\n",
            "d_loss: 0.16254236814877743\n",
            "g_loss: 0.10773579776287079\n",
            "Batch: 5597 Epoch: 0\n",
            "d_loss: 0.1625423670299\n",
            "g_loss: 0.10732205212116241\n",
            "Batch: 5598 Epoch: 0\n",
            "d_loss: 0.1625418605852218\n",
            "g_loss: 0.10643815994262695\n",
            "Batch: 5599 Epoch: 0\n",
            "d_loss: 0.16254188844803963\n",
            "g_loss: 0.10723376274108887\n",
            "Batch: 5600 Epoch: 0\n",
            "d_loss: 0.1625417877873474\n",
            "g_loss: 0.10663072019815445\n",
            "Batch: 5601 Epoch: 0\n",
            "d_loss: 0.16254315668972197\n",
            "g_loss: 0.1087789386510849\n",
            "Batch: 5602 Epoch: 0\n",
            "d_loss: 0.16254774783590165\n",
            "g_loss: 0.10513277351856232\n",
            "Batch: 5603 Epoch: 0\n",
            "d_loss: 0.16255032529001312\n",
            "g_loss: 0.10881763696670532\n",
            "Batch: 5604 Epoch: 0\n",
            "d_loss: 0.16254755006055177\n",
            "g_loss: 0.10554244369268417\n",
            "Batch: 5605 Epoch: 0\n",
            "d_loss: 0.16254427466189725\n",
            "g_loss: 0.10756902396678925\n",
            "Batch: 5606 Epoch: 0\n",
            "d_loss: 0.16254214454197324\n",
            "g_loss: 0.10754357278347015\n",
            "Batch: 5607 Epoch: 0\n",
            "d_loss: 0.16254355868505854\n",
            "g_loss: 0.10654572397470474\n",
            "Batch: 5608 Epoch: 0\n",
            "d_loss: 0.16254343952976313\n",
            "g_loss: 0.10887549072504044\n",
            "Batch: 5609 Epoch: 0\n",
            "d_loss: 0.162545955933858\n",
            "g_loss: 0.10569636523723602\n",
            "Batch: 5610 Epoch: 0\n",
            "d_loss: 0.16254574093451168\n",
            "g_loss: 0.10852684825658798\n",
            "Batch: 5611 Epoch: 0\n",
            "d_loss: 0.16254376672931414\n",
            "g_loss: 0.10684122145175934\n",
            "Batch: 5612 Epoch: 0\n",
            "d_loss: 0.16254370655722283\n",
            "g_loss: 0.10826526582241058\n",
            "Batch: 5613 Epoch: 0\n",
            "d_loss: 0.1625437894865911\n",
            "g_loss: 0.10648107528686523\n",
            "Batch: 5614 Epoch: 0\n",
            "d_loss: 0.1625432470235566\n",
            "g_loss: 0.10809842497110367\n",
            "Batch: 5615 Epoch: 0\n",
            "d_loss: 0.16254387312477547\n",
            "g_loss: 0.10599100589752197\n",
            "Batch: 5616 Epoch: 0\n",
            "d_loss: 0.16254512968291124\n",
            "g_loss: 0.10864726454019547\n",
            "Batch: 5617 Epoch: 0\n",
            "d_loss: 0.16254393483855978\n",
            "g_loss: 0.10685267299413681\n",
            "Batch: 5618 Epoch: 0\n",
            "d_loss: 0.16254215806940664\n",
            "g_loss: 0.10772397369146347\n",
            "Batch: 5619 Epoch: 0\n",
            "d_loss: 0.16254217541456484\n",
            "g_loss: 0.10673527419567108\n",
            "Batch: 5620 Epoch: 0\n",
            "d_loss: 0.1625431253783205\n",
            "g_loss: 0.10859111696481705\n",
            "Batch: 5621 Epoch: 0\n",
            "d_loss: 0.16254322079289807\n",
            "g_loss: 0.10730733722448349\n",
            "Batch: 5622 Epoch: 0\n",
            "d_loss: 0.16254232599321483\n",
            "g_loss: 0.10745350271463394\n",
            "Batch: 5623 Epoch: 0\n",
            "d_loss: 0.16254272549601723\n",
            "g_loss: 0.10683108866214752\n",
            "Batch: 5624 Epoch: 0\n",
            "d_loss: 0.16254196697269663\n",
            "g_loss: 0.10778546333312988\n",
            "Batch: 5625 Epoch: 0\n",
            "d_loss: 0.16254238068084703\n",
            "g_loss: 0.10712629556655884\n",
            "Batch: 5626 Epoch: 0\n",
            "d_loss: 0.16254166594203667\n",
            "g_loss: 0.10724139213562012\n",
            "Batch: 5627 Epoch: 0\n",
            "d_loss: 0.16254172724335803\n",
            "g_loss: 0.10777938365936279\n",
            "Batch: 5628 Epoch: 0\n",
            "d_loss: 0.16254208477066356\n",
            "g_loss: 0.10774028301239014\n",
            "Batch: 5629 Epoch: 0\n",
            "d_loss: 0.1625418042177742\n",
            "g_loss: 0.10686364024877548\n",
            "Batch: 5630 Epoch: 0\n",
            "d_loss: 0.16254231175178546\n",
            "g_loss: 0.107746422290802\n",
            "Batch: 5631 Epoch: 0\n",
            "d_loss: 0.16254284444239886\n",
            "g_loss: 0.1057690754532814\n",
            "Batch: 5632 Epoch: 0\n",
            "d_loss: 0.16254601653666612\n",
            "g_loss: 0.10898089408874512\n",
            "Batch: 5633 Epoch: 0\n",
            "d_loss: 0.16254965608969485\n",
            "g_loss: 0.10488341748714447\n",
            "Batch: 5634 Epoch: 0\n",
            "d_loss: 0.16254989209029702\n",
            "g_loss: 0.10890141874551773\n",
            "Batch: 5635 Epoch: 0\n",
            "d_loss: 0.1625511945350837\n",
            "g_loss: 0.10468761622905731\n",
            "Batch: 5636 Epoch: 0\n",
            "d_loss: 0.1625513949347095\n",
            "g_loss: 0.10921797901391983\n",
            "Batch: 5637 Epoch: 0\n",
            "d_loss: 0.1625523213760829\n",
            "g_loss: 0.10569775104522705\n",
            "Batch: 5638 Epoch: 0\n",
            "d_loss: 0.16255392641782151\n",
            "g_loss: 0.11040444672107697\n",
            "Batch: 5639 Epoch: 0\n",
            "d_loss: 0.162551261992661\n",
            "g_loss: 0.10692334175109863\n",
            "Batch: 5640 Epoch: 0\n",
            "d_loss: 0.1625472207793024\n",
            "g_loss: 0.10955721139907837\n",
            "Batch: 5641 Epoch: 0\n",
            "d_loss: 0.1625467197122603\n",
            "g_loss: 0.1068328469991684\n",
            "Batch: 5642 Epoch: 0\n",
            "d_loss: 0.1625445249583919\n",
            "g_loss: 0.10834752023220062\n",
            "Batch: 5643 Epoch: 0\n",
            "d_loss: 0.16254393319075433\n",
            "g_loss: 0.10626842826604843\n",
            "Batch: 5644 Epoch: 0\n",
            "d_loss: 0.16254447977239295\n",
            "g_loss: 0.10845781862735748\n",
            "Batch: 5645 Epoch: 0\n",
            "d_loss: 0.16254687926350186\n",
            "g_loss: 0.10530436038970947\n",
            "Batch: 5646 Epoch: 0\n",
            "d_loss: 0.16254920483406465\n",
            "g_loss: 0.109220489859581\n",
            "Batch: 5647 Epoch: 0\n",
            "d_loss: 0.16254481168734003\n",
            "g_loss: 0.10704002529382706\n",
            "Batch: 5648 Epoch: 0\n",
            "d_loss: 0.16254272372227518\n",
            "g_loss: 0.10514648258686066\n",
            "Batch: 5649 Epoch: 0\n",
            "d_loss: 0.16254737271450637\n",
            "g_loss: 0.10908140987157822\n",
            "Batch: 5650 Epoch: 0\n",
            "d_loss: 0.16254489785596604\n",
            "g_loss: 0.10761028528213501\n",
            "Batch: 5651 Epoch: 0\n",
            "d_loss: 0.16254339621272607\n",
            "g_loss: 0.1075148954987526\n",
            "Batch: 5652 Epoch: 0\n",
            "d_loss: 0.16254223104547094\n",
            "g_loss: 0.10821662098169327\n",
            "Batch: 5653 Epoch: 0\n",
            "d_loss: 0.16254725393913816\n",
            "g_loss: 0.10517780482769012\n",
            "Batch: 5654 Epoch: 0\n",
            "d_loss: 0.1625452414325963\n",
            "g_loss: 0.1074405163526535\n",
            "Batch: 5655 Epoch: 0\n",
            "d_loss: 0.16254293386928964\n",
            "g_loss: 0.10767588764429092\n",
            "Batch: 5656 Epoch: 0\n",
            "d_loss: 0.1625423366462968\n",
            "g_loss: 0.10729286819696426\n",
            "Batch: 5657 Epoch: 0\n",
            "d_loss: 0.1625420218096565\n",
            "g_loss: 0.10628049075603485\n",
            "Batch: 5658 Epoch: 0\n",
            "d_loss: 0.1625440932663622\n",
            "g_loss: 0.10898401588201523\n",
            "Batch: 5659 Epoch: 0\n",
            "d_loss: 0.16254550907136434\n",
            "g_loss: 0.10646171867847443\n",
            "Batch: 5660 Epoch: 0\n",
            "d_loss: 0.16254518603822987\n",
            "g_loss: 0.10813561826944351\n",
            "Batch: 5661 Epoch: 0\n",
            "d_loss: 0.16254321640576563\n",
            "g_loss: 0.10734407603740692\n",
            "Batch: 5662 Epoch: 0\n",
            "d_loss: 0.1625418010202111\n",
            "g_loss: 0.10713119804859161\n",
            "Batch: 5663 Epoch: 0\n",
            "d_loss: 0.16254273753374804\n",
            "g_loss: 0.10830149799585342\n",
            "Batch: 5664 Epoch: 0\n",
            "d_loss: 0.16254218513794427\n",
            "g_loss: 0.10748453438282013\n",
            "Batch: 5665 Epoch: 0\n",
            "d_loss: 0.16254209650240625\n",
            "g_loss: 0.10809493064880371\n",
            "Batch: 5666 Epoch: 0\n",
            "d_loss: 0.1625433514652599\n",
            "g_loss: 0.10652289539575577\n",
            "Batch: 5667 Epoch: 0\n",
            "d_loss: 0.16254346823676258\n",
            "g_loss: 0.10755717754364014\n",
            "Batch: 5668 Epoch: 0\n",
            "d_loss: 0.16254217013447914\n",
            "g_loss: 0.10762187093496323\n",
            "Batch: 5669 Epoch: 0\n",
            "d_loss: 0.16254220222349147\n",
            "g_loss: 0.10736827552318573\n",
            "Batch: 5670 Epoch: 0\n",
            "d_loss: 0.16254181423130376\n",
            "g_loss: 0.10724421590566635\n",
            "Batch: 5671 Epoch: 0\n",
            "d_loss: 0.16254202430906162\n",
            "g_loss: 0.1065322607755661\n",
            "Batch: 5672 Epoch: 0\n",
            "d_loss: 0.16254224719989452\n",
            "g_loss: 0.10752205550670624\n",
            "Batch: 5673 Epoch: 0\n",
            "d_loss: 0.16254220320195856\n",
            "g_loss: 0.10653380304574966\n",
            "Batch: 5674 Epoch: 0\n",
            "d_loss: 0.16254214218723462\n",
            "g_loss: 0.10766054689884186\n",
            "Batch: 5675 Epoch: 0\n",
            "d_loss: 0.16254263448962547\n",
            "g_loss: 0.106269970536232\n",
            "Batch: 5676 Epoch: 0\n",
            "d_loss: 0.1625421436966903\n",
            "g_loss: 0.10706345736980438\n",
            "Batch: 5677 Epoch: 0\n",
            "d_loss: 0.16254196142087807\n",
            "g_loss: 0.10825830698013306\n",
            "Batch: 5678 Epoch: 0\n",
            "d_loss: 0.1625445267943988\n",
            "g_loss: 0.10563121736049652\n",
            "Batch: 5679 Epoch: 0\n",
            "d_loss: 0.16254610427231597\n",
            "g_loss: 0.10849221050739288\n",
            "Batch: 5680 Epoch: 0\n",
            "d_loss: 0.1625441232053646\n",
            "g_loss: 0.1065732091665268\n",
            "Batch: 5681 Epoch: 0\n",
            "d_loss: 0.16254244102172777\n",
            "g_loss: 0.10754730552434921\n",
            "Batch: 5682 Epoch: 0\n",
            "d_loss: 0.16254176746306115\n",
            "g_loss: 0.10784373432397842\n",
            "Batch: 5683 Epoch: 0\n",
            "d_loss: 0.1625423194854747\n",
            "g_loss: 0.10689828544855118\n",
            "Batch: 5684 Epoch: 0\n",
            "d_loss: 0.1625419244040316\n",
            "g_loss: 0.107804074883461\n",
            "Batch: 5685 Epoch: 0\n",
            "d_loss: 0.16254172491037622\n",
            "g_loss: 0.10767042636871338\n",
            "Batch: 5686 Epoch: 0\n",
            "d_loss: 0.16254174432551594\n",
            "g_loss: 0.10722096264362335\n",
            "Batch: 5687 Epoch: 0\n",
            "d_loss: 0.16254217080260958\n",
            "g_loss: 0.10837918519973755\n",
            "Batch: 5688 Epoch: 0\n",
            "d_loss: 0.16254343851368702\n",
            "g_loss: 0.10668345540761948\n",
            "Batch: 5689 Epoch: 0\n",
            "d_loss: 0.16254331742664618\n",
            "g_loss: 0.10795816034078598\n",
            "Batch: 5690 Epoch: 0\n",
            "d_loss: 0.16254251633885275\n",
            "g_loss: 0.10684555768966675\n",
            "Batch: 5691 Epoch: 0\n",
            "d_loss: 0.16254494379352025\n",
            "g_loss: 0.1094735860824585\n",
            "Batch: 5692 Epoch: 0\n",
            "d_loss: 0.1625467760790471\n",
            "g_loss: 0.1057426929473877\n",
            "Batch: 5693 Epoch: 0\n",
            "d_loss: 0.16254379660246343\n",
            "g_loss: 0.10728390514850616\n",
            "Batch: 5694 Epoch: 0\n",
            "d_loss: 0.16254370511347815\n",
            "g_loss: 0.10823649168014526\n",
            "Batch: 5695 Epoch: 0\n",
            "d_loss: 0.16254243865675733\n",
            "g_loss: 0.10757702589035034\n",
            "Batch: 5696 Epoch: 0\n",
            "d_loss: 0.16254214191300065\n",
            "g_loss: 0.10784077644348145\n",
            "Batch: 5697 Epoch: 0\n",
            "d_loss: 0.1625417383816199\n",
            "g_loss: 0.10788248479366302\n",
            "Batch: 5698 Epoch: 0\n",
            "d_loss: 0.16254161891654206\n",
            "g_loss: 0.10794363170862198\n",
            "Batch: 5699 Epoch: 0\n",
            "d_loss: 0.1625418416688973\n",
            "g_loss: 0.10734367370605469\n",
            "Batch: 5700 Epoch: 0\n",
            "d_loss: 0.1625417691817006\n",
            "g_loss: 0.10757976770401001\n",
            "Batch: 5701 Epoch: 0\n",
            "d_loss: 0.16254172333208317\n",
            "g_loss: 0.10744263976812363\n",
            "Batch: 5702 Epoch: 0\n",
            "d_loss: 0.16254181211927232\n",
            "g_loss: 0.10700976848602295\n",
            "Batch: 5703 Epoch: 0\n",
            "d_loss: 0.1625418280041515\n",
            "g_loss: 0.10739314556121826\n",
            "Batch: 5704 Epoch: 0\n",
            "d_loss: 0.1625420255557657\n",
            "g_loss: 0.10645967721939087\n",
            "Batch: 5705 Epoch: 0\n",
            "d_loss: 0.16254351268941036\n",
            "g_loss: 0.10842227935791016\n",
            "Batch: 5706 Epoch: 0\n",
            "d_loss: 0.16254260196188852\n",
            "g_loss: 0.10717491805553436\n",
            "Batch: 5707 Epoch: 0\n",
            "d_loss: 0.1625418131663281\n",
            "g_loss: 0.10731835663318634\n",
            "Batch: 5708 Epoch: 0\n",
            "d_loss: 0.16254172423999336\n",
            "g_loss: 0.10710976272821426\n",
            "Batch: 5709 Epoch: 0\n",
            "d_loss: 0.1625419596405493\n",
            "g_loss: 0.10828617960214615\n",
            "Batch: 5710 Epoch: 0\n",
            "d_loss: 0.16254257195642197\n",
            "g_loss: 0.10707666724920273\n",
            "Batch: 5711 Epoch: 0\n",
            "d_loss: 0.16254203672939838\n",
            "g_loss: 0.10765649378299713\n",
            "Batch: 5712 Epoch: 0\n",
            "d_loss: 0.16254187305776213\n",
            "g_loss: 0.10767743736505508\n",
            "Batch: 5713 Epoch: 0\n",
            "d_loss: 0.16254175199667031\n",
            "g_loss: 0.10695628821849823\n",
            "Batch: 5714 Epoch: 0\n",
            "d_loss: 0.16254285959556825\n",
            "g_loss: 0.10818115621805191\n",
            "Batch: 5715 Epoch: 0\n",
            "d_loss: 0.16254245213577434\n",
            "g_loss: 0.10742386430501938\n",
            "Batch: 5716 Epoch: 0\n",
            "d_loss: 0.16254229124487551\n",
            "g_loss: 0.1062973290681839\n",
            "Batch: 5717 Epoch: 0\n",
            "d_loss: 0.16254434486022973\n",
            "g_loss: 0.10868605226278305\n",
            "Batch: 5718 Epoch: 0\n",
            "d_loss: 0.16254869682323658\n",
            "g_loss: 0.10480250418186188\n",
            "Batch: 5719 Epoch: 0\n",
            "d_loss: 0.1625510803822081\n",
            "g_loss: 0.10895031690597534\n",
            "Batch: 5720 Epoch: 0\n",
            "d_loss: 0.16254662509678042\n",
            "g_loss: 0.1062777042388916\n",
            "Batch: 5721 Epoch: 0\n",
            "d_loss: 0.16254469143069628\n",
            "g_loss: 0.10694531351327896\n",
            "Batch: 5722 Epoch: 0\n",
            "d_loss: 0.16254284071940361\n",
            "g_loss: 0.10890501737594604\n",
            "Batch: 5723 Epoch: 0\n",
            "d_loss: 0.1625451055638365\n",
            "g_loss: 0.10673739016056061\n",
            "Batch: 5724 Epoch: 0\n",
            "d_loss: 0.16254235037794018\n",
            "g_loss: 0.10762909799814224\n",
            "Batch: 5725 Epoch: 0\n",
            "d_loss: 0.16254331669230027\n",
            "g_loss: 0.10640380531549454\n",
            "Batch: 5726 Epoch: 0\n",
            "d_loss: 0.16254231854868095\n",
            "g_loss: 0.10751058906316757\n",
            "Batch: 5727 Epoch: 0\n",
            "d_loss: 0.16254233371063265\n",
            "g_loss: 0.1067822128534317\n",
            "Batch: 5728 Epoch: 0\n",
            "d_loss: 0.16254191660203077\n",
            "g_loss: 0.10710471868515015\n",
            "Batch: 5729 Epoch: 0\n",
            "d_loss: 0.16254178658074636\n",
            "g_loss: 0.1075921505689621\n",
            "Batch: 5730 Epoch: 0\n",
            "d_loss: 0.16254193062468403\n",
            "g_loss: 0.106894351541996\n",
            "Batch: 5731 Epoch: 0\n",
            "d_loss: 0.16254172299969838\n",
            "g_loss: 0.10709865391254425\n",
            "Batch: 5732 Epoch: 0\n",
            "d_loss: 0.1625422147974973\n",
            "g_loss: 0.10775880515575409\n",
            "Batch: 5733 Epoch: 0\n",
            "d_loss: 0.16254211245664862\n",
            "g_loss: 0.1065254658460617\n",
            "Batch: 5734 Epoch: 0\n",
            "d_loss: 0.16254225942145695\n",
            "g_loss: 0.1070135086774826\n",
            "Batch: 5735 Epoch: 0\n",
            "d_loss: 0.16254194535464705\n",
            "g_loss: 0.10664762556552887\n",
            "Batch: 5736 Epoch: 0\n",
            "d_loss: 0.1625417226303867\n",
            "g_loss: 0.1072496622800827\n",
            "Batch: 5737 Epoch: 0\n",
            "d_loss: 0.16254175050478636\n",
            "g_loss: 0.10753951221704483\n",
            "Batch: 5738 Epoch: 0\n",
            "d_loss: 0.16254233365174997\n",
            "g_loss: 0.10632193088531494\n",
            "Batch: 5739 Epoch: 0\n",
            "d_loss: 0.1625417250276655\n",
            "g_loss: 0.10635042190551758\n",
            "Batch: 5740 Epoch: 0\n",
            "d_loss: 0.1625421247212273\n",
            "g_loss: 0.10731711238622665\n",
            "Batch: 5741 Epoch: 0\n",
            "d_loss: 0.16254204945690276\n",
            "g_loss: 0.10734878480434418\n",
            "Batch: 5742 Epoch: 0\n",
            "d_loss: 0.16254178111408635\n",
            "g_loss: 0.10788033902645111\n",
            "Batch: 5743 Epoch: 0\n",
            "d_loss: 0.1625438822440941\n",
            "g_loss: 0.10546950250864029\n",
            "Batch: 5744 Epoch: 0\n",
            "d_loss: 0.16254471541693505\n",
            "g_loss: 0.10801313817501068\n",
            "Batch: 5745 Epoch: 0\n",
            "d_loss: 0.16254364111564712\n",
            "g_loss: 0.10642416775226593\n",
            "Batch: 5746 Epoch: 0\n",
            "d_loss: 0.16254236597216476\n",
            "g_loss: 0.10747512429952621\n",
            "Batch: 5747 Epoch: 0\n",
            "d_loss: 0.16254236298193803\n",
            "g_loss: 0.10631201416254044\n",
            "Batch: 5748 Epoch: 0\n",
            "d_loss: 0.16254240691615962\n",
            "g_loss: 0.10677578300237656\n",
            "Batch: 5749 Epoch: 0\n",
            "d_loss: 0.16254185806080557\n",
            "g_loss: 0.10623624175786972\n",
            "Batch: 5750 Epoch: 0\n",
            "d_loss: 0.16254251059271496\n",
            "g_loss: 0.10764720290899277\n",
            "Batch: 5751 Epoch: 0\n",
            "d_loss: 0.16254249736964255\n",
            "g_loss: 0.10678708553314209\n",
            "Batch: 5752 Epoch: 0\n",
            "d_loss: 0.16254194514003473\n",
            "g_loss: 0.10776808112859726\n",
            "Batch: 5753 Epoch: 0\n",
            "d_loss: 0.16254238022197143\n",
            "g_loss: 0.10708601772785187\n",
            "Batch: 5754 Epoch: 0\n",
            "d_loss: 0.16254179675237168\n",
            "g_loss: 0.10658301413059235\n",
            "Batch: 5755 Epoch: 0\n",
            "d_loss: 0.16254322571596447\n",
            "g_loss: 0.10820917040109634\n",
            "Batch: 5756 Epoch: 0\n",
            "d_loss: 0.162544464702151\n",
            "g_loss: 0.10613803565502167\n",
            "Batch: 5757 Epoch: 0\n",
            "d_loss: 0.16254371840172155\n",
            "g_loss: 0.10798712074756622\n",
            "Batch: 5758 Epoch: 0\n",
            "d_loss: 0.16254370496052672\n",
            "g_loss: 0.10575258731842041\n",
            "Batch: 5759 Epoch: 0\n",
            "d_loss: 0.1625470579436481\n",
            "g_loss: 0.10909990221261978\n",
            "Batch: 5760 Epoch: 0\n",
            "d_loss: 0.16254829325768583\n",
            "g_loss: 0.10585131496191025\n",
            "Batch: 5761 Epoch: 0\n",
            "d_loss: 0.1625452400747065\n",
            "g_loss: 0.10824622958898544\n",
            "Batch: 5762 Epoch: 0\n",
            "d_loss: 0.1625456957878555\n",
            "g_loss: 0.1053314357995987\n",
            "Batch: 5763 Epoch: 0\n",
            "d_loss: 0.16254583455130245\n",
            "g_loss: 0.10786344856023788\n",
            "Batch: 5764 Epoch: 0\n",
            "d_loss: 0.16254729651070932\n",
            "g_loss: 0.10462813079357147\n",
            "Batch: 5765 Epoch: 0\n",
            "d_loss: 0.16254565594991988\n",
            "g_loss: 0.10697008669376373\n",
            "Batch: 5766 Epoch: 0\n",
            "d_loss: 0.1625431229192742\n",
            "g_loss: 0.10554375499486923\n",
            "Batch: 5767 Epoch: 0\n",
            "d_loss: 0.1625437363373976\n",
            "g_loss: 0.10750225931406021\n",
            "Batch: 5768 Epoch: 0\n",
            "d_loss: 0.1625427703357687\n",
            "g_loss: 0.10634087026119232\n",
            "Batch: 5769 Epoch: 0\n",
            "d_loss: 0.16254173923518778\n",
            "g_loss: 0.10671589523553848\n",
            "Batch: 5770 Epoch: 0\n",
            "d_loss: 0.1625416625104208\n",
            "g_loss: 0.10740213096141815\n",
            "Batch: 5771 Epoch: 0\n",
            "d_loss: 0.16254274020909776\n",
            "g_loss: 0.10565711557865143\n",
            "Batch: 5772 Epoch: 0\n",
            "d_loss: 0.16254297340384483\n",
            "g_loss: 0.10721328109502792\n",
            "Batch: 5773 Epoch: 0\n",
            "d_loss: 0.16254308094249126\n",
            "g_loss: 0.10556779056787491\n",
            "Batch: 5774 Epoch: 0\n",
            "d_loss: 0.16254288513548687\n",
            "g_loss: 0.10668132454156876\n",
            "Batch: 5775 Epoch: 0\n",
            "d_loss: 0.16254267613978612\n",
            "g_loss: 0.10537306219339371\n",
            "Batch: 5776 Epoch: 0\n",
            "d_loss: 0.16254388270722586\n",
            "g_loss: 0.10731036961078644\n",
            "Batch: 5777 Epoch: 0\n",
            "d_loss: 0.16254543684949851\n",
            "g_loss: 0.10460035502910614\n",
            "Batch: 5778 Epoch: 0\n",
            "d_loss: 0.1625455067785282\n",
            "g_loss: 0.10753607749938965\n",
            "Batch: 5779 Epoch: 0\n",
            "d_loss: 0.16254506054262663\n",
            "g_loss: 0.10549251735210419\n",
            "Batch: 5780 Epoch: 0\n",
            "d_loss: 0.16254434459771971\n",
            "g_loss: 0.10766477882862091\n",
            "Batch: 5781 Epoch: 0\n",
            "d_loss: 0.16254446767062802\n",
            "g_loss: 0.10572101920843124\n",
            "Batch: 5782 Epoch: 0\n",
            "d_loss: 0.16254482152417893\n",
            "g_loss: 0.10833865404129028\n",
            "Batch: 5783 Epoch: 0\n",
            "d_loss: 0.1625452397069722\n",
            "g_loss: 0.10547930002212524\n",
            "Batch: 5784 Epoch: 0\n",
            "d_loss: 0.16254436003867312\n",
            "g_loss: 0.10758952796459198\n",
            "Batch: 5785 Epoch: 0\n",
            "d_loss: 0.1625424961070152\n",
            "g_loss: 0.10654373466968536\n",
            "Batch: 5786 Epoch: 0\n",
            "d_loss: 0.16254178239853445\n",
            "g_loss: 0.10656579583883286\n",
            "Batch: 5787 Epoch: 0\n",
            "d_loss: 0.16254194659678944\n",
            "g_loss: 0.1074984073638916\n",
            "Batch: 5788 Epoch: 0\n",
            "d_loss: 0.16254180164763454\n",
            "g_loss: 0.10728368908166885\n",
            "Batch: 5789 Epoch: 0\n",
            "d_loss: 0.16254242575774214\n",
            "g_loss: 0.10806357860565186\n",
            "Batch: 5790 Epoch: 0\n",
            "d_loss: 0.16254315950627785\n",
            "g_loss: 0.10613435506820679\n",
            "Batch: 5791 Epoch: 0\n",
            "d_loss: 0.16254418171801888\n",
            "g_loss: 0.10856236517429352\n",
            "Batch: 5792 Epoch: 0\n",
            "d_loss: 0.16254655291803743\n",
            "g_loss: 0.10550745576620102\n",
            "Batch: 5793 Epoch: 0\n",
            "d_loss: 0.16254956081290572\n",
            "g_loss: 0.10954155772924423\n",
            "Batch: 5794 Epoch: 0\n",
            "d_loss: 0.16255185653216842\n",
            "g_loss: 0.10467132180929184\n",
            "Batch: 5795 Epoch: 0\n",
            "d_loss: 0.16255680180506005\n",
            "g_loss: 0.10976588726043701\n",
            "Batch: 5796 Epoch: 0\n",
            "d_loss: 0.162556266007698\n",
            "g_loss: 0.10446655750274658\n",
            "Batch: 5797 Epoch: 0\n",
            "d_loss: 0.16255537218451366\n",
            "g_loss: 0.10917539894580841\n",
            "Batch: 5798 Epoch: 0\n",
            "d_loss: 0.16255500230833775\n",
            "g_loss: 0.10403139889240265\n",
            "Batch: 5799 Epoch: 0\n",
            "d_loss: 0.16255298914468597\n",
            "g_loss: 0.10767950117588043\n",
            "Batch: 5800 Epoch: 0\n",
            "d_loss: 0.16255525546282712\n",
            "g_loss: 0.10396472364664078\n",
            "Batch: 5801 Epoch: 0\n",
            "d_loss: 0.162556016234376\n",
            "g_loss: 0.10847804695367813\n",
            "Batch: 5802 Epoch: 0\n",
            "d_loss: 0.1625510073808556\n",
            "g_loss: 0.10682082176208496\n",
            "Batch: 5803 Epoch: 0\n",
            "d_loss: 0.1625420232061927\n",
            "g_loss: 0.10606729984283447\n",
            "Batch: 5804 Epoch: 0\n",
            "d_loss: 0.16254531711922482\n",
            "g_loss: 0.10731677711009979\n",
            "Batch: 5805 Epoch: 0\n",
            "d_loss: 0.16254188641280365\n",
            "g_loss: 0.10669969022274017\n",
            "Batch: 5806 Epoch: 0\n",
            "d_loss: 0.16254202384407535\n",
            "g_loss: 0.10573601722717285\n",
            "Batch: 5807 Epoch: 0\n",
            "d_loss: 0.1625427372600612\n",
            "g_loss: 0.10689898580312729\n",
            "Batch: 5808 Epoch: 0\n",
            "d_loss: 0.16254272161531702\n",
            "g_loss: 0.1061607226729393\n",
            "Batch: 5809 Epoch: 0\n",
            "d_loss: 0.16254249924652697\n",
            "g_loss: 0.1067516952753067\n",
            "Batch: 5810 Epoch: 0\n",
            "d_loss: 0.162543037509991\n",
            "g_loss: 0.10765236616134644\n",
            "Batch: 5811 Epoch: 0\n",
            "d_loss: 0.16254412490512493\n",
            "g_loss: 0.1058649867773056\n",
            "Batch: 5812 Epoch: 0\n",
            "d_loss: 0.16254301997243203\n",
            "g_loss: 0.10664904117584229\n",
            "Batch: 5813 Epoch: 0\n",
            "d_loss: 0.1625420521406511\n",
            "g_loss: 0.1068653091788292\n",
            "Batch: 5814 Epoch: 0\n",
            "d_loss: 0.1625419035574609\n",
            "g_loss: 0.10646955668926239\n",
            "Batch: 5815 Epoch: 0\n",
            "d_loss: 0.16254221951453474\n",
            "g_loss: 0.10735686868429184\n",
            "Batch: 5816 Epoch: 0\n",
            "d_loss: 0.16254226307437136\n",
            "g_loss: 0.10648119449615479\n",
            "Batch: 5817 Epoch: 0\n",
            "d_loss: 0.16254205215997075\n",
            "g_loss: 0.1071363091468811\n",
            "Batch: 5818 Epoch: 0\n",
            "d_loss: 0.16254279805693983\n",
            "g_loss: 0.10594578087329865\n",
            "Batch: 5819 Epoch: 0\n",
            "d_loss: 0.1625422025492398\n",
            "g_loss: 0.1070050448179245\n",
            "Batch: 5820 Epoch: 0\n",
            "d_loss: 0.16254195075363498\n",
            "g_loss: 0.10638157278299332\n",
            "Batch: 5821 Epoch: 0\n",
            "d_loss: 0.16254188892077082\n",
            "g_loss: 0.10702548176050186\n",
            "Batch: 5822 Epoch: 0\n",
            "d_loss: 0.16254172676606515\n",
            "g_loss: 0.10654345899820328\n",
            "Batch: 5823 Epoch: 0\n",
            "d_loss: 0.16254244590180633\n",
            "g_loss: 0.10742104053497314\n",
            "Batch: 5824 Epoch: 0\n",
            "d_loss: 0.1625422476726186\n",
            "g_loss: 0.10640156269073486\n",
            "Batch: 5825 Epoch: 0\n",
            "d_loss: 0.16254194965624436\n",
            "g_loss: 0.10671243816614151\n",
            "Batch: 5826 Epoch: 0\n",
            "d_loss: 0.1625432300034717\n",
            "g_loss: 0.10788945853710175\n",
            "Batch: 5827 Epoch: 0\n",
            "d_loss: 0.16254416933035287\n",
            "g_loss: 0.10605774819850922\n",
            "Batch: 5828 Epoch: 0\n",
            "d_loss: 0.16254484057278518\n",
            "g_loss: 0.10762989521026611\n",
            "Batch: 5829 Epoch: 0\n",
            "d_loss: 0.16254339475692348\n",
            "g_loss: 0.10574263334274292\n",
            "Batch: 5830 Epoch: 0\n",
            "d_loss: 0.16254419812319298\n",
            "g_loss: 0.10728752613067627\n",
            "Batch: 5831 Epoch: 0\n",
            "d_loss: 0.16254320601099437\n",
            "g_loss: 0.10577990859746933\n",
            "Batch: 5832 Epoch: 0\n",
            "d_loss: 0.16254208407703885\n",
            "g_loss: 0.10636790096759796\n",
            "Batch: 5833 Epoch: 0\n",
            "d_loss: 0.162541697190008\n",
            "g_loss: 0.1068667620420456\n",
            "Batch: 5834 Epoch: 0\n",
            "d_loss: 0.16254168527716217\n",
            "g_loss: 0.10708179324865341\n",
            "Batch: 5835 Epoch: 0\n",
            "d_loss: 0.16254238251023878\n",
            "g_loss: 0.10567808151245117\n",
            "Batch: 5836 Epoch: 0\n",
            "d_loss: 0.16254468926250354\n",
            "g_loss: 0.10829804837703705\n",
            "Batch: 5837 Epoch: 0\n",
            "d_loss: 0.16254547133600283\n",
            "g_loss: 0.10526585578918457\n",
            "Batch: 5838 Epoch: 0\n",
            "d_loss: 0.16254327417087922\n",
            "g_loss: 0.10664518922567368\n",
            "Batch: 5839 Epoch: 0\n",
            "d_loss: 0.1625424398287052\n",
            "g_loss: 0.10670898109674454\n",
            "Batch: 5840 Epoch: 0\n",
            "d_loss: 0.16254308322331923\n",
            "g_loss: 0.1050942912697792\n",
            "Batch: 5841 Epoch: 0\n",
            "d_loss: 0.16254554133699628\n",
            "g_loss: 0.10803340375423431\n",
            "Batch: 5842 Epoch: 0\n",
            "d_loss: 0.16254625218605412\n",
            "g_loss: 0.10482678562402725\n",
            "Batch: 5843 Epoch: 0\n",
            "d_loss: 0.1625451961197797\n",
            "g_loss: 0.10641934722661972\n",
            "Batch: 5844 Epoch: 0\n",
            "d_loss: 0.16254368917123685\n",
            "g_loss: 0.10489694774150848\n",
            "Batch: 5845 Epoch: 0\n",
            "d_loss: 0.16254421150057397\n",
            "g_loss: 0.10708983242511749\n",
            "Batch: 5846 Epoch: 0\n",
            "d_loss: 0.1625424059636913\n",
            "g_loss: 0.10677675902843475\n",
            "Batch: 5847 Epoch: 0\n",
            "d_loss: 0.1625417524582744\n",
            "g_loss: 0.10620911419391632\n",
            "Batch: 5848 Epoch: 0\n",
            "d_loss: 0.16254179692066373\n",
            "g_loss: 0.10671286284923553\n",
            "Batch: 5849 Epoch: 0\n",
            "d_loss: 0.16254173721988963\n",
            "g_loss: 0.1063741073012352\n",
            "Batch: 5850 Epoch: 0\n",
            "d_loss: 0.16254193091964453\n",
            "g_loss: 0.10643567889928818\n",
            "Batch: 5851 Epoch: 0\n",
            "d_loss: 0.16254175752764155\n",
            "g_loss: 0.10692707449197769\n",
            "Batch: 5852 Epoch: 0\n",
            "d_loss: 0.1625419784660167\n",
            "g_loss: 0.10616759955883026\n",
            "Batch: 5853 Epoch: 0\n",
            "d_loss: 0.1625419005092752\n",
            "g_loss: 0.10690587759017944\n",
            "Batch: 5854 Epoch: 0\n",
            "d_loss: 0.16254219918535284\n",
            "g_loss: 0.10578660666942596\n",
            "Batch: 5855 Epoch: 0\n",
            "d_loss: 0.16254202387419525\n",
            "g_loss: 0.10656484216451645\n",
            "Batch: 5856 Epoch: 0\n",
            "d_loss: 0.16254175466344378\n",
            "g_loss: 0.10695476830005646\n",
            "Batch: 5857 Epoch: 0\n",
            "d_loss: 0.16254185469698257\n",
            "g_loss: 0.10625427961349487\n",
            "Batch: 5858 Epoch: 0\n",
            "d_loss: 0.16254167752394721\n",
            "g_loss: 0.10595835745334625\n",
            "Batch: 5859 Epoch: 0\n",
            "d_loss: 0.16254252844947814\n",
            "g_loss: 0.10764341056346893\n",
            "Batch: 5860 Epoch: 0\n",
            "d_loss: 0.16254486717214434\n",
            "g_loss: 0.10491053760051727\n",
            "Batch: 5861 Epoch: 0\n",
            "d_loss: 0.16254531121194304\n",
            "g_loss: 0.10720400512218475\n",
            "Batch: 5862 Epoch: 0\n",
            "d_loss: 0.16254342075065864\n",
            "g_loss: 0.10571976006031036\n",
            "Batch: 5863 Epoch: 0\n",
            "d_loss: 0.16254334684276728\n",
            "g_loss: 0.10627035051584244\n",
            "Batch: 5864 Epoch: 0\n",
            "d_loss: 0.16254192819146596\n",
            "g_loss: 0.10663387924432755\n",
            "Batch: 5865 Epoch: 0\n",
            "d_loss: 0.16254185618351613\n",
            "g_loss: 0.10642103850841522\n",
            "Batch: 5866 Epoch: 0\n",
            "d_loss: 0.16254173646971992\n",
            "g_loss: 0.1058720201253891\n",
            "Batch: 5867 Epoch: 0\n",
            "d_loss: 0.16254264700803134\n",
            "g_loss: 0.1072348803281784\n",
            "Batch: 5868 Epoch: 0\n",
            "d_loss: 0.16254296012873226\n",
            "g_loss: 0.105727419257164\n",
            "Batch: 5869 Epoch: 0\n",
            "d_loss: 0.16254314730632302\n",
            "g_loss: 0.10720650851726532\n",
            "Batch: 5870 Epoch: 0\n",
            "d_loss: 0.16254422634764154\n",
            "g_loss: 0.10471700131893158\n",
            "Batch: 5871 Epoch: 0\n",
            "d_loss: 0.16254625498316955\n",
            "g_loss: 0.10778162628412247\n",
            "Batch: 5872 Epoch: 0\n",
            "d_loss: 0.16254923365160323\n",
            "g_loss: 0.1039343923330307\n",
            "Batch: 5873 Epoch: 0\n",
            "d_loss: 0.16255127381988643\n",
            "g_loss: 0.10816460847854614\n",
            "Batch: 5874 Epoch: 0\n",
            "d_loss: 0.16255310922581145\n",
            "g_loss: 0.10388781875371933\n",
            "Batch: 5875 Epoch: 0\n",
            "d_loss: 0.16255473756459082\n",
            "g_loss: 0.10870442539453506\n",
            "Batch: 5876 Epoch: 0\n",
            "d_loss: 0.16254921804446099\n",
            "g_loss: 0.1058647409081459\n",
            "Batch: 5877 Epoch: 0\n",
            "d_loss: 0.16255009590397407\n",
            "g_loss: 0.10842056572437286\n",
            "Batch: 5878 Epoch: 0\n",
            "d_loss: 0.16255008516021974\n",
            "g_loss: 0.10405892133712769\n",
            "Batch: 5879 Epoch: 0\n",
            "d_loss: 0.16255072200224419\n",
            "g_loss: 0.10840781778097153\n",
            "Batch: 5880 Epoch: 0\n",
            "d_loss: 0.1625484119289453\n",
            "g_loss: 0.10536397993564606\n",
            "Batch: 5881 Epoch: 0\n",
            "d_loss: 0.1625443153722017\n",
            "g_loss: 0.10715975612401962\n",
            "Batch: 5882 Epoch: 0\n",
            "d_loss: 0.1625424944596574\n",
            "g_loss: 0.10664156824350357\n",
            "Batch: 5883 Epoch: 0\n",
            "d_loss: 0.1625420646016238\n",
            "g_loss: 0.10734981298446655\n",
            "Batch: 5884 Epoch: 0\n",
            "d_loss: 0.16254261648870028\n",
            "g_loss: 0.10562515258789062\n",
            "Batch: 5885 Epoch: 0\n",
            "d_loss: 0.16254361548818252\n",
            "g_loss: 0.10777697712182999\n",
            "Batch: 5886 Epoch: 0\n",
            "d_loss: 0.16254367721649743\n",
            "g_loss: 0.1056685820221901\n",
            "Batch: 5887 Epoch: 0\n",
            "d_loss: 0.16254245232079256\n",
            "g_loss: 0.10655181109905243\n",
            "Batch: 5888 Epoch: 0\n",
            "d_loss: 0.16254242383769224\n",
            "g_loss: 0.1057971864938736\n",
            "Batch: 5889 Epoch: 0\n",
            "d_loss: 0.16254276500902876\n",
            "g_loss: 0.10713176429271698\n",
            "Batch: 5890 Epoch: 0\n",
            "d_loss: 0.1625446585748591\n",
            "g_loss: 0.10457620769739151\n",
            "Batch: 5891 Epoch: 0\n",
            "d_loss: 0.1625455827658726\n",
            "g_loss: 0.10716350376605988\n",
            "Batch: 5892 Epoch: 0\n",
            "d_loss: 0.16254166089171207\n",
            "g_loss: 0.1074465960264206\n",
            "Batch: 5893 Epoch: 0\n",
            "d_loss: 0.16254535771521716\n",
            "g_loss: 0.10460201650857925\n",
            "Batch: 5894 Epoch: 0\n",
            "d_loss: 0.16254479195689697\n",
            "g_loss: 0.10651705414056778\n",
            "Batch: 5895 Epoch: 0\n",
            "d_loss: 0.16254303699205508\n",
            "g_loss: 0.10647833347320557\n",
            "Batch: 5896 Epoch: 0\n",
            "d_loss: 0.16254207986314384\n",
            "g_loss: 0.10730131715536118\n",
            "Batch: 5897 Epoch: 0\n",
            "d_loss: 0.16254507815791897\n",
            "g_loss: 0.10480640828609467\n",
            "Batch: 5898 Epoch: 0\n",
            "d_loss: 0.1625507667925632\n",
            "g_loss: 0.10675988346338272\n",
            "Batch: 5899 Epoch: 0\n",
            "d_loss: 0.16254782275046864\n",
            "g_loss: 0.10612399876117706\n",
            "Batch: 5900 Epoch: 0\n",
            "d_loss: 0.16254328341417335\n",
            "g_loss: 0.10702149569988251\n",
            "Batch: 5901 Epoch: 0\n",
            "d_loss: 0.16254260729702708\n",
            "g_loss: 0.10598697513341904\n",
            "Batch: 5902 Epoch: 0\n",
            "d_loss: 0.1625432907307527\n",
            "g_loss: 0.10741450637578964\n",
            "Batch: 5903 Epoch: 0\n",
            "d_loss: 0.16254286389536077\n",
            "g_loss: 0.10606127977371216\n",
            "Batch: 5904 Epoch: 0\n",
            "d_loss: 0.1625435175508514\n",
            "g_loss: 0.1074196919798851\n",
            "Batch: 5905 Epoch: 0\n",
            "d_loss: 0.1625428021272981\n",
            "g_loss: 0.10620303452014923\n",
            "Batch: 5906 Epoch: 0\n",
            "d_loss: 0.16254194092261542\n",
            "g_loss: 0.1069444790482521\n",
            "Batch: 5907 Epoch: 0\n",
            "d_loss: 0.16254185033214696\n",
            "g_loss: 0.10730868577957153\n",
            "Batch: 5908 Epoch: 0\n",
            "d_loss: 0.16254190682631986\n",
            "g_loss: 0.10701216757297516\n",
            "Batch: 5909 Epoch: 0\n",
            "d_loss: 0.16254177552882254\n",
            "g_loss: 0.10690740495920181\n",
            "Batch: 5910 Epoch: 0\n",
            "d_loss: 0.16254231009592246\n",
            "g_loss: 0.10610377788543701\n",
            "Batch: 5911 Epoch: 0\n",
            "d_loss: 0.16254296715928973\n",
            "g_loss: 0.10782420635223389\n",
            "Batch: 5912 Epoch: 0\n",
            "d_loss: 0.16254405566905916\n",
            "g_loss: 0.10524483770132065\n",
            "Batch: 5913 Epoch: 0\n",
            "d_loss: 0.16254381801125817\n",
            "g_loss: 0.10687445104122162\n",
            "Batch: 5914 Epoch: 0\n",
            "d_loss: 0.162542562208273\n",
            "g_loss: 0.10647609084844589\n",
            "Batch: 5915 Epoch: 0\n",
            "d_loss: 0.16254259538983717\n",
            "g_loss: 0.10565292835235596\n",
            "Batch: 5916 Epoch: 0\n",
            "d_loss: 0.16254298036811576\n",
            "g_loss: 0.10744550079107285\n",
            "Batch: 5917 Epoch: 0\n",
            "d_loss: 0.16254347122013257\n",
            "g_loss: 0.10559165477752686\n",
            "Batch: 5918 Epoch: 0\n",
            "d_loss: 0.16254285948831182\n",
            "g_loss: 0.10709936916828156\n",
            "Batch: 5919 Epoch: 0\n",
            "d_loss: 0.16254224893398117\n",
            "g_loss: 0.10630987584590912\n",
            "Batch: 5920 Epoch: 0\n",
            "d_loss: 0.1625417293224558\n",
            "g_loss: 0.10649075359106064\n",
            "Batch: 5921 Epoch: 0\n",
            "d_loss: 0.16254169613355174\n",
            "g_loss: 0.10695578902959824\n",
            "Batch: 5922 Epoch: 0\n",
            "d_loss: 0.16254177314194607\n",
            "g_loss: 0.10632850229740143\n",
            "Batch: 5923 Epoch: 0\n",
            "d_loss: 0.16254174078331118\n",
            "g_loss: 0.10677479207515717\n",
            "Batch: 5924 Epoch: 0\n",
            "d_loss: 0.16254166653506985\n",
            "g_loss: 0.10661336034536362\n",
            "Batch: 5925 Epoch: 0\n",
            "d_loss: 0.1625417267248821\n",
            "g_loss: 0.10625024884939194\n",
            "Batch: 5926 Epoch: 0\n",
            "d_loss: 0.1625418614828149\n",
            "g_loss: 0.10694490373134613\n",
            "Batch: 5927 Epoch: 0\n",
            "d_loss: 0.16254172558507207\n",
            "g_loss: 0.10680665075778961\n",
            "Batch: 5928 Epoch: 0\n",
            "d_loss: 0.16254202707341392\n",
            "g_loss: 0.10696098953485489\n",
            "Batch: 5929 Epoch: 0\n",
            "d_loss: 0.16254221857459328\n",
            "g_loss: 0.105698361992836\n",
            "Batch: 5930 Epoch: 0\n",
            "d_loss: 0.16254296272996527\n",
            "g_loss: 0.10737298429012299\n",
            "Batch: 5931 Epoch: 0\n",
            "d_loss: 0.162542918661309\n",
            "g_loss: 0.10616620630025864\n",
            "Batch: 5932 Epoch: 0\n",
            "d_loss: 0.1625421933672726\n",
            "g_loss: 0.10667558014392853\n",
            "Batch: 5933 Epoch: 0\n",
            "d_loss: 0.16254171788274618\n",
            "g_loss: 0.10683455318212509\n",
            "Batch: 5934 Epoch: 0\n",
            "d_loss: 0.16254171241185134\n",
            "g_loss: 0.1072712317109108\n",
            "Batch: 5935 Epoch: 0\n",
            "d_loss: 0.16254213068936707\n",
            "g_loss: 0.10632260143756866\n",
            "Batch: 5936 Epoch: 0\n",
            "d_loss: 0.16254202530473094\n",
            "g_loss: 0.10700052976608276\n",
            "Batch: 5937 Epoch: 0\n",
            "d_loss: 0.16254177007131432\n",
            "g_loss: 0.1065634936094284\n",
            "Batch: 5938 Epoch: 0\n",
            "d_loss: 0.16254181564351455\n",
            "g_loss: 0.10656722635030746\n",
            "Batch: 5939 Epoch: 0\n",
            "d_loss: 0.16254172419955637\n",
            "g_loss: 0.10662315040826797\n",
            "Batch: 5940 Epoch: 0\n",
            "d_loss: 0.16254160481067004\n",
            "g_loss: 0.10638966411352158\n",
            "Batch: 5941 Epoch: 0\n",
            "d_loss: 0.1625417452432103\n",
            "g_loss: 0.1069416031241417\n",
            "Batch: 5942 Epoch: 0\n",
            "d_loss: 0.16254178419197984\n",
            "g_loss: 0.10642359405755997\n",
            "Batch: 5943 Epoch: 0\n",
            "d_loss: 0.1625416081796658\n",
            "g_loss: 0.10640789568424225\n",
            "Batch: 5944 Epoch: 0\n",
            "d_loss: 0.1625419172122804\n",
            "g_loss: 0.10717467218637466\n",
            "Batch: 5945 Epoch: 0\n",
            "d_loss: 0.162542008574448\n",
            "g_loss: 0.10618947446346283\n",
            "Batch: 5946 Epoch: 0\n",
            "d_loss: 0.16254190281033232\n",
            "g_loss: 0.10686397552490234\n",
            "Batch: 5947 Epoch: 0\n",
            "d_loss: 0.16254237973952002\n",
            "g_loss: 0.10570385307073593\n",
            "Batch: 5948 Epoch: 0\n",
            "d_loss: 0.1625431537578379\n",
            "g_loss: 0.10761703550815582\n",
            "Batch: 5949 Epoch: 0\n",
            "d_loss: 0.1625445434197772\n",
            "g_loss: 0.10538037121295929\n",
            "Batch: 5950 Epoch: 0\n",
            "d_loss: 0.16254463098662342\n",
            "g_loss: 0.10733835399150848\n",
            "Batch: 5951 Epoch: 0\n",
            "d_loss: 0.16254255794100914\n",
            "g_loss: 0.10664188861846924\n",
            "Batch: 5952 Epoch: 0\n",
            "d_loss: 0.16254187316046398\n",
            "g_loss: 0.10707638412714005\n",
            "Batch: 5953 Epoch: 0\n",
            "d_loss: 0.1625419778099868\n",
            "g_loss: 0.10663847625255585\n",
            "Batch: 5954 Epoch: 0\n",
            "d_loss: 0.16254179324977258\n",
            "g_loss: 0.10665558278560638\n",
            "Batch: 5955 Epoch: 0\n",
            "d_loss: 0.16254157420616622\n",
            "g_loss: 0.10666783899068832\n",
            "Batch: 5956 Epoch: 0\n",
            "d_loss: 0.1625426655248603\n",
            "g_loss: 0.10501547157764435\n",
            "Batch: 5957 Epoch: 0\n",
            "d_loss: 0.16254627383216302\n",
            "g_loss: 0.10812593996524811\n",
            "Batch: 5958 Epoch: 0\n",
            "d_loss: 0.16254801393490226\n",
            "g_loss: 0.10461300611495972\n",
            "Batch: 5959 Epoch: 0\n",
            "d_loss: 0.16254625553776236\n",
            "g_loss: 0.10738448053598404\n",
            "Batch: 5960 Epoch: 0\n",
            "d_loss: 0.16254367729510477\n",
            "g_loss: 0.10574553161859512\n",
            "Batch: 5961 Epoch: 0\n",
            "d_loss: 0.16254200735340874\n",
            "g_loss: 0.10621857643127441\n",
            "Batch: 5962 Epoch: 0\n",
            "d_loss: 0.16254217198704168\n",
            "g_loss: 0.10768936574459076\n",
            "Batch: 5963 Epoch: 0\n",
            "d_loss: 0.16254431872242492\n",
            "g_loss: 0.10516756772994995\n",
            "Batch: 5964 Epoch: 0\n",
            "d_loss: 0.16254686782554728\n",
            "g_loss: 0.10815393924713135\n",
            "Batch: 5965 Epoch: 0\n",
            "d_loss: 0.1625467457768508\n",
            "g_loss: 0.10499478876590729\n",
            "Batch: 5966 Epoch: 0\n",
            "d_loss: 0.16254589442146283\n",
            "g_loss: 0.10767795145511627\n",
            "Batch: 5967 Epoch: 0\n",
            "d_loss: 0.16254577758390099\n",
            "g_loss: 0.10501495748758316\n",
            "Batch: 5968 Epoch: 0\n",
            "d_loss: 0.1625447161399478\n",
            "g_loss: 0.10747452080249786\n",
            "Batch: 5969 Epoch: 0\n",
            "d_loss: 0.1625428732741412\n",
            "g_loss: 0.10694209486246109\n",
            "Batch: 5970 Epoch: 0\n",
            "d_loss: 0.1625423973627136\n",
            "g_loss: 0.10710899531841278\n",
            "Batch: 5971 Epoch: 0\n",
            "d_loss: 0.16254196344763017\n",
            "g_loss: 0.10617021471261978\n",
            "Batch: 5972 Epoch: 0\n",
            "d_loss: 0.16254196355204442\n",
            "g_loss: 0.10677739232778549\n",
            "Batch: 5973 Epoch: 0\n",
            "d_loss: 0.16254238705978707\n",
            "g_loss: 0.10538098961114883\n",
            "Batch: 5974 Epoch: 0\n",
            "d_loss: 0.16254345244500712\n",
            "g_loss: 0.1073065996170044\n",
            "Batch: 5975 Epoch: 0\n",
            "d_loss: 0.16254415754532658\n",
            "g_loss: 0.10530911386013031\n",
            "Batch: 5976 Epoch: 0\n",
            "d_loss: 0.1625467892573198\n",
            "g_loss: 0.10896982997655869\n",
            "Batch: 5977 Epoch: 0\n",
            "d_loss: 0.1625532321118186\n",
            "g_loss: 0.10393495857715607\n",
            "Batch: 5978 Epoch: 0\n",
            "d_loss: 0.16255363347739404\n",
            "g_loss: 0.10825742781162262\n",
            "Batch: 5979 Epoch: 0\n",
            "d_loss: 0.16255357461307085\n",
            "g_loss: 0.10373963415622711\n",
            "Batch: 5980 Epoch: 0\n",
            "d_loss: 0.16254871500824208\n",
            "g_loss: 0.10697458684444427\n",
            "Batch: 5981 Epoch: 0\n",
            "d_loss: 0.16254527612873204\n",
            "g_loss: 0.10557077080011368\n",
            "Batch: 5982 Epoch: 0\n",
            "d_loss: 0.1625427232000476\n",
            "g_loss: 0.10650543868541718\n",
            "Batch: 5983 Epoch: 0\n",
            "d_loss: 0.1625421741116\n",
            "g_loss: 0.1063990369439125\n",
            "Batch: 5984 Epoch: 0\n",
            "d_loss: 0.16254200922469408\n",
            "g_loss: 0.10654699802398682\n",
            "Batch: 5985 Epoch: 0\n",
            "d_loss: 0.162542245403138\n",
            "g_loss: 0.10641787201166153\n",
            "Batch: 5986 Epoch: 0\n",
            "d_loss: 0.16254193348884627\n",
            "g_loss: 0.1069893017411232\n",
            "Batch: 5987 Epoch: 0\n",
            "d_loss: 0.1625423827443413\n",
            "g_loss: 0.10577619075775146\n",
            "Batch: 5988 Epoch: 0\n",
            "d_loss: 0.16254238337057814\n",
            "g_loss: 0.10689425468444824\n",
            "Batch: 5989 Epoch: 0\n",
            "d_loss: 0.16254202166143017\n",
            "g_loss: 0.10658104717731476\n",
            "Batch: 5990 Epoch: 0\n",
            "d_loss: 0.16254198022916455\n",
            "g_loss: 0.10567964613437653\n",
            "Batch: 5991 Epoch: 0\n",
            "d_loss: 0.16254260480401683\n",
            "g_loss: 0.10722623020410538\n",
            "Batch: 5992 Epoch: 0\n",
            "d_loss: 0.16254211501340876\n",
            "g_loss: 0.10640867054462433\n",
            "Batch: 5993 Epoch: 0\n",
            "d_loss: 0.16254190400928792\n",
            "g_loss: 0.10548202693462372\n",
            "Batch: 5994 Epoch: 0\n",
            "d_loss: 0.1625437499122171\n",
            "g_loss: 0.10770086944103241\n",
            "Batch: 5995 Epoch: 0\n",
            "d_loss: 0.16254378298235395\n",
            "g_loss: 0.10565292835235596\n",
            "Batch: 5996 Epoch: 0\n",
            "d_loss: 0.16254279617790246\n",
            "g_loss: 0.1071188896894455\n",
            "Batch: 5997 Epoch: 0\n",
            "d_loss: 0.16254200643081163\n",
            "g_loss: 0.10682947933673859\n",
            "Batch: 5998 Epoch: 0\n",
            "d_loss: 0.16254163410575018\n",
            "g_loss: 0.10645260661840439\n",
            "Batch: 5999 Epoch: 0\n",
            "d_loss: 0.1625416932622059\n",
            "g_loss: 0.10678086429834366\n",
            "Batch: 6000 Epoch: 0\n",
            "d_loss: 0.1625419028775923\n",
            "g_loss: 0.10636098682880402\n",
            "Batch: 6001 Epoch: 0\n",
            "d_loss: 0.16254166491184208\n",
            "g_loss: 0.10674822330474854\n",
            "Batch: 6002 Epoch: 0\n",
            "d_loss: 0.1625418133896659\n",
            "g_loss: 0.10740615427494049\n",
            "Batch: 6003 Epoch: 0\n",
            "d_loss: 0.16254354848691577\n",
            "g_loss: 0.10511883348226547\n",
            "Batch: 6004 Epoch: 0\n",
            "d_loss: 0.16254428635899387\n",
            "g_loss: 0.10770899057388306\n",
            "Batch: 6005 Epoch: 0\n",
            "d_loss: 0.1625438009100293\n",
            "g_loss: 0.10579274594783783\n",
            "Batch: 6006 Epoch: 0\n",
            "d_loss: 0.16254309392541444\n",
            "g_loss: 0.10733828693628311\n",
            "Batch: 6007 Epoch: 0\n",
            "d_loss: 0.1625429609682172\n",
            "g_loss: 0.10570899397134781\n",
            "Batch: 6008 Epoch: 0\n",
            "d_loss: 0.16254436145849382\n",
            "g_loss: 0.1078934445977211\n",
            "Batch: 6009 Epoch: 0\n",
            "d_loss: 0.16254464505807675\n",
            "g_loss: 0.10531558096408844\n",
            "Batch: 6010 Epoch: 0\n",
            "d_loss: 0.16254428618510985\n",
            "g_loss: 0.10741572082042694\n",
            "Batch: 6011 Epoch: 0\n",
            "d_loss: 0.16254276822371594\n",
            "g_loss: 0.10589977353811264\n",
            "Batch: 6012 Epoch: 0\n",
            "d_loss: 0.16254242410530395\n",
            "g_loss: 0.1061067134141922\n",
            "Batch: 6013 Epoch: 0\n",
            "d_loss: 0.16254224609220103\n",
            "g_loss: 0.10550198704004288\n",
            "Batch: 6014 Epoch: 0\n",
            "d_loss: 0.16254221753701614\n",
            "g_loss: 0.10606862604618073\n",
            "Batch: 6015 Epoch: 0\n",
            "d_loss: 0.16254261825905303\n",
            "g_loss: 0.10656166076660156\n",
            "Batch: 6016 Epoch: 0\n",
            "d_loss: 0.1625432148392818\n",
            "g_loss: 0.10506638139486313\n",
            "Batch: 6017 Epoch: 0\n",
            "d_loss: 0.16254434811200014\n",
            "g_loss: 0.10742638260126114\n",
            "Batch: 6018 Epoch: 0\n",
            "d_loss: 0.16254345427446282\n",
            "g_loss: 0.10612829029560089\n",
            "Batch: 6019 Epoch: 0\n",
            "d_loss: 0.16254242366825622\n",
            "g_loss: 0.10738470405340195\n",
            "Batch: 6020 Epoch: 0\n",
            "d_loss: 0.16254299327239607\n",
            "g_loss: 0.10639548301696777\n",
            "Batch: 6021 Epoch: 0\n",
            "d_loss: 0.16254172596605798\n",
            "g_loss: 0.10607738792896271\n",
            "Batch: 6022 Epoch: 0\n",
            "d_loss: 0.16254178629363025\n",
            "g_loss: 0.10630901902914047\n",
            "Batch: 6023 Epoch: 0\n",
            "d_loss: 0.16254217167452367\n",
            "g_loss: 0.10701227188110352\n",
            "Batch: 6024 Epoch: 0\n",
            "d_loss: 0.16254320385282028\n",
            "g_loss: 0.10516346991062164\n",
            "Batch: 6025 Epoch: 0\n",
            "d_loss: 0.16254416879299072\n",
            "g_loss: 0.10743384063243866\n",
            "Batch: 6026 Epoch: 0\n",
            "d_loss: 0.1625435732027114\n",
            "g_loss: 0.10542887449264526\n",
            "Batch: 6027 Epoch: 0\n",
            "d_loss: 0.16254285464405882\n",
            "g_loss: 0.1068228930234909\n",
            "Batch: 6028 Epoch: 0\n",
            "d_loss: 0.16254193202476586\n",
            "g_loss: 0.10636965930461884\n",
            "Batch: 6029 Epoch: 0\n",
            "d_loss: 0.16254184547121042\n",
            "g_loss: 0.10548423230648041\n",
            "Batch: 6030 Epoch: 0\n",
            "d_loss: 0.162542394750389\n",
            "g_loss: 0.10655298084020615\n",
            "Batch: 6031 Epoch: 0\n",
            "d_loss: 0.16254247550041612\n",
            "g_loss: 0.10536609590053558\n",
            "Batch: 6032 Epoch: 0\n",
            "d_loss: 0.1625442711768912\n",
            "g_loss: 0.10753285884857178\n",
            "Batch: 6033 Epoch: 0\n",
            "d_loss: 0.16254780797215318\n",
            "g_loss: 0.10410401970148087\n",
            "Batch: 6034 Epoch: 0\n",
            "d_loss: 0.16254823493259352\n",
            "g_loss: 0.10763265937566757\n",
            "Batch: 6035 Epoch: 0\n",
            "d_loss: 0.16254470192625092\n",
            "g_loss: 0.1063276082277298\n",
            "Batch: 6036 Epoch: 0\n",
            "d_loss: 0.1625417821138484\n",
            "g_loss: 0.10571006685495377\n",
            "Batch: 6037 Epoch: 0\n",
            "d_loss: 0.1625420962414026\n",
            "g_loss: 0.10642099380493164\n",
            "Batch: 6038 Epoch: 0\n",
            "d_loss: 0.16254184603290867\n",
            "g_loss: 0.10610570013523102\n",
            "Batch: 6039 Epoch: 0\n",
            "d_loss: 0.16254165165645418\n",
            "g_loss: 0.10627274215221405\n",
            "Batch: 6040 Epoch: 0\n",
            "d_loss: 0.1625416327844036\n",
            "g_loss: 0.1060328483581543\n",
            "Batch: 6041 Epoch: 0\n",
            "d_loss: 0.16254207994985848\n",
            "g_loss: 0.10724091529846191\n",
            "Batch: 6042 Epoch: 0\n",
            "d_loss: 0.1625439143015015\n",
            "g_loss: 0.1049705371260643\n",
            "Batch: 6043 Epoch: 0\n",
            "d_loss: 0.16254529774548843\n",
            "g_loss: 0.10762449353933334\n",
            "Batch: 6044 Epoch: 0\n",
            "d_loss: 0.1625444779093712\n",
            "g_loss: 0.10573376715183258\n",
            "Batch: 6045 Epoch: 0\n",
            "d_loss: 0.1625437621479051\n",
            "g_loss: 0.10742384195327759\n",
            "Batch: 6046 Epoch: 0\n",
            "d_loss: 0.16254401640982508\n",
            "g_loss: 0.10558225959539413\n",
            "Batch: 6047 Epoch: 0\n",
            "d_loss: 0.1625437480614309\n",
            "g_loss: 0.10712073743343353\n",
            "Batch: 6048 Epoch: 0\n",
            "d_loss: 0.1625432409163423\n",
            "g_loss: 0.10553556680679321\n",
            "Batch: 6049 Epoch: 0\n",
            "d_loss: 0.16254384775886876\n",
            "g_loss: 0.10761038959026337\n",
            "Batch: 6050 Epoch: 0\n",
            "d_loss: 0.16254415029555958\n",
            "g_loss: 0.10532452911138535\n",
            "Batch: 6051 Epoch: 0\n",
            "d_loss: 0.1625439856880888\n",
            "g_loss: 0.1072072759270668\n",
            "Batch: 6052 Epoch: 0\n",
            "d_loss: 0.16254303166882522\n",
            "g_loss: 0.10554194450378418\n",
            "Batch: 6053 Epoch: 0\n",
            "d_loss: 0.1625426740519913\n",
            "g_loss: 0.10694883018732071\n",
            "Batch: 6054 Epoch: 0\n",
            "d_loss: 0.16254274816962777\n",
            "g_loss: 0.10561463981866837\n",
            "Batch: 6055 Epoch: 0\n",
            "d_loss: 0.16254265957699232\n",
            "g_loss: 0.10688616335391998\n",
            "Batch: 6056 Epoch: 0\n",
            "d_loss: 0.16254339432250475\n",
            "g_loss: 0.10555150359869003\n",
            "Batch: 6057 Epoch: 0\n",
            "d_loss: 0.16254288185398735\n",
            "g_loss: 0.10688622295856476\n",
            "Batch: 6058 Epoch: 0\n",
            "d_loss: 0.16254331397896493\n",
            "g_loss: 0.10469502210617065\n",
            "Batch: 6059 Epoch: 0\n",
            "d_loss: 0.16254349470104756\n",
            "g_loss: 0.1064092367887497\n",
            "Batch: 6060 Epoch: 0\n",
            "d_loss: 0.1625427335507652\n",
            "g_loss: 0.10523611307144165\n",
            "Batch: 6061 Epoch: 0\n",
            "d_loss: 0.16254265867013373\n",
            "g_loss: 0.10599277913570404\n",
            "Batch: 6062 Epoch: 0\n",
            "d_loss: 0.162541791471277\n",
            "g_loss: 0.10574573278427124\n",
            "Batch: 6063 Epoch: 0\n",
            "d_loss: 0.16254167776634176\n",
            "g_loss: 0.10525987297296524\n",
            "Batch: 6064 Epoch: 0\n",
            "d_loss: 0.16254170523344413\n",
            "g_loss: 0.10543543100357056\n",
            "Batch: 6065 Epoch: 0\n",
            "d_loss: 0.16254189979260758\n",
            "g_loss: 0.10571136325597763\n",
            "Batch: 6066 Epoch: 0\n",
            "d_loss: 0.16254230773794376\n",
            "g_loss: 0.10495146363973618\n",
            "Batch: 6067 Epoch: 0\n",
            "d_loss: 0.1625427423672221\n",
            "g_loss: 0.10638701915740967\n",
            "Batch: 6068 Epoch: 0\n",
            "d_loss: 0.162543571609703\n",
            "g_loss: 0.10642323642969131\n",
            "Batch: 6069 Epoch: 0\n",
            "d_loss: 0.16254196023083267\n",
            "g_loss: 0.10607512295246124\n",
            "Batch: 6070 Epoch: 0\n",
            "d_loss: 0.1625421261440536\n",
            "g_loss: 0.1053154245018959\n",
            "Batch: 6071 Epoch: 0\n",
            "d_loss: 0.16254219664448044\n",
            "g_loss: 0.10631178319454193\n",
            "Batch: 6072 Epoch: 0\n",
            "d_loss: 0.16254231608844805\n",
            "g_loss: 0.10525914281606674\n",
            "Batch: 6073 Epoch: 0\n",
            "d_loss: 0.1625420933258681\n",
            "g_loss: 0.10615336894989014\n",
            "Batch: 6074 Epoch: 0\n",
            "d_loss: 0.1625419439405178\n",
            "g_loss: 0.106614850461483\n",
            "Batch: 6075 Epoch: 0\n",
            "d_loss: 0.16254209359888705\n",
            "g_loss: 0.10569904744625092\n",
            "Batch: 6076 Epoch: 0\n",
            "d_loss: 0.162542245073368\n",
            "g_loss: 0.10674812644720078\n",
            "Batch: 6077 Epoch: 0\n",
            "d_loss: 0.16254274922385292\n",
            "g_loss: 0.10514605045318604\n",
            "Batch: 6078 Epoch: 0\n",
            "d_loss: 0.1625432103539879\n",
            "g_loss: 0.10690551996231079\n",
            "Batch: 6079 Epoch: 0\n",
            "d_loss: 0.162542631039841\n",
            "g_loss: 0.10577765852212906\n",
            "Batch: 6080 Epoch: 0\n",
            "d_loss: 0.16254259912361846\n",
            "g_loss: 0.10686129331588745\n",
            "Batch: 6081 Epoch: 0\n",
            "d_loss: 0.1625423917975226\n",
            "g_loss: 0.10567314922809601\n",
            "Batch: 6082 Epoch: 0\n",
            "d_loss: 0.1625422128351488\n",
            "g_loss: 0.106833316385746\n",
            "Batch: 6083 Epoch: 0\n",
            "d_loss: 0.16254216695274692\n",
            "g_loss: 0.10624773800373077\n",
            "Batch: 6084 Epoch: 0\n",
            "d_loss: 0.1625416465129348\n",
            "g_loss: 0.10609517246484756\n",
            "Batch: 6085 Epoch: 0\n",
            "d_loss: 0.16254173478770895\n",
            "g_loss: 0.10607025772333145\n",
            "Batch: 6086 Epoch: 0\n",
            "d_loss: 0.16254230091604427\n",
            "g_loss: 0.10503163188695908\n",
            "Batch: 6087 Epoch: 0\n",
            "d_loss: 0.16254467180014842\n",
            "g_loss: 0.10811638832092285\n",
            "Batch: 6088 Epoch: 0\n",
            "d_loss: 0.16255024345284852\n",
            "g_loss: 0.10387550294399261\n",
            "Batch: 6089 Epoch: 0\n",
            "d_loss: 0.1625514355390436\n",
            "g_loss: 0.1087331548333168\n",
            "Batch: 6090 Epoch: 0\n",
            "d_loss: 0.16254751490241404\n",
            "g_loss: 0.10566858947277069\n",
            "Batch: 6091 Epoch: 0\n",
            "d_loss: 0.16254731963741165\n",
            "g_loss: 0.10854785144329071\n",
            "Batch: 6092 Epoch: 0\n",
            "d_loss: 0.16255368758153566\n",
            "g_loss: 0.10460929572582245\n",
            "Batch: 6093 Epoch: 0\n",
            "d_loss: 0.16255578549520067\n",
            "g_loss: 0.10953228175640106\n",
            "Batch: 6094 Epoch: 0\n",
            "d_loss: 0.1625579320420698\n",
            "g_loss: 0.10303565114736557\n",
            "Batch: 6095 Epoch: 0\n",
            "d_loss: 0.1625560109016817\n",
            "g_loss: 0.10804350674152374\n",
            "Batch: 6096 Epoch: 0\n",
            "d_loss: 0.1625546826430977\n",
            "g_loss: 0.10422278940677643\n",
            "Batch: 6097 Epoch: 0\n",
            "d_loss: 0.16255194261464112\n",
            "g_loss: 0.10947517305612564\n",
            "Batch: 6098 Epoch: 0\n",
            "d_loss: 0.1625601074737375\n",
            "g_loss: 0.10398797690868378\n",
            "Batch: 6099 Epoch: 0\n",
            "d_loss: 0.16255489296530357\n",
            "g_loss: 0.10823632776737213\n",
            "Batch: 6100 Epoch: 0\n",
            "d_loss: 0.1625490326511212\n",
            "g_loss: 0.10964357852935791\n",
            "Batch: 6101 Epoch: 0\n",
            "d_loss: 0.16255162814606194\n",
            "g_loss: 0.10394718497991562\n",
            "Batch: 6102 Epoch: 0\n",
            "d_loss: 0.1625469941599178\n",
            "g_loss: 0.10637541860342026\n",
            "Batch: 6103 Epoch: 0\n",
            "d_loss: 0.1625438343647687\n",
            "g_loss: 0.10737717151641846\n",
            "Batch: 6104 Epoch: 0\n",
            "d_loss: 0.16254367227679722\n",
            "g_loss: 0.10563163459300995\n",
            "Batch: 6105 Epoch: 0\n",
            "d_loss: 0.16254729030843507\n",
            "g_loss: 0.10841460525989532\n",
            "Batch: 6106 Epoch: 0\n",
            "d_loss: 0.1625471458513701\n",
            "g_loss: 0.10515940189361572\n",
            "Batch: 6107 Epoch: 0\n",
            "d_loss: 0.16255019631066858\n",
            "g_loss: 0.10826046764850616\n",
            "Batch: 6108 Epoch: 0\n",
            "d_loss: 0.16254824528175504\n",
            "g_loss: 0.10507453978061676\n",
            "Batch: 6109 Epoch: 0\n",
            "d_loss: 0.1625560677417326\n",
            "g_loss: 0.1090756207704544\n",
            "Batch: 6110 Epoch: 0\n",
            "d_loss: 0.16256369962327\n",
            "g_loss: 0.10245339572429657\n",
            "Batch: 6111 Epoch: 0\n",
            "d_loss: 0.16256008047590598\n",
            "g_loss: 0.1077343001961708\n",
            "Batch: 6112 Epoch: 0\n",
            "d_loss: 0.1625488317127406\n",
            "g_loss: 0.10506956279277802\n",
            "Batch: 6113 Epoch: 0\n",
            "d_loss: 0.16254214011182455\n",
            "g_loss: 0.10465025901794434\n",
            "Batch: 6114 Epoch: 0\n",
            "d_loss: 0.16254754856503695\n",
            "g_loss: 0.10770908743143082\n",
            "Batch: 6115 Epoch: 0\n",
            "d_loss: 0.1625514413515461\n",
            "g_loss: 0.10395397245883942\n",
            "Batch: 6116 Epoch: 0\n",
            "d_loss: 0.16255055643573968\n",
            "g_loss: 0.10752560943365097\n",
            "Batch: 6117 Epoch: 0\n",
            "d_loss: 0.16254557784439783\n",
            "g_loss: 0.10686574876308441\n",
            "Batch: 6118 Epoch: 0\n",
            "d_loss: 0.16254231434589883\n",
            "g_loss: 0.10791052877902985\n",
            "Batch: 6119 Epoch: 0\n",
            "d_loss: 0.1625492196718028\n",
            "g_loss: 0.10491503775119781\n",
            "Batch: 6120 Epoch: 0\n",
            "d_loss: 0.1625493243936944\n",
            "g_loss: 0.10790778696537018\n",
            "Batch: 6121 Epoch: 0\n",
            "d_loss: 0.16254374476282862\n",
            "g_loss: 0.10690771043300629\n",
            "Batch: 6122 Epoch: 0\n",
            "d_loss: 0.16254177975124406\n",
            "g_loss: 0.10595233738422394\n",
            "Batch: 6123 Epoch: 0\n",
            "d_loss: 0.16254248104535662\n",
            "g_loss: 0.10712940990924835\n",
            "Batch: 6124 Epoch: 0\n",
            "d_loss: 0.16254261158286454\n",
            "g_loss: 0.10569461435079575\n",
            "Batch: 6125 Epoch: 0\n",
            "d_loss: 0.16254505817159526\n",
            "g_loss: 0.1063610091805458\n",
            "Batch: 6126 Epoch: 0\n",
            "d_loss: 0.16254274166690408\n",
            "g_loss: 0.10533080995082855\n",
            "Batch: 6127 Epoch: 0\n",
            "d_loss: 0.16254453206464348\n",
            "g_loss: 0.10716744512319565\n",
            "Batch: 6128 Epoch: 0\n",
            "d_loss: 0.16254403190153965\n",
            "g_loss: 0.10545085370540619\n",
            "Batch: 6129 Epoch: 0\n",
            "d_loss: 0.16254270137767435\n",
            "g_loss: 0.10643742233514786\n",
            "Batch: 6130 Epoch: 0\n",
            "d_loss: 0.16254271924949393\n",
            "g_loss: 0.10530481487512589\n",
            "Batch: 6131 Epoch: 0\n",
            "d_loss: 0.16254195765409207\n",
            "g_loss: 0.10599787533283234\n",
            "Batch: 6132 Epoch: 0\n",
            "d_loss: 0.16254264163422505\n",
            "g_loss: 0.10784076154232025\n",
            "Batch: 6133 Epoch: 0\n",
            "d_loss: 0.16254447466840105\n",
            "g_loss: 0.10547151416540146\n",
            "Batch: 6134 Epoch: 0\n",
            "d_loss: 0.16254292611900212\n",
            "g_loss: 0.10683895647525787\n",
            "Batch: 6135 Epoch: 0\n",
            "d_loss: 0.16254238696956946\n",
            "g_loss: 0.1058882474899292\n",
            "Batch: 6136 Epoch: 0\n",
            "d_loss: 0.162542673412176\n",
            "g_loss: 0.10706033557653427\n",
            "Batch: 6137 Epoch: 0\n",
            "d_loss: 0.1625422550214921\n",
            "g_loss: 0.10584545135498047\n",
            "Batch: 6138 Epoch: 0\n",
            "d_loss: 0.16254223808770618\n",
            "g_loss: 0.10676930099725723\n",
            "Batch: 6139 Epoch: 0\n",
            "d_loss: 0.16254190200064755\n",
            "g_loss: 0.10691837966442108\n",
            "Batch: 6140 Epoch: 0\n",
            "d_loss: 0.16254355092248574\n",
            "g_loss: 0.10499642044305801\n",
            "Batch: 6141 Epoch: 0\n",
            "d_loss: 0.16254853997335061\n",
            "g_loss: 0.10863927751779556\n",
            "Batch: 6142 Epoch: 0\n",
            "d_loss: 0.16254757924842522\n",
            "g_loss: 0.10507657378911972\n",
            "Batch: 6143 Epoch: 0\n",
            "d_loss: 0.16254511675314376\n",
            "g_loss: 0.10730677843093872\n",
            "Batch: 6144 Epoch: 0\n",
            "d_loss: 0.1625428956845667\n",
            "g_loss: 0.10610385239124298\n",
            "Batch: 6145 Epoch: 0\n",
            "d_loss: 0.16254472976756063\n",
            "g_loss: 0.10453450679779053\n",
            "Batch: 6146 Epoch: 0\n",
            "d_loss: 0.16254892870209048\n",
            "g_loss: 0.10823879390954971\n",
            "Batch: 6147 Epoch: 0\n",
            "d_loss: 0.16254934827215095\n",
            "g_loss: 0.10439922660589218\n",
            "Batch: 6148 Epoch: 0\n",
            "d_loss: 0.16254785577998376\n",
            "g_loss: 0.10750384628772736\n",
            "Batch: 6149 Epoch: 0\n",
            "d_loss: 0.1625450046035084\n",
            "g_loss: 0.10561239719390869\n",
            "Batch: 6150 Epoch: 0\n",
            "d_loss: 0.16254267039172277\n",
            "g_loss: 0.10579057037830353\n",
            "Batch: 6151 Epoch: 0\n",
            "d_loss: 0.16254219171465323\n",
            "g_loss: 0.10733256489038467\n",
            "Batch: 6152 Epoch: 0\n",
            "d_loss: 0.16254222497003923\n",
            "g_loss: 0.10780670493841171\n",
            "Batch: 6153 Epoch: 0\n",
            "d_loss: 0.16254320827741964\n",
            "g_loss: 0.10590487718582153\n",
            "Batch: 6154 Epoch: 0\n",
            "d_loss: 0.1625430944786146\n",
            "g_loss: 0.10732372850179672\n",
            "Batch: 6155 Epoch: 0\n",
            "d_loss: 0.16254304332909442\n",
            "g_loss: 0.10565195232629776\n",
            "Batch: 6156 Epoch: 0\n",
            "d_loss: 0.16254388322057878\n",
            "g_loss: 0.10777591168880463\n",
            "Batch: 6157 Epoch: 0\n",
            "d_loss: 0.1625435508293691\n",
            "g_loss: 0.10629775375127792\n",
            "Batch: 6158 Epoch: 0\n",
            "d_loss: 0.16254249422945577\n",
            "g_loss: 0.10678224265575409\n",
            "Batch: 6159 Epoch: 0\n",
            "d_loss: 0.16254165723167802\n",
            "g_loss: 0.10689554363489151\n",
            "Batch: 6160 Epoch: 0\n",
            "d_loss: 0.16254186706881768\n",
            "g_loss: 0.10681585967540741\n",
            "Batch: 6161 Epoch: 0\n",
            "d_loss: 0.162542403006114\n",
            "g_loss: 0.1067647933959961\n",
            "Batch: 6162 Epoch: 0\n",
            "d_loss: 0.16254259552952277\n",
            "g_loss: 0.10683344304561615\n",
            "Batch: 6163 Epoch: 0\n",
            "d_loss: 0.16254244767682735\n",
            "g_loss: 0.10599259287118912\n",
            "Batch: 6164 Epoch: 0\n",
            "d_loss: 0.16254173308955444\n",
            "g_loss: 0.10606682300567627\n",
            "Batch: 6165 Epoch: 0\n",
            "d_loss: 0.1625422389548561\n",
            "g_loss: 0.10657943785190582\n",
            "Batch: 6166 Epoch: 0\n",
            "d_loss: 0.16254240296100164\n",
            "g_loss: 0.10790939629077911\n",
            "Batch: 6167 Epoch: 0\n",
            "d_loss: 0.16254304455430457\n",
            "g_loss: 0.10592144727706909\n",
            "Batch: 6168 Epoch: 0\n",
            "d_loss: 0.16254398239579615\n",
            "g_loss: 0.1075567975640297\n",
            "Batch: 6169 Epoch: 0\n",
            "d_loss: 0.16254291581093128\n",
            "g_loss: 0.1064378023147583\n",
            "Batch: 6170 Epoch: 0\n",
            "d_loss: 0.16254246230371905\n",
            "g_loss: 0.10683713853359222\n",
            "Batch: 6171 Epoch: 0\n",
            "d_loss: 0.16254243888383968\n",
            "g_loss: 0.10673598945140839\n",
            "Batch: 6172 Epoch: 0\n",
            "d_loss: 0.1625416460641631\n",
            "g_loss: 0.10685455799102783\n",
            "Batch: 6173 Epoch: 0\n",
            "d_loss: 0.16254170359491127\n",
            "g_loss: 0.10669904947280884\n",
            "Batch: 6174 Epoch: 0\n",
            "d_loss: 0.16254165215968186\n",
            "g_loss: 0.1067206859588623\n",
            "Batch: 6175 Epoch: 0\n",
            "d_loss: 0.16254160122963413\n",
            "g_loss: 0.10651075839996338\n",
            "Batch: 6176 Epoch: 0\n",
            "d_loss: 0.16254205470188055\n",
            "g_loss: 0.10611357539892197\n",
            "Batch: 6177 Epoch: 0\n",
            "d_loss: 0.16254322341126226\n",
            "g_loss: 0.1076301708817482\n",
            "Batch: 6178 Epoch: 0\n",
            "d_loss: 0.16254401193874557\n",
            "g_loss: 0.10572423040866852\n",
            "Batch: 6179 Epoch: 0\n",
            "d_loss: 0.16254547311145728\n",
            "g_loss: 0.10814285278320312\n",
            "Batch: 6180 Epoch: 0\n",
            "d_loss: 0.1625442204852554\n",
            "g_loss: 0.10607530176639557\n",
            "Batch: 6181 Epoch: 0\n",
            "d_loss: 0.1625426710644433\n",
            "g_loss: 0.1074412614107132\n",
            "Batch: 6182 Epoch: 0\n",
            "d_loss: 0.162542610195203\n",
            "g_loss: 0.10612905025482178\n",
            "Batch: 6183 Epoch: 0\n",
            "d_loss: 0.16254397361991124\n",
            "g_loss: 0.10835476219654083\n",
            "Batch: 6184 Epoch: 0\n",
            "d_loss: 0.1625432119264616\n",
            "g_loss: 0.10665728151798248\n",
            "Batch: 6185 Epoch: 0\n",
            "d_loss: 0.16254284929539153\n",
            "g_loss: 0.10540582984685898\n",
            "Batch: 6186 Epoch: 0\n",
            "d_loss: 0.16254556084885508\n",
            "g_loss: 0.10840976238250732\n",
            "Batch: 6187 Epoch: 0\n",
            "d_loss: 0.16254857407081147\n",
            "g_loss: 0.10540230572223663\n",
            "Batch: 6188 Epoch: 0\n",
            "d_loss: 0.1625462620694762\n",
            "g_loss: 0.10821533203125\n",
            "Batch: 6189 Epoch: 0\n",
            "d_loss: 0.16254435695627478\n",
            "g_loss: 0.10640989243984222\n",
            "Batch: 6190 Epoch: 0\n",
            "d_loss: 0.16254346145576193\n",
            "g_loss: 0.10782460868358612\n",
            "Batch: 6191 Epoch: 0\n",
            "d_loss: 0.16254231818076192\n",
            "g_loss: 0.1068161353468895\n",
            "Batch: 6192 Epoch: 0\n",
            "d_loss: 0.16254258124101284\n",
            "g_loss: 0.10768530517816544\n",
            "Batch: 6193 Epoch: 0\n",
            "d_loss: 0.16254228420866923\n",
            "g_loss: 0.1066969484090805\n",
            "Batch: 6194 Epoch: 0\n",
            "d_loss: 0.1625425208986151\n",
            "g_loss: 0.1068899855017662\n",
            "Batch: 6195 Epoch: 0\n",
            "d_loss: 0.16254198633019\n",
            "g_loss: 0.10769786685705185\n",
            "Batch: 6196 Epoch: 0\n",
            "d_loss: 0.16254237289508566\n",
            "g_loss: 0.10651946067810059\n",
            "Batch: 6197 Epoch: 0\n",
            "d_loss: 0.16254251345633008\n",
            "g_loss: 0.1076238602399826\n",
            "Batch: 6198 Epoch: 0\n",
            "d_loss: 0.16254237248760006\n",
            "g_loss: 0.1068601980805397\n",
            "Batch: 6199 Epoch: 0\n",
            "d_loss: 0.16254183675181366\n",
            "g_loss: 0.10708113759756088\n",
            "Batch: 6200 Epoch: 0\n",
            "d_loss: 0.16254171742055235\n",
            "g_loss: 0.10760662704706192\n",
            "Batch: 6201 Epoch: 0\n",
            "d_loss: 0.16254217664391746\n",
            "g_loss: 0.10666005313396454\n",
            "Batch: 6202 Epoch: 0\n",
            "d_loss: 0.1625416873893144\n",
            "g_loss: 0.10703647136688232\n",
            "Batch: 6203 Epoch: 0\n",
            "d_loss: 0.1625417338353614\n",
            "g_loss: 0.10744686424732208\n",
            "Batch: 6204 Epoch: 0\n",
            "d_loss: 0.16254337006731134\n",
            "g_loss: 0.10566446930170059\n",
            "Batch: 6205 Epoch: 0\n",
            "d_loss: 0.1625461727453157\n",
            "g_loss: 0.10909386724233627\n",
            "Batch: 6206 Epoch: 0\n",
            "d_loss: 0.16254569424975784\n",
            "g_loss: 0.10670176893472672\n",
            "Batch: 6207 Epoch: 0\n",
            "d_loss: 0.1625457384226756\n",
            "g_loss: 0.10934200137853622\n",
            "Batch: 6208 Epoch: 0\n",
            "d_loss: 0.16254645766953502\n",
            "g_loss: 0.10632465034723282\n",
            "Batch: 6209 Epoch: 0\n",
            "d_loss: 0.16254399593590918\n",
            "g_loss: 0.10739339888095856\n",
            "Batch: 6210 Epoch: 0\n",
            "d_loss: 0.16254229761216266\n",
            "g_loss: 0.10718636214733124\n",
            "Batch: 6211 Epoch: 0\n",
            "d_loss: 0.1625419717710983\n",
            "g_loss: 0.10789159685373306\n",
            "Batch: 6212 Epoch: 0\n",
            "d_loss: 0.1625420760049323\n",
            "g_loss: 0.10767918825149536\n",
            "Batch: 6213 Epoch: 0\n",
            "d_loss: 0.16254202889046354\n",
            "g_loss: 0.10702691227197647\n",
            "Batch: 6214 Epoch: 0\n",
            "d_loss: 0.16254179108957345\n",
            "g_loss: 0.10675264894962311\n",
            "Batch: 6215 Epoch: 0\n",
            "d_loss: 0.16254220773111427\n",
            "g_loss: 0.10781566798686981\n",
            "Batch: 6216 Epoch: 0\n",
            "d_loss: 0.1625420136195892\n",
            "g_loss: 0.10727743804454803\n",
            "Batch: 6217 Epoch: 0\n",
            "d_loss: 0.16254165722462943\n",
            "g_loss: 0.107139453291893\n",
            "Batch: 6218 Epoch: 0\n",
            "d_loss: 0.1625417013671253\n",
            "g_loss: 0.10738979279994965\n",
            "Batch: 6219 Epoch: 0\n",
            "d_loss: 0.16254174834642754\n",
            "g_loss: 0.10741661489009857\n",
            "Batch: 6220 Epoch: 0\n",
            "d_loss: 0.1625418051926104\n",
            "g_loss: 0.10728771984577179\n",
            "Batch: 6221 Epoch: 0\n",
            "d_loss: 0.16254168579847672\n",
            "g_loss: 0.10713912546634674\n",
            "Batch: 6222 Epoch: 0\n",
            "d_loss: 0.16254171511412707\n",
            "g_loss: 0.10736532509326935\n",
            "Batch: 6223 Epoch: 0\n",
            "d_loss: 0.16254164913675595\n",
            "g_loss: 0.1077072024345398\n",
            "Batch: 6224 Epoch: 0\n",
            "d_loss: 0.1625417007239207\n",
            "g_loss: 0.10725879669189453\n",
            "Batch: 6225 Epoch: 0\n",
            "d_loss: 0.162541999949827\n",
            "g_loss: 0.10823321342468262\n",
            "Batch: 6226 Epoch: 0\n",
            "d_loss: 0.1625432062527814\n",
            "g_loss: 0.10649432986974716\n",
            "Batch: 6227 Epoch: 0\n",
            "d_loss: 0.1625433849698723\n",
            "g_loss: 0.10809697955846786\n",
            "Batch: 6228 Epoch: 0\n",
            "d_loss: 0.1625432061132912\n",
            "g_loss: 0.1065995842218399\n",
            "Batch: 6229 Epoch: 0\n",
            "d_loss: 0.1625428193397127\n",
            "g_loss: 0.10791939496994019\n",
            "Batch: 6230 Epoch: 0\n",
            "d_loss: 0.162542594875287\n",
            "g_loss: 0.10663364082574844\n",
            "Batch: 6231 Epoch: 0\n",
            "d_loss: 0.16254225322533244\n",
            "g_loss: 0.1074250340461731\n",
            "Batch: 6232 Epoch: 0\n",
            "d_loss: 0.16254225129602062\n",
            "g_loss: 0.10657670348882675\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\n",
            "Number of batches:  6232\n",
            "Batch: 1 Epoch: 1\n",
            "d_loss: 0.16254217893246548\n",
            "g_loss: 0.1076788678765297\n",
            "Batch: 2 Epoch: 1\n",
            "d_loss: 0.16254225183567428\n",
            "g_loss: 0.10664598643779755\n",
            "Batch: 3 Epoch: 1\n",
            "d_loss: 0.1625420586427211\n",
            "g_loss: 0.1074182540178299\n",
            "Batch: 4 Epoch: 1\n",
            "d_loss: 0.16254190827167037\n",
            "g_loss: 0.10730655491352081\n",
            "Batch: 5 Epoch: 1\n",
            "d_loss: 0.1625417797045543\n",
            "g_loss: 0.10653015226125717\n",
            "Batch: 6 Epoch: 1\n",
            "d_loss: 0.16254276009619417\n",
            "g_loss: 0.10826553404331207\n",
            "Batch: 7 Epoch: 1\n",
            "d_loss: 0.16254372934479733\n",
            "g_loss: 0.10592224448919296\n",
            "Batch: 8 Epoch: 1\n",
            "d_loss: 0.16254743798543103\n",
            "g_loss: 0.10999379307031631\n",
            "Batch: 9 Epoch: 1\n",
            "d_loss: 0.16255053653738827\n",
            "g_loss: 0.10574700683355331\n",
            "Batch: 10 Epoch: 1\n",
            "d_loss: 0.16254593257162853\n",
            "g_loss: 0.10842530429363251\n",
            "Batch: 11 Epoch: 1\n",
            "d_loss: 0.16254246782193604\n",
            "g_loss: 0.10742492973804474\n",
            "Batch: 12 Epoch: 1\n",
            "d_loss: 0.1625416108997335\n",
            "g_loss: 0.10743705928325653\n",
            "Batch: 13 Epoch: 1\n",
            "d_loss: 0.16254211648115913\n",
            "g_loss: 0.10872962325811386\n",
            "Batch: 14 Epoch: 1\n",
            "d_loss: 0.16254415952835188\n",
            "g_loss: 0.1064930409193039\n",
            "Batch: 15 Epoch: 1\n",
            "d_loss: 0.16254383216074686\n",
            "g_loss: 0.10823384672403336\n",
            "Batch: 16 Epoch: 1\n",
            "d_loss: 0.16254231273328656\n",
            "g_loss: 0.1074182540178299\n",
            "Batch: 17 Epoch: 1\n",
            "d_loss: 0.162542728238396\n",
            "g_loss: 0.10845965147018433\n",
            "Batch: 18 Epoch: 1\n",
            "d_loss: 0.1625438771771215\n",
            "g_loss: 0.10637650638818741\n",
            "Batch: 19 Epoch: 1\n",
            "d_loss: 0.16254624557452502\n",
            "g_loss: 0.10951045900583267\n",
            "Batch: 20 Epoch: 1\n",
            "d_loss: 0.16254637993857912\n",
            "g_loss: 0.10692410171031952\n",
            "Batch: 21 Epoch: 1\n",
            "d_loss: 0.1625446361737417\n",
            "g_loss: 0.10932473838329315\n",
            "Batch: 22 Epoch: 1\n",
            "d_loss: 0.16254278873406136\n",
            "g_loss: 0.10798931121826172\n",
            "Batch: 23 Epoch: 1\n",
            "d_loss: 0.16254176122084374\n",
            "g_loss: 0.10808686167001724\n",
            "Batch: 24 Epoch: 1\n",
            "d_loss: 0.16254170156992132\n",
            "g_loss: 0.10792805254459381\n",
            "Batch: 25 Epoch: 1\n",
            "d_loss: 0.1625421933947493\n",
            "g_loss: 0.1074051633477211\n",
            "Batch: 26 Epoch: 1\n",
            "d_loss: 0.16254221287334047\n",
            "g_loss: 0.10711987316608429\n",
            "Batch: 27 Epoch: 1\n",
            "d_loss: 0.1625421059146248\n",
            "g_loss: 0.10766305774450302\n",
            "Batch: 28 Epoch: 1\n",
            "d_loss: 0.16254183505638053\n",
            "g_loss: 0.10724897682666779\n",
            "Batch: 29 Epoch: 1\n",
            "d_loss: 0.16254219194794928\n",
            "g_loss: 0.10777503252029419\n",
            "Batch: 30 Epoch: 1\n",
            "d_loss: 0.1625418943336392\n",
            "g_loss: 0.10728158801794052\n",
            "Batch: 31 Epoch: 1\n",
            "d_loss: 0.16254191030770215\n",
            "g_loss: 0.10671963542699814\n",
            "Batch: 32 Epoch: 1\n",
            "d_loss: 0.16254222124749163\n",
            "g_loss: 0.10777363926172256\n",
            "Batch: 33 Epoch: 1\n",
            "d_loss: 0.1625420282437915\n",
            "g_loss: 0.10708000510931015\n",
            "Batch: 34 Epoch: 1\n",
            "d_loss: 0.16254184928705584\n",
            "g_loss: 0.10736298561096191\n",
            "Batch: 35 Epoch: 1\n",
            "d_loss: 0.1625417146838224\n",
            "g_loss: 0.10725130885839462\n",
            "Batch: 36 Epoch: 1\n",
            "d_loss: 0.16254171477151402\n",
            "g_loss: 0.10665272176265717\n",
            "Batch: 37 Epoch: 1\n",
            "d_loss: 0.16254213263280803\n",
            "g_loss: 0.10783586651086807\n",
            "Batch: 38 Epoch: 1\n",
            "d_loss: 0.16254262864656255\n",
            "g_loss: 0.10640601813793182\n",
            "Batch: 39 Epoch: 1\n",
            "d_loss: 0.16254271459461123\n",
            "g_loss: 0.10756412893533707\n",
            "Batch: 40 Epoch: 1\n",
            "d_loss: 0.16254475501692056\n",
            "g_loss: 0.10497371852397919\n",
            "Batch: 41 Epoch: 1\n",
            "d_loss: 0.16254611090530346\n",
            "g_loss: 0.10816045105457306\n",
            "Batch: 42 Epoch: 1\n",
            "d_loss: 0.16254529254810635\n",
            "g_loss: 0.10566376149654388\n",
            "Batch: 43 Epoch: 1\n",
            "d_loss: 0.1625446711365086\n",
            "g_loss: 0.10821574926376343\n",
            "Batch: 44 Epoch: 1\n",
            "d_loss: 0.1625434277240636\n",
            "g_loss: 0.10689592361450195\n",
            "Batch: 45 Epoch: 1\n",
            "d_loss: 0.1625424297648017\n",
            "g_loss: 0.10785655677318573\n",
            "Batch: 46 Epoch: 1\n",
            "d_loss: 0.1625419692585517\n",
            "g_loss: 0.10724840313196182\n",
            "Batch: 47 Epoch: 1\n",
            "d_loss: 0.1625420453478199\n",
            "g_loss: 0.10681259632110596\n",
            "Batch: 48 Epoch: 1\n",
            "d_loss: 0.1625429281036972\n",
            "g_loss: 0.10832209885120392\n",
            "Batch: 49 Epoch: 1\n",
            "d_loss: 0.16254576947472543\n",
            "g_loss: 0.10490284860134125\n",
            "Batch: 50 Epoch: 1\n",
            "d_loss: 0.16254824206718155\n",
            "g_loss: 0.10830084979534149\n",
            "Batch: 51 Epoch: 1\n",
            "d_loss: 0.162550970359284\n",
            "g_loss: 0.10428506135940552\n",
            "Batch: 52 Epoch: 1\n",
            "d_loss: 0.16255329675534114\n",
            "g_loss: 0.10895954072475433\n",
            "Batch: 53 Epoch: 1\n",
            "d_loss: 0.16255666510588895\n",
            "g_loss: 0.1035410612821579\n",
            "Batch: 54 Epoch: 1\n",
            "d_loss: 0.16256840472022915\n",
            "g_loss: 0.10944297164678574\n",
            "Batch: 55 Epoch: 1\n",
            "d_loss: 0.1625714905651492\n",
            "g_loss: 0.10288695245981216\n",
            "Batch: 56 Epoch: 1\n",
            "d_loss: 0.16256158118652309\n",
            "g_loss: 0.10804399102926254\n",
            "Batch: 57 Epoch: 1\n",
            "d_loss: 0.1625439971096867\n",
            "g_loss: 0.10866846889257431\n",
            "Batch: 58 Epoch: 1\n",
            "d_loss: 0.16254493610699683\n",
            "g_loss: 0.10622851550579071\n",
            "Batch: 59 Epoch: 1\n",
            "d_loss: 0.16256678456043971\n",
            "g_loss: 0.10248167812824249\n",
            "Batch: 60 Epoch: 1\n",
            "d_loss: 0.16256844905787915\n",
            "g_loss: 0.10896693170070648\n",
            "Batch: 61 Epoch: 1\n",
            "d_loss: 0.16257247610028003\n",
            "g_loss: 0.10272109508514404\n",
            "Batch: 62 Epoch: 1\n",
            "d_loss: 0.16256597855556265\n",
            "g_loss: 0.10881538689136505\n",
            "Batch: 63 Epoch: 1\n",
            "d_loss: 0.16255173270680956\n",
            "g_loss: 0.10568414628505707\n",
            "Batch: 64 Epoch: 1\n",
            "d_loss: 0.16254335889389893\n",
            "g_loss: 0.1069725900888443\n",
            "Batch: 65 Epoch: 1\n",
            "d_loss: 0.1625432867748131\n",
            "g_loss: 0.10689661651849747\n",
            "Batch: 66 Epoch: 1\n",
            "d_loss: 0.16254215169311692\n",
            "g_loss: 0.10775323212146759\n",
            "Batch: 67 Epoch: 1\n",
            "d_loss: 0.16254250978637685\n",
            "g_loss: 0.10670801252126694\n",
            "Batch: 68 Epoch: 1\n",
            "d_loss: 0.16254213706731946\n",
            "g_loss: 0.10645447671413422\n",
            "Batch: 69 Epoch: 1\n",
            "d_loss: 0.1625416905418433\n",
            "g_loss: 0.10652939230203629\n",
            "Batch: 70 Epoch: 1\n",
            "d_loss: 0.16254237923342174\n",
            "g_loss: 0.10700966417789459\n",
            "Batch: 71 Epoch: 1\n",
            "d_loss: 0.16254261172728235\n",
            "g_loss: 0.1080087199807167\n",
            "Batch: 72 Epoch: 1\n",
            "d_loss: 0.16254577357370437\n",
            "g_loss: 0.10522626340389252\n",
            "Batch: 73 Epoch: 1\n",
            "d_loss: 0.1625454774010393\n",
            "g_loss: 0.10799826681613922\n",
            "Batch: 74 Epoch: 1\n",
            "d_loss: 0.1625421679875032\n",
            "g_loss: 0.10810325294733047\n",
            "Batch: 75 Epoch: 1\n",
            "d_loss: 0.16254292586582153\n",
            "g_loss: 0.1070689782500267\n",
            "Batch: 76 Epoch: 1\n",
            "d_loss: 0.162542313993832\n",
            "g_loss: 0.1075306311249733\n",
            "Batch: 77 Epoch: 1\n",
            "d_loss: 0.1625418967355472\n",
            "g_loss: 0.10840612649917603\n",
            "Batch: 78 Epoch: 1\n",
            "d_loss: 0.16254820079542043\n",
            "g_loss: 0.10426304489374161\n",
            "Batch: 79 Epoch: 1\n",
            "d_loss: 0.16255435467604684\n",
            "g_loss: 0.10910239070653915\n",
            "Batch: 80 Epoch: 1\n",
            "d_loss: 0.16254905303694756\n",
            "g_loss: 0.10655045509338379\n",
            "Batch: 81 Epoch: 1\n",
            "d_loss: 0.16254353680433553\n",
            "g_loss: 0.10798950493335724\n",
            "Batch: 82 Epoch: 1\n",
            "d_loss: 0.16254302990306968\n",
            "g_loss: 0.10644890367984772\n",
            "Batch: 83 Epoch: 1\n",
            "d_loss: 0.16254301889748746\n",
            "g_loss: 0.10639431327581406\n",
            "Batch: 84 Epoch: 1\n",
            "d_loss: 0.1625421235701765\n",
            "g_loss: 0.10666505247354507\n",
            "Batch: 85 Epoch: 1\n",
            "d_loss: 0.16254174884237926\n",
            "g_loss: 0.10633448511362076\n",
            "Batch: 86 Epoch: 1\n",
            "d_loss: 0.1625427975537974\n",
            "g_loss: 0.10745441913604736\n",
            "Batch: 87 Epoch: 1\n",
            "d_loss: 0.1625422109899759\n",
            "g_loss: 0.10660608857870102\n",
            "Batch: 88 Epoch: 1\n",
            "d_loss: 0.16254224243198223\n",
            "g_loss: 0.10724948346614838\n",
            "Batch: 89 Epoch: 1\n",
            "d_loss: 0.1625418832070551\n",
            "g_loss: 0.10679197311401367\n",
            "Batch: 90 Epoch: 1\n",
            "d_loss: 0.16254208289946348\n",
            "g_loss: 0.10740846395492554\n",
            "Batch: 91 Epoch: 1\n",
            "d_loss: 0.1625427909531254\n",
            "g_loss: 0.10666175186634064\n",
            "Batch: 92 Epoch: 1\n",
            "d_loss: 0.16254177881445742\n",
            "g_loss: 0.10704632103443146\n",
            "Batch: 93 Epoch: 1\n",
            "d_loss: 0.16254191214358116\n",
            "g_loss: 0.10608943551778793\n",
            "Batch: 94 Epoch: 1\n",
            "d_loss: 0.16254219574818762\n",
            "g_loss: 0.10720787942409515\n",
            "Batch: 95 Epoch: 1\n",
            "d_loss: 0.16254173917423742\n",
            "g_loss: 0.10717540979385376\n",
            "Batch: 96 Epoch: 1\n",
            "d_loss: 0.16254185299787594\n",
            "g_loss: 0.10631374269723892\n",
            "Batch: 97 Epoch: 1\n",
            "d_loss: 0.16254292503126067\n",
            "g_loss: 0.10781098902225494\n",
            "Batch: 98 Epoch: 1\n",
            "d_loss: 0.16254419250730479\n",
            "g_loss: 0.10564997047185898\n",
            "Batch: 99 Epoch: 1\n",
            "d_loss: 0.16254338985481098\n",
            "g_loss: 0.10726618766784668\n",
            "Batch: 100 Epoch: 1\n",
            "d_loss: 0.1625419736294944\n",
            "g_loss: 0.10712900012731552\n",
            "Batch: 101 Epoch: 1\n",
            "d_loss: 0.16254245262938127\n",
            "g_loss: 0.10615319013595581\n",
            "Batch: 102 Epoch: 1\n",
            "d_loss: 0.16254201852524375\n",
            "g_loss: 0.10682952404022217\n",
            "Batch: 103 Epoch: 1\n",
            "d_loss: 0.1625423755270745\n",
            "g_loss: 0.10760743916034698\n",
            "Batch: 104 Epoch: 1\n",
            "d_loss: 0.1625419577219276\n",
            "g_loss: 0.10687024891376495\n",
            "Batch: 105 Epoch: 1\n",
            "d_loss: 0.16254184273414296\n",
            "g_loss: 0.1065022200345993\n",
            "Batch: 106 Epoch: 1\n",
            "d_loss: 0.16254233232047\n",
            "g_loss: 0.10730224847793579\n",
            "Batch: 107 Epoch: 1\n",
            "d_loss: 0.16254201581183736\n",
            "g_loss: 0.1067349910736084\n",
            "Batch: 108 Epoch: 1\n",
            "d_loss: 0.16254176729925263\n",
            "g_loss: 0.10676391422748566\n",
            "Batch: 109 Epoch: 1\n",
            "d_loss: 0.16254175346762167\n",
            "g_loss: 0.10740374028682709\n",
            "Batch: 110 Epoch: 1\n",
            "d_loss: 0.162541868940977\n",
            "g_loss: 0.10674731433391571\n",
            "Batch: 111 Epoch: 1\n",
            "d_loss: 0.1625416014580594\n",
            "g_loss: 0.10651131719350815\n",
            "Batch: 112 Epoch: 1\n",
            "d_loss: 0.16254276699960002\n",
            "g_loss: 0.10816729068756104\n",
            "Batch: 113 Epoch: 1\n",
            "d_loss: 0.16254470096994567\n",
            "g_loss: 0.1052565947175026\n",
            "Batch: 114 Epoch: 1\n",
            "d_loss: 0.16254595092263457\n",
            "g_loss: 0.10828495025634766\n",
            "Batch: 115 Epoch: 1\n",
            "d_loss: 0.16254535520191382\n",
            "g_loss: 0.10548566281795502\n",
            "Batch: 116 Epoch: 1\n",
            "d_loss: 0.16254401367415028\n",
            "g_loss: 0.10764910280704498\n",
            "Batch: 117 Epoch: 1\n",
            "d_loss: 0.16254264278633457\n",
            "g_loss: 0.10669083893299103\n",
            "Batch: 118 Epoch: 1\n",
            "d_loss: 0.1625416889421487\n",
            "g_loss: 0.10668802261352539\n",
            "Batch: 119 Epoch: 1\n",
            "d_loss: 0.16254169902686044\n",
            "g_loss: 0.1070195883512497\n",
            "Batch: 120 Epoch: 1\n",
            "d_loss: 0.16254171919275961\n",
            "g_loss: 0.10708387196063995\n",
            "Batch: 121 Epoch: 1\n",
            "d_loss: 0.162542194961091\n",
            "g_loss: 0.10620337724685669\n",
            "Batch: 122 Epoch: 1\n",
            "d_loss: 0.16254255398213502\n",
            "g_loss: 0.10701023042201996\n",
            "Batch: 123 Epoch: 1\n",
            "d_loss: 0.16254189754670278\n",
            "g_loss: 0.10675277560949326\n",
            "Batch: 124 Epoch: 1\n",
            "d_loss: 0.1625417349354379\n",
            "g_loss: 0.10701906681060791\n",
            "Batch: 125 Epoch: 1\n",
            "d_loss: 0.16254171915237237\n",
            "g_loss: 0.10683872550725937\n",
            "Batch: 126 Epoch: 1\n",
            "d_loss: 0.16254207614744587\n",
            "g_loss: 0.10675337165594101\n",
            "Batch: 127 Epoch: 1\n",
            "d_loss: 0.16254164372837465\n",
            "g_loss: 0.10701010376214981\n",
            "Batch: 128 Epoch: 1\n",
            "d_loss: 0.16254185461326642\n",
            "g_loss: 0.10665164142847061\n",
            "Batch: 129 Epoch: 1\n",
            "d_loss: 0.16254188500791855\n",
            "g_loss: 0.10664279758930206\n",
            "Batch: 130 Epoch: 1\n",
            "d_loss: 0.1625425529579232\n",
            "g_loss: 0.10819146782159805\n",
            "Batch: 131 Epoch: 1\n",
            "d_loss: 0.16254455447595006\n",
            "g_loss: 0.10595649480819702\n",
            "Batch: 132 Epoch: 1\n",
            "d_loss: 0.16254773734454986\n",
            "g_loss: 0.1095389872789383\n",
            "Batch: 133 Epoch: 1\n",
            "d_loss: 0.16255018152726564\n",
            "g_loss: 0.10574208199977875\n",
            "Batch: 134 Epoch: 1\n",
            "d_loss: 0.16254985542330758\n",
            "g_loss: 0.10733214765787125\n",
            "Batch: 135 Epoch: 1\n",
            "d_loss: 0.1625425517498016\n",
            "g_loss: 0.10607653856277466\n",
            "Batch: 136 Epoch: 1\n",
            "d_loss: 0.16254466996021932\n",
            "g_loss: 0.10757102817296982\n",
            "Batch: 137 Epoch: 1\n",
            "d_loss: 0.16254242180479395\n",
            "g_loss: 0.10658719390630722\n",
            "Batch: 138 Epoch: 1\n",
            "d_loss: 0.16254226011398742\n",
            "g_loss: 0.10632266849279404\n",
            "Batch: 139 Epoch: 1\n",
            "d_loss: 0.16254232366362942\n",
            "g_loss: 0.10693075507879257\n",
            "Batch: 140 Epoch: 1\n",
            "d_loss: 0.16254213751376767\n",
            "g_loss: 0.10562515258789062\n",
            "Batch: 141 Epoch: 1\n",
            "d_loss: 0.16254461604298598\n",
            "g_loss: 0.10817545652389526\n",
            "Batch: 142 Epoch: 1\n",
            "d_loss: 0.16254286452896238\n",
            "g_loss: 0.10675548017024994\n",
            "Batch: 143 Epoch: 1\n",
            "d_loss: 0.162542015668663\n",
            "g_loss: 0.10735608637332916\n",
            "Batch: 144 Epoch: 1\n",
            "d_loss: 0.1625416874588339\n",
            "g_loss: 0.10740838944911957\n",
            "Batch: 145 Epoch: 1\n",
            "d_loss: 0.1625418429168377\n",
            "g_loss: 0.10685700178146362\n",
            "Batch: 146 Epoch: 1\n",
            "d_loss: 0.16254219502250322\n",
            "g_loss: 0.10816721618175507\n",
            "Batch: 147 Epoch: 1\n",
            "d_loss: 0.16254291277891753\n",
            "g_loss: 0.10689165443181992\n",
            "Batch: 148 Epoch: 1\n",
            "d_loss: 0.16254229989942814\n",
            "g_loss: 0.10787491500377655\n",
            "Batch: 149 Epoch: 1\n",
            "d_loss: 0.1625420610182715\n",
            "g_loss: 0.10720092058181763\n",
            "Batch: 150 Epoch: 1\n",
            "d_loss: 0.16254204579075804\n",
            "g_loss: 0.10787487030029297\n",
            "Batch: 151 Epoch: 1\n",
            "d_loss: 0.16254259657006997\n",
            "g_loss: 0.10671348869800568\n",
            "Batch: 152 Epoch: 1\n",
            "d_loss: 0.1625416889942315\n",
            "g_loss: 0.10662515461444855\n",
            "Batch: 153 Epoch: 1\n",
            "d_loss: 0.1625421786562029\n",
            "g_loss: 0.10778911411762238\n",
            "Batch: 154 Epoch: 1\n",
            "d_loss: 0.16254304412053244\n",
            "g_loss: 0.10633198171854019\n",
            "Batch: 155 Epoch: 1\n",
            "d_loss: 0.16254314738681686\n",
            "g_loss: 0.10776512324810028\n",
            "Batch: 156 Epoch: 1\n",
            "d_loss: 0.16254390901599436\n",
            "g_loss: 0.10577630996704102\n",
            "Batch: 157 Epoch: 1\n",
            "d_loss: 0.1625435209145678\n",
            "g_loss: 0.10747120529413223\n",
            "Batch: 158 Epoch: 1\n",
            "d_loss: 0.1625426709448341\n",
            "g_loss: 0.10637559741735458\n",
            "Batch: 159 Epoch: 1\n",
            "d_loss: 0.16254200193729673\n",
            "g_loss: 0.10679519176483154\n",
            "Batch: 160 Epoch: 1\n",
            "d_loss: 0.16254171733321243\n",
            "g_loss: 0.106745645403862\n",
            "Batch: 161 Epoch: 1\n",
            "d_loss: 0.16254183621064655\n",
            "g_loss: 0.10727226734161377\n",
            "Batch: 162 Epoch: 1\n",
            "d_loss: 0.16254176433265854\n",
            "g_loss: 0.10670192539691925\n",
            "Batch: 163 Epoch: 1\n",
            "d_loss: 0.16254174718797287\n",
            "g_loss: 0.10663886368274689\n",
            "Batch: 164 Epoch: 1\n",
            "d_loss: 0.16254180948654096\n",
            "g_loss: 0.10718510299921036\n",
            "Batch: 165 Epoch: 1\n",
            "d_loss: 0.16254204508418724\n",
            "g_loss: 0.10622292757034302\n",
            "Batch: 166 Epoch: 1\n",
            "d_loss: 0.16254232816010727\n",
            "g_loss: 0.1074458509683609\n",
            "Batch: 167 Epoch: 1\n",
            "d_loss: 0.16254225515770315\n",
            "g_loss: 0.10621678829193115\n",
            "Batch: 168 Epoch: 1\n",
            "d_loss: 0.16254169135290653\n",
            "g_loss: 0.10620014369487762\n",
            "Batch: 169 Epoch: 1\n",
            "d_loss: 0.16254231477287817\n",
            "g_loss: 0.10771223157644272\n",
            "Batch: 170 Epoch: 1\n",
            "d_loss: 0.1625424333404908\n",
            "g_loss: 0.10654990375041962\n",
            "Batch: 171 Epoch: 1\n",
            "d_loss: 0.1625421942762415\n",
            "g_loss: 0.10765974223613739\n",
            "Batch: 172 Epoch: 1\n",
            "d_loss: 0.16254201523813094\n",
            "g_loss: 0.10714404284954071\n",
            "Batch: 173 Epoch: 1\n",
            "d_loss: 0.162541926699717\n",
            "g_loss: 0.1069839745759964\n",
            "Batch: 174 Epoch: 1\n",
            "d_loss: 0.16254171010740492\n",
            "g_loss: 0.1071457639336586\n",
            "Batch: 175 Epoch: 1\n",
            "d_loss: 0.162541703669298\n",
            "g_loss: 0.10698187351226807\n",
            "Batch: 176 Epoch: 1\n",
            "d_loss: 0.1625420011347245\n",
            "g_loss: 0.1064252033829689\n",
            "Batch: 177 Epoch: 1\n",
            "d_loss: 0.16254232902705468\n",
            "g_loss: 0.10766969621181488\n",
            "Batch: 178 Epoch: 1\n",
            "d_loss: 0.16254339372879656\n",
            "g_loss: 0.10538303852081299\n",
            "Batch: 179 Epoch: 1\n",
            "d_loss: 0.16254353512035635\n",
            "g_loss: 0.10752610862255096\n",
            "Batch: 180 Epoch: 1\n",
            "d_loss: 0.16254268595837118\n",
            "g_loss: 0.10609853267669678\n",
            "Batch: 181 Epoch: 1\n",
            "d_loss: 0.16254173448206188\n",
            "g_loss: 0.10641585290431976\n",
            "Batch: 182 Epoch: 1\n",
            "d_loss: 0.16254195760406276\n",
            "g_loss: 0.10712965577840805\n",
            "Batch: 183 Epoch: 1\n",
            "d_loss: 0.16254261171179962\n",
            "g_loss: 0.10618045181035995\n",
            "Batch: 184 Epoch: 1\n",
            "d_loss: 0.16254204837586883\n",
            "g_loss: 0.10735847800970078\n",
            "Batch: 185 Epoch: 1\n",
            "d_loss: 0.162542612964657\n",
            "g_loss: 0.10577838122844696\n",
            "Batch: 186 Epoch: 1\n",
            "d_loss: 0.16254331211116835\n",
            "g_loss: 0.10754326730966568\n",
            "Batch: 187 Epoch: 1\n",
            "d_loss: 0.1625436436771608\n",
            "g_loss: 0.10555656999349594\n",
            "Batch: 188 Epoch: 1\n",
            "d_loss: 0.16254386203333837\n",
            "g_loss: 0.10749413818120956\n",
            "Batch: 189 Epoch: 1\n",
            "d_loss: 0.1625437149471196\n",
            "g_loss: 0.10545845329761505\n",
            "Batch: 190 Epoch: 1\n",
            "d_loss: 0.16254290992900167\n",
            "g_loss: 0.10662653297185898\n",
            "Batch: 191 Epoch: 1\n",
            "d_loss: 0.16254212248703936\n",
            "g_loss: 0.10586359351873398\n",
            "Batch: 192 Epoch: 1\n",
            "d_loss: 0.1625419854434611\n",
            "g_loss: 0.10682038962841034\n",
            "Batch: 193 Epoch: 1\n",
            "d_loss: 0.16254220950149545\n",
            "g_loss: 0.10575830936431885\n",
            "Batch: 194 Epoch: 1\n",
            "d_loss: 0.16254220084878312\n",
            "g_loss: 0.10693633556365967\n",
            "Batch: 195 Epoch: 1\n",
            "d_loss: 0.16254189616210368\n",
            "g_loss: 0.10651533305644989\n",
            "Batch: 196 Epoch: 1\n",
            "d_loss: 0.16254172324051552\n",
            "g_loss: 0.10628523677587509\n",
            "Batch: 197 Epoch: 1\n",
            "d_loss: 0.16254167610539838\n",
            "g_loss: 0.10629024356603622\n",
            "Batch: 198 Epoch: 1\n",
            "d_loss: 0.16254189794743468\n",
            "g_loss: 0.10722143948078156\n",
            "Batch: 199 Epoch: 1\n",
            "d_loss: 0.162543088859735\n",
            "g_loss: 0.10556721687316895\n",
            "Batch: 200 Epoch: 1\n",
            "d_loss: 0.1625440994087164\n",
            "g_loss: 0.10782984644174576\n",
            "Batch: 201 Epoch: 1\n",
            "d_loss: 0.1625437572346975\n",
            "g_loss: 0.10616336017847061\n",
            "Batch: 202 Epoch: 1\n",
            "d_loss: 0.16254256769813225\n",
            "g_loss: 0.10731005668640137\n",
            "Batch: 203 Epoch: 1\n",
            "d_loss: 0.16254308844280985\n",
            "g_loss: 0.10554828494787216\n",
            "Batch: 204 Epoch: 1\n",
            "d_loss: 0.16254302859867664\n",
            "g_loss: 0.10709121078252792\n",
            "Batch: 205 Epoch: 1\n",
            "d_loss: 0.1625424016545658\n",
            "g_loss: 0.10625819861888885\n",
            "Batch: 206 Epoch: 1\n",
            "d_loss: 0.16254213418518404\n",
            "g_loss: 0.10674428939819336\n",
            "Batch: 207 Epoch: 1\n",
            "d_loss: 0.1625423124265808\n",
            "g_loss: 0.10583053529262543\n",
            "Batch: 208 Epoch: 1\n",
            "d_loss: 0.16254266984785204\n",
            "g_loss: 0.10745938867330551\n",
            "Batch: 209 Epoch: 1\n",
            "d_loss: 0.16254259468940901\n",
            "g_loss: 0.10624979436397552\n",
            "Batch: 210 Epoch: 1\n",
            "d_loss: 0.16254189498095073\n",
            "g_loss: 0.10671980679035187\n",
            "Batch: 211 Epoch: 1\n",
            "d_loss: 0.1625417478572473\n",
            "g_loss: 0.10714229196310043\n",
            "Batch: 212 Epoch: 1\n",
            "d_loss: 0.16254223669020007\n",
            "g_loss: 0.1065109595656395\n",
            "Batch: 213 Epoch: 1\n",
            "d_loss: 0.1625420288431556\n",
            "g_loss: 0.10732249915599823\n",
            "Batch: 214 Epoch: 1\n",
            "d_loss: 0.1625422558702354\n",
            "g_loss: 0.10665810108184814\n",
            "Batch: 215 Epoch: 1\n",
            "d_loss: 0.1625416558488446\n",
            "g_loss: 0.10675223916769028\n",
            "Batch: 216 Epoch: 1\n",
            "d_loss: 0.16254174660343068\n",
            "g_loss: 0.106706902384758\n",
            "Batch: 217 Epoch: 1\n",
            "d_loss: 0.16254159685964353\n",
            "g_loss: 0.10680965334177017\n",
            "Batch: 218 Epoch: 1\n",
            "d_loss: 0.1625417166745713\n",
            "g_loss: 0.10683096945285797\n",
            "Batch: 219 Epoch: 1\n",
            "d_loss: 0.1625416263984114\n",
            "g_loss: 0.10665043443441391\n",
            "Batch: 220 Epoch: 1\n",
            "d_loss: 0.1625415992770769\n",
            "g_loss: 0.10669825971126556\n",
            "Batch: 221 Epoch: 1\n",
            "d_loss: 0.16254171467660328\n",
            "g_loss: 0.10636643320322037\n",
            "Batch: 222 Epoch: 1\n",
            "d_loss: 0.16254180654153316\n",
            "g_loss: 0.10664727538824081\n",
            "Batch: 223 Epoch: 1\n",
            "d_loss: 0.16254164124745074\n",
            "g_loss: 0.10704662650823593\n",
            "Batch: 224 Epoch: 1\n",
            "d_loss: 0.16254184952564898\n",
            "g_loss: 0.10620448738336563\n",
            "Batch: 225 Epoch: 1\n",
            "d_loss: 0.16254219174718898\n",
            "g_loss: 0.1070673018693924\n",
            "Batch: 226 Epoch: 1\n",
            "d_loss: 0.16254219245467283\n",
            "g_loss: 0.10613924264907837\n",
            "Batch: 227 Epoch: 1\n",
            "d_loss: 0.1625417750405731\n",
            "g_loss: 0.10650615394115448\n",
            "Batch: 228 Epoch: 1\n",
            "d_loss: 0.16254168611728304\n",
            "g_loss: 0.10666320472955704\n",
            "Batch: 229 Epoch: 1\n",
            "d_loss: 0.1625416468365657\n",
            "g_loss: 0.10649168491363525\n",
            "Batch: 230 Epoch: 1\n",
            "d_loss: 0.162541879786108\n",
            "g_loss: 0.10555100440979004\n",
            "Batch: 231 Epoch: 1\n",
            "d_loss: 0.16254358442927241\n",
            "g_loss: 0.10805493593215942\n",
            "Batch: 232 Epoch: 1\n",
            "d_loss: 0.1625469021624042\n",
            "g_loss: 0.10398131608963013\n",
            "Batch: 233 Epoch: 1\n",
            "d_loss: 0.16254674326277296\n",
            "g_loss: 0.10658802092075348\n",
            "Batch: 234 Epoch: 1\n",
            "d_loss: 0.16254432558282872\n",
            "g_loss: 0.10463780164718628\n",
            "Batch: 235 Epoch: 1\n",
            "d_loss: 0.16254311636091145\n",
            "g_loss: 0.10572006553411484\n",
            "Batch: 236 Epoch: 1\n",
            "d_loss: 0.1625437723578429\n",
            "g_loss: 0.10489282757043839\n",
            "Batch: 237 Epoch: 1\n",
            "d_loss: 0.16254210345783093\n",
            "g_loss: 0.10570807754993439\n",
            "Batch: 238 Epoch: 1\n",
            "d_loss: 0.16254251985821\n",
            "g_loss: 0.1068907231092453\n",
            "Batch: 239 Epoch: 1\n",
            "d_loss: 0.1625454265008166\n",
            "g_loss: 0.10379044711589813\n",
            "Batch: 240 Epoch: 1\n",
            "d_loss: 0.16255532103966175\n",
            "g_loss: 0.10885985940694809\n",
            "Batch: 241 Epoch: 1\n",
            "d_loss: 0.162565142536657\n",
            "g_loss: 0.10195449739694595\n",
            "Batch: 242 Epoch: 1\n",
            "d_loss: 0.16257589732757793\n",
            "g_loss: 0.11082013696432114\n",
            "Batch: 243 Epoch: 1\n",
            "d_loss: 0.1625748745646689\n",
            "g_loss: 0.10243856906890869\n",
            "Batch: 244 Epoch: 1\n",
            "d_loss: 0.16256128039230333\n",
            "g_loss: 0.10811655223369598\n",
            "Batch: 245 Epoch: 1\n",
            "d_loss: 0.1625499395248653\n",
            "g_loss: 0.10806670039892197\n",
            "Batch: 246 Epoch: 1\n",
            "d_loss: 0.16254544069617083\n",
            "g_loss: 0.10911271721124649\n",
            "Batch: 247 Epoch: 1\n",
            "d_loss: 0.16254841157056177\n",
            "g_loss: 0.10595681518316269\n",
            "Batch: 248 Epoch: 1\n",
            "d_loss: 0.16255182403417479\n",
            "g_loss: 0.1072993129491806\n",
            "Batch: 249 Epoch: 1\n",
            "d_loss: 0.1625431485889095\n",
            "g_loss: 0.10634376108646393\n",
            "Batch: 250 Epoch: 1\n",
            "d_loss: 0.16254271865008718\n",
            "g_loss: 0.10676072537899017\n",
            "Batch: 251 Epoch: 1\n",
            "d_loss: 0.1625432702339893\n",
            "g_loss: 0.10486584901809692\n",
            "Batch: 252 Epoch: 1\n",
            "d_loss: 0.16254368966742305\n",
            "g_loss: 0.10706998407840729\n",
            "Batch: 253 Epoch: 1\n",
            "d_loss: 0.16254239184087282\n",
            "g_loss: 0.10641475021839142\n",
            "Batch: 254 Epoch: 1\n",
            "d_loss: 0.16254193152625618\n",
            "g_loss: 0.10545335710048676\n",
            "Batch: 255 Epoch: 1\n",
            "d_loss: 0.16254230255515978\n",
            "g_loss: 0.10672652721405029\n",
            "Batch: 256 Epoch: 1\n",
            "d_loss: 0.1625421719065656\n",
            "g_loss: 0.10622018575668335\n",
            "Batch: 257 Epoch: 1\n",
            "d_loss: 0.1625418400503591\n",
            "g_loss: 0.10646631568670273\n",
            "Batch: 258 Epoch: 1\n",
            "d_loss: 0.16254265929257627\n",
            "g_loss: 0.10557373613119125\n",
            "Batch: 259 Epoch: 1\n",
            "d_loss: 0.16254288723941102\n",
            "g_loss: 0.10707078129053116\n",
            "Batch: 260 Epoch: 1\n",
            "d_loss: 0.1625430921116191\n",
            "g_loss: 0.10545779764652252\n",
            "Batch: 261 Epoch: 1\n",
            "d_loss: 0.16254224984596988\n",
            "g_loss: 0.10639393329620361\n",
            "Batch: 262 Epoch: 1\n",
            "d_loss: 0.16254199102304767\n",
            "g_loss: 0.10623781383037567\n",
            "Batch: 263 Epoch: 1\n",
            "d_loss: 0.16254276789266697\n",
            "g_loss: 0.10512858629226685\n",
            "Batch: 264 Epoch: 1\n",
            "d_loss: 0.1625422759138928\n",
            "g_loss: 0.10582314431667328\n",
            "Batch: 265 Epoch: 1\n",
            "d_loss: 0.162542321019842\n",
            "g_loss: 0.10559985786676407\n",
            "Batch: 266 Epoch: 1\n",
            "d_loss: 0.1625420823631174\n",
            "g_loss: 0.10587401688098907\n",
            "Batch: 267 Epoch: 1\n",
            "d_loss: 0.16254174062235904\n",
            "g_loss: 0.10550010204315186\n",
            "Batch: 268 Epoch: 1\n",
            "d_loss: 0.16254253263520013\n",
            "g_loss: 0.10681577026844025\n",
            "Batch: 269 Epoch: 1\n",
            "d_loss: 0.16254279634129887\n",
            "g_loss: 0.10581372678279877\n",
            "Batch: 270 Epoch: 1\n",
            "d_loss: 0.16254263060932317\n",
            "g_loss: 0.10670220851898193\n",
            "Batch: 271 Epoch: 1\n",
            "d_loss: 0.16254222692909082\n",
            "g_loss: 0.10628024488687515\n",
            "Batch: 272 Epoch: 1\n",
            "d_loss: 0.16254184111019043\n",
            "g_loss: 0.10561180114746094\n",
            "Batch: 273 Epoch: 1\n",
            "d_loss: 0.16254301667748905\n",
            "g_loss: 0.10728976875543594\n",
            "Batch: 274 Epoch: 1\n",
            "d_loss: 0.16254333163918488\n",
            "g_loss: 0.10548295825719833\n",
            "Batch: 275 Epoch: 1\n",
            "d_loss: 0.16254304735530667\n",
            "g_loss: 0.10740506649017334\n",
            "Batch: 276 Epoch: 1\n",
            "d_loss: 0.16254212100092502\n",
            "g_loss: 0.10681287944316864\n",
            "Batch: 277 Epoch: 1\n",
            "d_loss: 0.16254246981922194\n",
            "g_loss: 0.10601606220006943\n",
            "Batch: 278 Epoch: 1\n",
            "d_loss: 0.16254327249684053\n",
            "g_loss: 0.10725326836109161\n",
            "Batch: 279 Epoch: 1\n",
            "d_loss: 0.16254264528975426\n",
            "g_loss: 0.10603518784046173\n",
            "Batch: 280 Epoch: 1\n",
            "d_loss: 0.1625431938701709\n",
            "g_loss: 0.10776548087596893\n",
            "Batch: 281 Epoch: 1\n",
            "d_loss: 0.1625433285700666\n",
            "g_loss: 0.10644892603158951\n",
            "Batch: 282 Epoch: 1\n",
            "d_loss: 0.1625431955385821\n",
            "g_loss: 0.10767598450183868\n",
            "Batch: 283 Epoch: 1\n",
            "d_loss: 0.16254343613947242\n",
            "g_loss: 0.10609441995620728\n",
            "Batch: 284 Epoch: 1\n",
            "d_loss: 0.16254327362027254\n",
            "g_loss: 0.10771771520376205\n",
            "Batch: 285 Epoch: 1\n",
            "d_loss: 0.16254279133195837\n",
            "g_loss: 0.10641715675592422\n",
            "Batch: 286 Epoch: 1\n",
            "d_loss: 0.16254246524764682\n",
            "g_loss: 0.10766869783401489\n",
            "Batch: 287 Epoch: 1\n",
            "d_loss: 0.1625428512020548\n",
            "g_loss: 0.1069251149892807\n",
            "Batch: 288 Epoch: 1\n",
            "d_loss: 0.16254219762261357\n",
            "g_loss: 0.10781607776880264\n",
            "Batch: 289 Epoch: 1\n",
            "d_loss: 0.16254197272074578\n",
            "g_loss: 0.10687942802906036\n",
            "Batch: 290 Epoch: 1\n",
            "d_loss: 0.1625416915040674\n",
            "g_loss: 0.10674867779016495\n",
            "Batch: 291 Epoch: 1\n",
            "d_loss: 0.1625423117677549\n",
            "g_loss: 0.10803256183862686\n",
            "Batch: 292 Epoch: 1\n",
            "d_loss: 0.16254243358458353\n",
            "g_loss: 0.10673294216394424\n",
            "Batch: 293 Epoch: 1\n",
            "d_loss: 0.1625416142518219\n",
            "g_loss: 0.10635878890752792\n",
            "Batch: 294 Epoch: 1\n",
            "d_loss: 0.16254229842821744\n",
            "g_loss: 0.10743442922830582\n",
            "Batch: 295 Epoch: 1\n",
            "d_loss: 0.16254268613872824\n",
            "g_loss: 0.10608456283807755\n",
            "Batch: 296 Epoch: 1\n",
            "d_loss: 0.16254271646884888\n",
            "g_loss: 0.10730905830860138\n",
            "Batch: 297 Epoch: 1\n",
            "d_loss: 0.16254290981826358\n",
            "g_loss: 0.10590499639511108\n",
            "Batch: 298 Epoch: 1\n",
            "d_loss: 0.16254299860360177\n",
            "g_loss: 0.10736529529094696\n",
            "Batch: 299 Epoch: 1\n",
            "d_loss: 0.16254292455150932\n",
            "g_loss: 0.10588297992944717\n",
            "Batch: 300 Epoch: 1\n",
            "d_loss: 0.162542968493387\n",
            "g_loss: 0.10734977573156357\n",
            "Batch: 301 Epoch: 1\n",
            "d_loss: 0.16254284949950915\n",
            "g_loss: 0.10594308376312256\n",
            "Batch: 302 Epoch: 1\n",
            "d_loss: 0.16254259634841972\n",
            "g_loss: 0.10735024511814117\n",
            "Batch: 303 Epoch: 1\n",
            "d_loss: 0.1625424042490451\n",
            "g_loss: 0.10605661571025848\n",
            "Batch: 304 Epoch: 1\n",
            "d_loss: 0.16254252446468342\n",
            "g_loss: 0.10766391456127167\n",
            "Batch: 305 Epoch: 1\n",
            "d_loss: 0.16254276100812604\n",
            "g_loss: 0.10614907741546631\n",
            "Batch: 306 Epoch: 1\n",
            "d_loss: 0.16254314787602908\n",
            "g_loss: 0.10782404243946075\n",
            "Batch: 307 Epoch: 1\n",
            "d_loss: 0.1625429123468649\n",
            "g_loss: 0.106508269906044\n",
            "Batch: 308 Epoch: 1\n",
            "d_loss: 0.16254308639269155\n",
            "g_loss: 0.10734409093856812\n",
            "Batch: 309 Epoch: 1\n",
            "d_loss: 0.16254193937338002\n",
            "g_loss: 0.10736297070980072\n",
            "Batch: 310 Epoch: 1\n",
            "d_loss: 0.16254255165835474\n",
            "g_loss: 0.1056525707244873\n",
            "Batch: 311 Epoch: 1\n",
            "d_loss: 0.16254340134014456\n",
            "g_loss: 0.10763534158468246\n",
            "Batch: 312 Epoch: 1\n",
            "d_loss: 0.16254344567632373\n",
            "g_loss: 0.10598291456699371\n",
            "Batch: 313 Epoch: 1\n",
            "d_loss: 0.16254313215224414\n",
            "g_loss: 0.10723769664764404\n",
            "Batch: 314 Epoch: 1\n",
            "d_loss: 0.16254316541488834\n",
            "g_loss: 0.106222964823246\n",
            "Batch: 315 Epoch: 1\n",
            "d_loss: 0.1625419544932427\n",
            "g_loss: 0.1071668267250061\n",
            "Batch: 316 Epoch: 1\n",
            "d_loss: 0.1625419242954642\n",
            "g_loss: 0.10638831555843353\n",
            "Batch: 317 Epoch: 1\n",
            "d_loss: 0.16254213072129176\n",
            "g_loss: 0.10659289360046387\n",
            "Batch: 318 Epoch: 1\n",
            "d_loss: 0.1625416729401863\n",
            "g_loss: 0.10679461807012558\n",
            "Batch: 319 Epoch: 1\n",
            "d_loss: 0.1625422356744579\n",
            "g_loss: 0.10797715187072754\n",
            "Batch: 320 Epoch: 1\n",
            "d_loss: 0.16254984013302476\n",
            "g_loss: 0.10341129451990128\n",
            "Batch: 321 Epoch: 1\n",
            "d_loss: 0.16256610894537715\n",
            "g_loss: 0.11020191013813019\n",
            "Batch: 322 Epoch: 1\n",
            "d_loss: 0.16257132677556996\n",
            "g_loss: 0.10323095321655273\n",
            "Batch: 323 Epoch: 1\n",
            "d_loss: 0.16257205644991046\n",
            "g_loss: 0.11060818284749985\n",
            "Batch: 324 Epoch: 1\n",
            "d_loss: 0.16256371377942003\n",
            "g_loss: 0.10338805615901947\n",
            "Batch: 325 Epoch: 1\n",
            "d_loss: 0.16255721912823162\n",
            "g_loss: 0.1087222546339035\n",
            "Batch: 326 Epoch: 1\n",
            "d_loss: 0.1625499179472314\n",
            "g_loss: 0.10854420810937881\n",
            "Batch: 327 Epoch: 1\n",
            "d_loss: 0.16254801014450493\n",
            "g_loss: 0.10503526031970978\n",
            "Batch: 328 Epoch: 1\n",
            "d_loss: 0.1625544313243239\n",
            "g_loss: 0.10994051396846771\n",
            "Batch: 329 Epoch: 1\n",
            "d_loss: 0.16256798938000827\n",
            "g_loss: 0.10649852454662323\n",
            "Batch: 330 Epoch: 1\n",
            "d_loss: 0.1628922210099759\n",
            "g_loss: 0.12094757705926895\n",
            "Batch: 331 Epoch: 1\n",
            "d_loss: 0.16295023206944137\n",
            "g_loss: 0.09879519790410995\n",
            "Batch: 332 Epoch: 1\n",
            "d_loss: 0.16275273635035603\n",
            "g_loss: 0.11054768413305283\n",
            "Batch: 333 Epoch: 1\n",
            "d_loss: 0.16256243836908624\n",
            "g_loss: 0.10739777237176895\n",
            "Batch: 334 Epoch: 1\n",
            "d_loss: 0.16254239728172593\n",
            "g_loss: 0.10707112401723862\n",
            "Batch: 335 Epoch: 1\n",
            "d_loss: 0.1631972257221932\n",
            "g_loss: 0.09073514491319656\n",
            "Batch: 336 Epoch: 1\n",
            "d_loss: 0.16353195838262025\n",
            "g_loss: 0.10727517306804657\n",
            "Batch: 337 Epoch: 1\n",
            "d_loss: 0.16258259055566526\n",
            "g_loss: 0.11721484363079071\n",
            "Batch: 338 Epoch: 1\n",
            "d_loss: 0.16265007137712928\n",
            "g_loss: 0.10726664960384369\n",
            "Batch: 339 Epoch: 1\n",
            "d_loss: 0.16255382956838815\n",
            "g_loss: 0.10397329181432724\n",
            "Batch: 340 Epoch: 1\n",
            "d_loss: 0.16257350895428146\n",
            "g_loss: 0.10915732383728027\n",
            "Batch: 341 Epoch: 1\n",
            "d_loss: 0.16254801749077785\n",
            "g_loss: 0.10785986483097076\n",
            "Batch: 342 Epoch: 1\n",
            "d_loss: 0.16255208349156192\n",
            "g_loss: 0.10674618184566498\n",
            "Batch: 343 Epoch: 1\n",
            "d_loss: 0.16254262361576366\n",
            "g_loss: 0.10686063766479492\n",
            "Batch: 344 Epoch: 1\n",
            "d_loss: 0.16254280236546492\n",
            "g_loss: 0.10622414201498032\n",
            "Batch: 345 Epoch: 1\n",
            "d_loss: 0.16254647107588482\n",
            "g_loss: 0.10551229864358902\n",
            "Batch: 346 Epoch: 1\n",
            "d_loss: 0.1625421205898192\n",
            "g_loss: 0.10574257373809814\n",
            "Batch: 347 Epoch: 1\n",
            "d_loss: 0.16254385541537886\n",
            "g_loss: 0.10696891695261002\n",
            "Batch: 348 Epoch: 1\n",
            "d_loss: 0.1625454969621103\n",
            "g_loss: 0.10589604079723358\n",
            "Batch: 349 Epoch: 1\n",
            "d_loss: 0.16254392451509148\n",
            "g_loss: 0.10623438656330109\n",
            "Batch: 350 Epoch: 1\n",
            "d_loss: 0.16254760924098832\n",
            "g_loss: 0.10780593007802963\n",
            "Batch: 351 Epoch: 1\n",
            "d_loss: 0.16254530656487987\n",
            "g_loss: 0.10634095966815948\n",
            "Batch: 352 Epoch: 1\n",
            "d_loss: 0.16254607807536559\n",
            "g_loss: 0.10722477734088898\n",
            "Batch: 353 Epoch: 1\n",
            "d_loss: 0.16254260184204838\n",
            "g_loss: 0.10753029584884644\n",
            "Batch: 354 Epoch: 1\n",
            "d_loss: 0.16254513172722795\n",
            "g_loss: 0.10658764839172363\n",
            "Batch: 355 Epoch: 1\n",
            "d_loss: 0.1625419938699011\n",
            "g_loss: 0.1063859686255455\n",
            "Batch: 356 Epoch: 1\n",
            "d_loss: 0.16254218432377598\n",
            "g_loss: 0.1067575216293335\n",
            "Batch: 357 Epoch: 1\n",
            "d_loss: 0.1625421601036905\n",
            "g_loss: 0.10689987242221832\n",
            "Batch: 358 Epoch: 1\n",
            "d_loss: 0.1625422135405188\n",
            "g_loss: 0.10688497126102448\n",
            "Batch: 359 Epoch: 1\n",
            "d_loss: 0.1625422503995324\n",
            "g_loss: 0.10638382285833359\n",
            "Batch: 360 Epoch: 1\n",
            "d_loss: 0.1625425998619363\n",
            "g_loss: 0.10640618950128555\n",
            "Batch: 361 Epoch: 1\n",
            "d_loss: 0.16254219646631896\n",
            "g_loss: 0.1070447787642479\n",
            "Batch: 362 Epoch: 1\n",
            "d_loss: 0.16254242637531036\n",
            "g_loss: 0.10647976398468018\n",
            "Batch: 363 Epoch: 1\n",
            "d_loss: 0.16254187510539708\n",
            "g_loss: 0.10647188127040863\n",
            "Batch: 364 Epoch: 1\n",
            "d_loss: 0.16254248187576792\n",
            "g_loss: 0.10702027380466461\n",
            "Batch: 365 Epoch: 1\n",
            "d_loss: 0.1625420521668488\n",
            "g_loss: 0.10689115524291992\n",
            "Batch: 366 Epoch: 1\n",
            "d_loss: 0.16254271609892612\n",
            "g_loss: 0.10622207075357437\n",
            "Batch: 367 Epoch: 1\n",
            "d_loss: 0.1625460029178285\n",
            "g_loss: 0.10830654203891754\n",
            "Batch: 368 Epoch: 1\n",
            "d_loss: 0.16254368725511625\n",
            "g_loss: 0.10731790959835052\n",
            "Batch: 369 Epoch: 1\n",
            "d_loss: 0.1625448641951408\n",
            "g_loss: 0.10580326616764069\n",
            "Batch: 370 Epoch: 1\n",
            "d_loss: 0.16254860440659513\n",
            "g_loss: 0.10788532346487045\n",
            "Batch: 371 Epoch: 1\n",
            "d_loss: 0.1625440255689128\n",
            "g_loss: 0.10687653720378876\n",
            "Batch: 372 Epoch: 1\n",
            "d_loss: 0.16254234788944188\n",
            "g_loss: 0.10603330284357071\n",
            "Batch: 373 Epoch: 1\n",
            "d_loss: 0.16254285124431078\n",
            "g_loss: 0.10697457939386368\n",
            "Batch: 374 Epoch: 1\n",
            "d_loss: 0.16254264130753882\n",
            "g_loss: 0.10643844306468964\n",
            "Batch: 375 Epoch: 1\n",
            "d_loss: 0.1625444611141802\n",
            "g_loss: 0.10799894481897354\n",
            "Batch: 376 Epoch: 1\n",
            "d_loss: 0.16254432004694763\n",
            "g_loss: 0.10689669847488403\n",
            "Batch: 377 Epoch: 1\n",
            "d_loss: 0.16254273125389318\n",
            "g_loss: 0.10743347555398941\n",
            "Batch: 378 Epoch: 1\n",
            "d_loss: 0.16254217355092493\n",
            "g_loss: 0.10710994154214859\n",
            "Batch: 379 Epoch: 1\n",
            "d_loss: 0.16254207857858916\n",
            "g_loss: 0.10721869766712189\n",
            "Batch: 380 Epoch: 1\n",
            "d_loss: 0.16254183574660885\n",
            "g_loss: 0.10713471472263336\n",
            "Batch: 381 Epoch: 1\n",
            "d_loss: 0.16254275738877055\n",
            "g_loss: 0.10610301792621613\n",
            "Batch: 382 Epoch: 1\n",
            "d_loss: 0.16254293055303748\n",
            "g_loss: 0.10698314011096954\n",
            "Batch: 383 Epoch: 1\n",
            "d_loss: 0.1625422965513721\n",
            "g_loss: 0.10679107904434204\n",
            "Batch: 384 Epoch: 1\n",
            "d_loss: 0.162542368899949\n",
            "g_loss: 0.10686790943145752\n",
            "Batch: 385 Epoch: 1\n",
            "d_loss: 0.16254175962681217\n",
            "g_loss: 0.10709597915410995\n",
            "Batch: 386 Epoch: 1\n",
            "d_loss: 0.16254251924673468\n",
            "g_loss: 0.10677297413349152\n",
            "Batch: 387 Epoch: 1\n",
            "d_loss: 0.1625418085272088\n",
            "g_loss: 0.10677491128444672\n",
            "Batch: 388 Epoch: 1\n",
            "d_loss: 0.16254234228912168\n",
            "g_loss: 0.10722430050373077\n",
            "Batch: 389 Epoch: 1\n",
            "d_loss: 0.16254213616879554\n",
            "g_loss: 0.10655305534601212\n",
            "Batch: 390 Epoch: 1\n",
            "d_loss: 0.16254286634155335\n",
            "g_loss: 0.10704053938388824\n",
            "Batch: 391 Epoch: 1\n",
            "d_loss: 0.16254200111082184\n",
            "g_loss: 0.10724462568759918\n",
            "Batch: 392 Epoch: 1\n",
            "d_loss: 0.16254197101284262\n",
            "g_loss: 0.10664329677820206\n",
            "Batch: 393 Epoch: 1\n",
            "d_loss: 0.16254188194129426\n",
            "g_loss: 0.10665079206228256\n",
            "Batch: 394 Epoch: 1\n",
            "d_loss: 0.16254194669526356\n",
            "g_loss: 0.10622258484363556\n",
            "Batch: 395 Epoch: 1\n",
            "d_loss: 0.1625432046487134\n",
            "g_loss: 0.10712697356939316\n",
            "Batch: 396 Epoch: 1\n",
            "d_loss: 0.16254198099086636\n",
            "g_loss: 0.10757336765527725\n",
            "Batch: 397 Epoch: 1\n",
            "d_loss: 0.16254247357660745\n",
            "g_loss: 0.10668780654668808\n",
            "Batch: 398 Epoch: 1\n",
            "d_loss: 0.162541704844692\n",
            "g_loss: 0.10675098747015\n",
            "Batch: 399 Epoch: 1\n",
            "d_loss: 0.1625417644839473\n",
            "g_loss: 0.10684902966022491\n",
            "Batch: 400 Epoch: 1\n",
            "d_loss: 0.16254191922904226\n",
            "g_loss: 0.10688912868499756\n",
            "Batch: 401 Epoch: 1\n",
            "d_loss: 0.16254187594769576\n",
            "g_loss: 0.10704505443572998\n",
            "Batch: 402 Epoch: 1\n",
            "d_loss: 0.1625423724152597\n",
            "g_loss: 0.10636895895004272\n",
            "Batch: 403 Epoch: 1\n",
            "d_loss: 0.16254235869742928\n",
            "g_loss: 0.10706043243408203\n",
            "Batch: 404 Epoch: 1\n",
            "d_loss: 0.16254240015869215\n",
            "g_loss: 0.10761265456676483\n",
            "Batch: 405 Epoch: 1\n",
            "d_loss: 0.1625423554110057\n",
            "g_loss: 0.10677705705165863\n",
            "Batch: 406 Epoch: 1\n",
            "d_loss: 0.1625417914238696\n",
            "g_loss: 0.10677280277013779\n",
            "Batch: 407 Epoch: 1\n",
            "d_loss: 0.16254169573503674\n",
            "g_loss: 0.10715611279010773\n",
            "Batch: 408 Epoch: 1\n",
            "d_loss: 0.16254177538742454\n",
            "g_loss: 0.10712502151727676\n",
            "Batch: 409 Epoch: 1\n",
            "d_loss: 0.1625421445013444\n",
            "g_loss: 0.10739407688379288\n",
            "Batch: 410 Epoch: 1\n",
            "d_loss: 0.16254313430302147\n",
            "g_loss: 0.10636226832866669\n",
            "Batch: 411 Epoch: 1\n",
            "d_loss: 0.16254263760728094\n",
            "g_loss: 0.10715772956609726\n",
            "Batch: 412 Epoch: 1\n",
            "d_loss: 0.16254202000976647\n",
            "g_loss: 0.10702469199895859\n",
            "Batch: 413 Epoch: 1\n",
            "d_loss: 0.16254199514838774\n",
            "g_loss: 0.10754235833883286\n",
            "Batch: 414 Epoch: 1\n",
            "d_loss: 0.16254210459184293\n",
            "g_loss: 0.10695581138134003\n",
            "Batch: 415 Epoch: 1\n",
            "d_loss: 0.16254187890693572\n",
            "g_loss: 0.1069432720541954\n",
            "Batch: 416 Epoch: 1\n",
            "d_loss: 0.16254192160020153\n",
            "g_loss: 0.10704974830150604\n",
            "Batch: 417 Epoch: 1\n",
            "d_loss: 0.16254182330798983\n",
            "g_loss: 0.10723002254962921\n",
            "Batch: 418 Epoch: 1\n",
            "d_loss: 0.16254168283861503\n",
            "g_loss: 0.10723741352558136\n",
            "Batch: 419 Epoch: 1\n",
            "d_loss: 0.16254178233858596\n",
            "g_loss: 0.10700821876525879\n",
            "Batch: 420 Epoch: 1\n",
            "d_loss: 0.16254210371448607\n",
            "g_loss: 0.10705957561731339\n",
            "Batch: 421 Epoch: 1\n",
            "d_loss: 0.1625419375113566\n",
            "g_loss: 0.10743530094623566\n",
            "Batch: 422 Epoch: 1\n",
            "d_loss: 0.16254205923769405\n",
            "g_loss: 0.10722331702709198\n",
            "Batch: 423 Epoch: 1\n",
            "d_loss: 0.16254212946839175\n",
            "g_loss: 0.10678891092538834\n",
            "Batch: 424 Epoch: 1\n",
            "d_loss: 0.16254193448619247\n",
            "g_loss: 0.10711950063705444\n",
            "Batch: 425 Epoch: 1\n",
            "d_loss: 0.16254187623898275\n",
            "g_loss: 0.10710438340902328\n",
            "Batch: 426 Epoch: 1\n",
            "d_loss: 0.1625420098637136\n",
            "g_loss: 0.1075044646859169\n",
            "Batch: 427 Epoch: 1\n",
            "d_loss: 0.16254212883593766\n",
            "g_loss: 0.10707877576351166\n",
            "Batch: 428 Epoch: 1\n",
            "d_loss: 0.1625417105047262\n",
            "g_loss: 0.10675294697284698\n",
            "Batch: 429 Epoch: 1\n",
            "d_loss: 0.1625422894316486\n",
            "g_loss: 0.1075611338019371\n",
            "Batch: 430 Epoch: 1\n",
            "d_loss: 0.16254313956589073\n",
            "g_loss: 0.10654094070196152\n",
            "Batch: 431 Epoch: 1\n",
            "d_loss: 0.1625437217106409\n",
            "g_loss: 0.1076960414648056\n",
            "Batch: 432 Epoch: 1\n",
            "d_loss: 0.16254263327623164\n",
            "g_loss: 0.10654747486114502\n",
            "Batch: 433 Epoch: 1\n",
            "d_loss: 0.16254217884704758\n",
            "g_loss: 0.10676151514053345\n",
            "Batch: 434 Epoch: 1\n",
            "d_loss: 0.16254192376087673\n",
            "g_loss: 0.1063304990530014\n",
            "Batch: 435 Epoch: 1\n",
            "d_loss: 0.16254267894672836\n",
            "g_loss: 0.10714723914861679\n",
            "Batch: 436 Epoch: 1\n",
            "d_loss: 0.162541946588469\n",
            "g_loss: 0.10696122795343399\n",
            "Batch: 437 Epoch: 1\n",
            "d_loss: 0.1625422335925606\n",
            "g_loss: 0.10675406455993652\n",
            "Batch: 438 Epoch: 1\n",
            "d_loss: 0.1625423258241412\n",
            "g_loss: 0.10723797976970673\n",
            "Batch: 439 Epoch: 1\n",
            "d_loss: 0.1625420510037543\n",
            "g_loss: 0.10722502321004868\n",
            "Batch: 440 Epoch: 1\n",
            "d_loss: 0.16254284420697473\n",
            "g_loss: 0.10631337016820908\n",
            "Batch: 441 Epoch: 1\n",
            "d_loss: 0.16254319963644548\n",
            "g_loss: 0.10724673420190811\n",
            "Batch: 442 Epoch: 1\n",
            "d_loss: 0.16254205043013314\n",
            "g_loss: 0.10714308172464371\n",
            "Batch: 443 Epoch: 1\n",
            "d_loss: 0.16254169560456688\n",
            "g_loss: 0.10702158510684967\n",
            "Batch: 444 Epoch: 1\n",
            "d_loss: 0.1625416625634486\n",
            "g_loss: 0.10674943774938583\n",
            "Batch: 445 Epoch: 1\n",
            "d_loss: 0.16254229028449174\n",
            "g_loss: 0.10761867463588715\n",
            "Batch: 446 Epoch: 1\n",
            "d_loss: 0.16254228832293904\n",
            "g_loss: 0.10703568160533905\n",
            "Batch: 447 Epoch: 1\n",
            "d_loss: 0.1625418103327405\n",
            "g_loss: 0.10693333297967911\n",
            "Batch: 448 Epoch: 1\n",
            "d_loss: 0.1625419627659852\n",
            "g_loss: 0.1071668416261673\n",
            "Batch: 449 Epoch: 1\n",
            "d_loss: 0.16254187356012295\n",
            "g_loss: 0.10681388527154922\n",
            "Batch: 450 Epoch: 1\n",
            "d_loss: 0.16254175625967804\n",
            "g_loss: 0.10723254829645157\n",
            "Batch: 451 Epoch: 1\n",
            "d_loss: 0.16254224474126033\n",
            "g_loss: 0.10719015449285507\n",
            "Batch: 452 Epoch: 1\n",
            "d_loss: 0.1625416951738572\n",
            "g_loss: 0.10705997794866562\n",
            "Batch: 453 Epoch: 1\n",
            "d_loss: 0.1625417510587326\n",
            "g_loss: 0.10717473179101944\n",
            "Batch: 454 Epoch: 1\n",
            "d_loss: 0.16254231725939405\n",
            "g_loss: 0.10710801929235458\n",
            "Batch: 455 Epoch: 1\n",
            "d_loss: 0.16254232136920166\n",
            "g_loss: 0.10640052706003189\n",
            "Batch: 456 Epoch: 1\n",
            "d_loss: 0.1625425865056087\n",
            "g_loss: 0.107572041451931\n",
            "Batch: 457 Epoch: 1\n",
            "d_loss: 0.1625418292748435\n",
            "g_loss: 0.10716166347265244\n",
            "Batch: 458 Epoch: 1\n",
            "d_loss: 0.16254180341336166\n",
            "g_loss: 0.10744402557611465\n",
            "Batch: 459 Epoch: 1\n",
            "d_loss: 0.16254193379893422\n",
            "g_loss: 0.10702665895223618\n",
            "Batch: 460 Epoch: 1\n",
            "d_loss: 0.1625418722214249\n",
            "g_loss: 0.10654095560312271\n",
            "Batch: 461 Epoch: 1\n",
            "d_loss: 0.16254216818384037\n",
            "g_loss: 0.10742125660181046\n",
            "Batch: 462 Epoch: 1\n",
            "d_loss: 0.16254184170552577\n",
            "g_loss: 0.10728075355291367\n",
            "Batch: 463 Epoch: 1\n",
            "d_loss: 0.16254175446920271\n",
            "g_loss: 0.10684366524219513\n",
            "Batch: 464 Epoch: 1\n",
            "d_loss: 0.16254196247484742\n",
            "g_loss: 0.10709168761968613\n",
            "Batch: 465 Epoch: 1\n",
            "d_loss: 0.16254224307091647\n",
            "g_loss: 0.1065119057893753\n",
            "Batch: 466 Epoch: 1\n",
            "d_loss: 0.16254306071162716\n",
            "g_loss: 0.10731025040149689\n",
            "Batch: 467 Epoch: 1\n",
            "d_loss: 0.16254215331566968\n",
            "g_loss: 0.10687242448329926\n",
            "Batch: 468 Epoch: 1\n",
            "d_loss: 0.1625416349566109\n",
            "g_loss: 0.10663428157567978\n",
            "Batch: 469 Epoch: 1\n",
            "d_loss: 0.16254191840540955\n",
            "g_loss: 0.10662567615509033\n",
            "Batch: 470 Epoch: 1\n",
            "d_loss: 0.1625424125770678\n",
            "g_loss: 0.10757921636104584\n",
            "Batch: 471 Epoch: 1\n",
            "d_loss: 0.16254282176844015\n",
            "g_loss: 0.1068926602602005\n",
            "Batch: 472 Epoch: 1\n",
            "d_loss: 0.16254177109499324\n",
            "g_loss: 0.106576107442379\n",
            "Batch: 473 Epoch: 1\n",
            "d_loss: 0.1625423894299871\n",
            "g_loss: 0.10743473470211029\n",
            "Batch: 474 Epoch: 1\n",
            "d_loss: 0.16254187005610277\n",
            "g_loss: 0.10726599395275116\n",
            "Batch: 475 Epoch: 1\n",
            "d_loss: 0.16254195869503718\n",
            "g_loss: 0.10672304779291153\n",
            "Batch: 476 Epoch: 1\n",
            "d_loss: 0.1625419882465664\n",
            "g_loss: 0.10603207349777222\n",
            "Batch: 477 Epoch: 1\n",
            "d_loss: 0.162542885118917\n",
            "g_loss: 0.10711034387350082\n",
            "Batch: 478 Epoch: 1\n",
            "d_loss: 0.1625418232136795\n",
            "g_loss: 0.1069328561425209\n",
            "Batch: 479 Epoch: 1\n",
            "d_loss: 0.16254179481141762\n",
            "g_loss: 0.10731496661901474\n",
            "Batch: 480 Epoch: 1\n",
            "d_loss: 0.16254197168294127\n",
            "g_loss: 0.10664843022823334\n",
            "Batch: 481 Epoch: 1\n",
            "d_loss: 0.16254203110323573\n",
            "g_loss: 0.10713223367929459\n",
            "Batch: 482 Epoch: 1\n",
            "d_loss: 0.16254173382532144\n",
            "g_loss: 0.10691212117671967\n",
            "Batch: 483 Epoch: 1\n",
            "d_loss: 0.16254218162363543\n",
            "g_loss: 0.10683491080999374\n",
            "Batch: 484 Epoch: 1\n",
            "d_loss: 0.16254175158127993\n",
            "g_loss: 0.10679285228252411\n",
            "Batch: 485 Epoch: 1\n",
            "d_loss: 0.16254180722828693\n",
            "g_loss: 0.10712448507547379\n",
            "Batch: 486 Epoch: 1\n",
            "d_loss: 0.16254176271517906\n",
            "g_loss: 0.10730794817209244\n",
            "Batch: 487 Epoch: 1\n",
            "d_loss: 0.1625421644062186\n",
            "g_loss: 0.10670201480388641\n",
            "Batch: 488 Epoch: 1\n",
            "d_loss: 0.16254174908091557\n",
            "g_loss: 0.10699045658111572\n",
            "Batch: 489 Epoch: 1\n",
            "d_loss: 0.16254171720430577\n",
            "g_loss: 0.10660108178853989\n",
            "Batch: 490 Epoch: 1\n",
            "d_loss: 0.16254173342184686\n",
            "g_loss: 0.10679157823324203\n",
            "Batch: 491 Epoch: 1\n",
            "d_loss: 0.16254209174994827\n",
            "g_loss: 0.10756129026412964\n",
            "Batch: 492 Epoch: 1\n",
            "d_loss: 0.1625422241203509\n",
            "g_loss: 0.10675287246704102\n",
            "Batch: 493 Epoch: 1\n",
            "d_loss: 0.16254183873482475\n",
            "g_loss: 0.10622791200876236\n",
            "Batch: 494 Epoch: 1\n",
            "d_loss: 0.16254253857941592\n",
            "g_loss: 0.10696306079626083\n",
            "Batch: 495 Epoch: 1\n",
            "d_loss: 0.16254207471912707\n",
            "g_loss: 0.10687931627035141\n",
            "Batch: 496 Epoch: 1\n",
            "d_loss: 0.16254167099437922\n",
            "g_loss: 0.10688762366771698\n",
            "Batch: 497 Epoch: 1\n",
            "d_loss: 0.1625419862357731\n",
            "g_loss: 0.10687415301799774\n",
            "Batch: 498 Epoch: 1\n",
            "d_loss: 0.16254199977375094\n",
            "g_loss: 0.10700664669275284\n",
            "Batch: 499 Epoch: 1\n",
            "d_loss: 0.1625418358473283\n",
            "g_loss: 0.10723499953746796\n",
            "Batch: 500 Epoch: 1\n",
            "d_loss: 0.16254210439812766\n",
            "g_loss: 0.10656454414129257\n",
            "Batch: 501 Epoch: 1\n",
            "d_loss: 0.16254171888732571\n",
            "g_loss: 0.10642117261886597\n",
            "Batch: 502 Epoch: 1\n",
            "d_loss: 0.1625427284298766\n",
            "g_loss: 0.10775654017925262\n",
            "Batch: 503 Epoch: 1\n",
            "d_loss: 0.1625434621282693\n",
            "g_loss: 0.10651860386133194\n",
            "Batch: 504 Epoch: 1\n",
            "d_loss: 0.16254177623675758\n",
            "g_loss: 0.10640035569667816\n",
            "Batch: 505 Epoch: 1\n",
            "d_loss: 0.16254194219305873\n",
            "g_loss: 0.10637509822845459\n",
            "Batch: 506 Epoch: 1\n",
            "d_loss: 0.1625417169269454\n",
            "g_loss: 0.10659285634756088\n",
            "Batch: 507 Epoch: 1\n",
            "d_loss: 0.1625419154348151\n",
            "g_loss: 0.10620403289794922\n",
            "Batch: 508 Epoch: 1\n",
            "d_loss: 0.16254183746347906\n",
            "g_loss: 0.10655759274959564\n",
            "Batch: 509 Epoch: 1\n",
            "d_loss: 0.16254186567881845\n",
            "g_loss: 0.10736056417226791\n",
            "Batch: 510 Epoch: 1\n",
            "d_loss: 0.1625418349683656\n",
            "g_loss: 0.10693750530481339\n",
            "Batch: 511 Epoch: 1\n",
            "d_loss: 0.1625418649062027\n",
            "g_loss: 0.10622526705265045\n",
            "Batch: 512 Epoch: 1\n",
            "d_loss: 0.16254222285624564\n",
            "g_loss: 0.10675479471683502\n",
            "Batch: 513 Epoch: 1\n",
            "d_loss: 0.162541792905202\n",
            "g_loss: 0.1069268137216568\n",
            "Batch: 514 Epoch: 1\n",
            "d_loss: 0.16254180462946977\n",
            "g_loss: 0.10660550743341446\n",
            "Batch: 515 Epoch: 1\n",
            "d_loss: 0.16254164090632628\n",
            "g_loss: 0.10626818239688873\n",
            "Batch: 516 Epoch: 1\n",
            "d_loss: 0.16254210239845435\n",
            "g_loss: 0.1069459542632103\n",
            "Batch: 517 Epoch: 1\n",
            "d_loss: 0.16254243167070115\n",
            "g_loss: 0.10616596788167953\n",
            "Batch: 518 Epoch: 1\n",
            "d_loss: 0.16254203196707095\n",
            "g_loss: 0.10654465109109879\n",
            "Batch: 519 Epoch: 1\n",
            "d_loss: 0.16254165983202995\n",
            "g_loss: 0.10668458789587021\n",
            "Batch: 520 Epoch: 1\n",
            "d_loss: 0.16254176237939788\n",
            "g_loss: 0.10637593269348145\n",
            "Batch: 521 Epoch: 1\n",
            "d_loss: 0.16254228540410764\n",
            "g_loss: 0.10714788734912872\n",
            "Batch: 522 Epoch: 1\n",
            "d_loss: 0.1625424014568253\n",
            "g_loss: 0.10648081451654434\n",
            "Batch: 523 Epoch: 1\n",
            "d_loss: 0.16254184746581757\n",
            "g_loss: 0.10655498504638672\n",
            "Batch: 524 Epoch: 1\n",
            "d_loss: 0.16254182692473762\n",
            "g_loss: 0.10704945027828217\n",
            "Batch: 525 Epoch: 1\n",
            "d_loss: 0.1625416569736018\n",
            "g_loss: 0.10713981091976166\n",
            "Batch: 526 Epoch: 1\n",
            "d_loss: 0.16254246714466092\n",
            "g_loss: 0.10618758201599121\n",
            "Batch: 527 Epoch: 1\n",
            "d_loss: 0.1625424027982305\n",
            "g_loss: 0.10696204006671906\n",
            "Batch: 528 Epoch: 1\n",
            "d_loss: 0.16254220779442363\n",
            "g_loss: 0.10669390857219696\n",
            "Batch: 529 Epoch: 1\n",
            "d_loss: 0.1625419229178675\n",
            "g_loss: 0.10696284472942352\n",
            "Batch: 530 Epoch: 1\n",
            "d_loss: 0.1625418366885114\n",
            "g_loss: 0.10657312721014023\n",
            "Batch: 531 Epoch: 1\n",
            "d_loss: 0.16254187900152317\n",
            "g_loss: 0.10696510225534439\n",
            "Batch: 532 Epoch: 1\n",
            "d_loss: 0.16254186326018782\n",
            "g_loss: 0.10723098367452621\n",
            "Batch: 533 Epoch: 1\n",
            "d_loss: 0.16254255074491653\n",
            "g_loss: 0.10605933517217636\n",
            "Batch: 534 Epoch: 1\n",
            "d_loss: 0.16254260929114395\n",
            "g_loss: 0.1071242243051529\n",
            "Batch: 535 Epoch: 1\n",
            "d_loss: 0.1625419384996647\n",
            "g_loss: 0.10672847181558609\n",
            "Batch: 536 Epoch: 1\n",
            "d_loss: 0.16254167109023854\n",
            "g_loss: 0.10675568878650665\n",
            "Batch: 537 Epoch: 1\n",
            "d_loss: 0.16254167190723479\n",
            "g_loss: 0.10676251351833344\n",
            "Batch: 538 Epoch: 1\n",
            "d_loss: 0.1625417956607862\n",
            "g_loss: 0.10713917016983032\n",
            "Batch: 539 Epoch: 1\n",
            "d_loss: 0.16254180325267953\n",
            "g_loss: 0.1068870797753334\n",
            "Batch: 540 Epoch: 1\n",
            "d_loss: 0.16254227972946467\n",
            "g_loss: 0.10669161379337311\n",
            "Batch: 541 Epoch: 1\n",
            "d_loss: 0.16254190742004937\n",
            "g_loss: 0.10660324990749359\n",
            "Batch: 542 Epoch: 1\n",
            "d_loss: 0.16254165594115477\n",
            "g_loss: 0.1066879853606224\n",
            "Batch: 543 Epoch: 1\n",
            "d_loss: 0.16254230852997864\n",
            "g_loss: 0.10753653198480606\n",
            "Batch: 544 Epoch: 1\n",
            "d_loss: 0.16254297886982272\n",
            "g_loss: 0.1062079444527626\n",
            "Batch: 545 Epoch: 1\n",
            "d_loss: 0.16254251660645025\n",
            "g_loss: 0.10707905143499374\n",
            "Batch: 546 Epoch: 1\n",
            "d_loss: 0.16254199716000528\n",
            "g_loss: 0.10726122558116913\n",
            "Batch: 547 Epoch: 1\n",
            "d_loss: 0.16254275721924216\n",
            "g_loss: 0.10598472505807877\n",
            "Batch: 548 Epoch: 1\n",
            "d_loss: 0.16254251906200068\n",
            "g_loss: 0.10677621513605118\n",
            "Batch: 549 Epoch: 1\n",
            "d_loss: 0.1625417437961545\n",
            "g_loss: 0.10696331411600113\n",
            "Batch: 550 Epoch: 1\n",
            "d_loss: 0.16254180310529165\n",
            "g_loss: 0.10736346244812012\n",
            "Batch: 551 Epoch: 1\n",
            "d_loss: 0.1625424572550358\n",
            "g_loss: 0.10855609178543091\n",
            "Batch: 552 Epoch: 1\n",
            "d_loss: 0.16254515812907755\n",
            "g_loss: 0.10654252767562866\n",
            "Batch: 553 Epoch: 1\n",
            "d_loss: 0.1625426354558357\n",
            "g_loss: 0.10727403312921524\n",
            "Batch: 554 Epoch: 1\n",
            "d_loss: 0.16254187815180643\n",
            "g_loss: 0.10754232108592987\n",
            "Batch: 555 Epoch: 1\n",
            "d_loss: 0.1625447381913716\n",
            "g_loss: 0.10687490552663803\n",
            "Batch: 556 Epoch: 1\n",
            "d_loss: 0.16254307417854363\n",
            "g_loss: 0.10679571330547333\n",
            "Batch: 557 Epoch: 1\n",
            "d_loss: 0.16254284641419758\n",
            "g_loss: 0.10610301792621613\n",
            "Batch: 558 Epoch: 1\n",
            "d_loss: 0.16254300345310924\n",
            "g_loss: 0.10728597640991211\n",
            "Batch: 559 Epoch: 1\n",
            "d_loss: 0.16254202665646034\n",
            "g_loss: 0.10689107328653336\n",
            "Batch: 560 Epoch: 1\n",
            "d_loss: 0.16254177186131358\n",
            "g_loss: 0.10703631490468979\n",
            "Batch: 561 Epoch: 1\n",
            "d_loss: 0.16254188044758422\n",
            "g_loss: 0.10751378536224365\n",
            "Batch: 562 Epoch: 1\n",
            "d_loss: 0.162541912086418\n",
            "g_loss: 0.10718712955713272\n",
            "Batch: 563 Epoch: 1\n",
            "d_loss: 0.162541831223038\n",
            "g_loss: 0.10682591050863266\n",
            "Batch: 564 Epoch: 1\n",
            "d_loss: 0.1625416685850496\n",
            "g_loss: 0.10702897608280182\n",
            "Batch: 565 Epoch: 1\n",
            "d_loss: 0.16254198219743898\n",
            "g_loss: 0.10707028210163116\n",
            "Batch: 566 Epoch: 1\n",
            "d_loss: 0.1625418614429961\n",
            "g_loss: 0.10715478658676147\n",
            "Batch: 567 Epoch: 1\n",
            "d_loss: 0.16254183541931155\n",
            "g_loss: 0.10686130821704865\n",
            "Batch: 568 Epoch: 1\n",
            "d_loss: 0.16254180956964603\n",
            "g_loss: 0.10654433071613312\n",
            "Batch: 569 Epoch: 1\n",
            "d_loss: 0.162542880401773\n",
            "g_loss: 0.10782716423273087\n",
            "Batch: 570 Epoch: 1\n",
            "d_loss: 0.1625429345496201\n",
            "g_loss: 0.10707304626703262\n",
            "Batch: 571 Epoch: 1\n",
            "d_loss: 0.1625417923480441\n",
            "g_loss: 0.10736288875341415\n",
            "Batch: 572 Epoch: 1\n",
            "d_loss: 0.16254186657614866\n",
            "g_loss: 0.10709366947412491\n",
            "Batch: 573 Epoch: 1\n",
            "d_loss: 0.16254210144624892\n",
            "g_loss: 0.1072884052991867\n",
            "Batch: 574 Epoch: 1\n",
            "d_loss: 0.16254174500450347\n",
            "g_loss: 0.10762592405080795\n",
            "Batch: 575 Epoch: 1\n",
            "d_loss: 0.16254179306067584\n",
            "g_loss: 0.10756085067987442\n",
            "Batch: 576 Epoch: 1\n",
            "d_loss: 0.1625421597778285\n",
            "g_loss: 0.1066368967294693\n",
            "Batch: 577 Epoch: 1\n",
            "d_loss: 0.16254210030005822\n",
            "g_loss: 0.10729742050170898\n",
            "Batch: 578 Epoch: 1\n",
            "d_loss: 0.16254180257443807\n",
            "g_loss: 0.10719140619039536\n",
            "Batch: 579 Epoch: 1\n",
            "d_loss: 0.16254175734134435\n",
            "g_loss: 0.1072789654135704\n",
            "Batch: 580 Epoch: 1\n",
            "d_loss: 0.16254175851135244\n",
            "g_loss: 0.10702888667583466\n",
            "Batch: 581 Epoch: 1\n",
            "d_loss: 0.16254190702174753\n",
            "g_loss: 0.10673116147518158\n",
            "Batch: 582 Epoch: 1\n",
            "d_loss: 0.16254238309596758\n",
            "g_loss: 0.10754604637622833\n",
            "Batch: 583 Epoch: 1\n",
            "d_loss: 0.16254243030623172\n",
            "g_loss: 0.10697684437036514\n",
            "Batch: 584 Epoch: 1\n",
            "d_loss: 0.16254187618858396\n",
            "g_loss: 0.10724803060293198\n",
            "Batch: 585 Epoch: 1\n",
            "d_loss: 0.16254184789983128\n",
            "g_loss: 0.1077902689576149\n",
            "Batch: 586 Epoch: 1\n",
            "d_loss: 0.16254197950750893\n",
            "g_loss: 0.10758397728204727\n",
            "Batch: 587 Epoch: 1\n",
            "d_loss: 0.16254187933521536\n",
            "g_loss: 0.10709176957607269\n",
            "Batch: 588 Epoch: 1\n",
            "d_loss: 0.1625416820568759\n",
            "g_loss: 0.10679589211940765\n",
            "Batch: 589 Epoch: 1\n",
            "d_loss: 0.1625418006177597\n",
            "g_loss: 0.10713867098093033\n",
            "Batch: 590 Epoch: 1\n",
            "d_loss: 0.16254208488048505\n",
            "g_loss: 0.10708221048116684\n",
            "Batch: 591 Epoch: 1\n",
            "d_loss: 0.16254174176369673\n",
            "g_loss: 0.1068490743637085\n",
            "Batch: 592 Epoch: 1\n",
            "d_loss: 0.1625419843132221\n",
            "g_loss: 0.10720916837453842\n",
            "Batch: 593 Epoch: 1\n",
            "d_loss: 0.1625419793837395\n",
            "g_loss: 0.10666326433420181\n",
            "Batch: 594 Epoch: 1\n",
            "d_loss: 0.16254196462062964\n",
            "g_loss: 0.10736732184886932\n",
            "Batch: 595 Epoch: 1\n",
            "d_loss: 0.16254184650019\n",
            "g_loss: 0.10694976150989532\n",
            "Batch: 596 Epoch: 1\n",
            "d_loss: 0.16254186887601918\n",
            "g_loss: 0.10674762725830078\n",
            "Batch: 597 Epoch: 1\n",
            "d_loss: 0.16254187535911058\n",
            "g_loss: 0.10715937614440918\n",
            "Batch: 598 Epoch: 1\n",
            "d_loss: 0.16254265034683613\n",
            "g_loss: 0.10621881484985352\n",
            "Batch: 599 Epoch: 1\n",
            "d_loss: 0.1625420997580278\n",
            "g_loss: 0.10683996975421906\n",
            "Batch: 600 Epoch: 1\n",
            "d_loss: 0.16254174077121064\n",
            "g_loss: 0.10709939152002335\n",
            "Batch: 601 Epoch: 1\n",
            "d_loss: 0.1625419693924215\n",
            "g_loss: 0.10728661715984344\n",
            "Batch: 602 Epoch: 1\n",
            "d_loss: 0.1625420550243959\n",
            "g_loss: 0.1063796877861023\n",
            "Batch: 603 Epoch: 1\n",
            "d_loss: 0.16254198493042793\n",
            "g_loss: 0.10697567462921143\n",
            "Batch: 604 Epoch: 1\n",
            "d_loss: 0.16254182882352097\n",
            "g_loss: 0.10759203135967255\n",
            "Batch: 605 Epoch: 1\n",
            "d_loss: 0.16254234153852565\n",
            "g_loss: 0.10667165368795395\n",
            "Batch: 606 Epoch: 1\n",
            "d_loss: 0.16254197859402808\n",
            "g_loss: 0.10715220123529434\n",
            "Batch: 607 Epoch: 1\n",
            "d_loss: 0.16254171119966543\n",
            "g_loss: 0.10707306861877441\n",
            "Batch: 608 Epoch: 1\n",
            "d_loss: 0.16254168105321298\n",
            "g_loss: 0.10661711543798447\n",
            "Batch: 609 Epoch: 1\n",
            "d_loss: 0.16254271111135665\n",
            "g_loss: 0.10729215294122696\n",
            "Batch: 610 Epoch: 1\n",
            "d_loss: 0.16254306660741946\n",
            "g_loss: 0.10622791200876236\n",
            "Batch: 611 Epoch: 1\n",
            "d_loss: 0.1625428338029664\n",
            "g_loss: 0.10734550654888153\n",
            "Batch: 612 Epoch: 1\n",
            "d_loss: 0.16254171066454148\n",
            "g_loss: 0.10730626434087753\n",
            "Batch: 613 Epoch: 1\n",
            "d_loss: 0.16254238246931862\n",
            "g_loss: 0.10632888227701187\n",
            "Batch: 614 Epoch: 1\n",
            "d_loss: 0.16254186100894685\n",
            "g_loss: 0.10663644969463348\n",
            "Batch: 615 Epoch: 1\n",
            "d_loss: 0.16254199275196868\n",
            "g_loss: 0.10702617466449738\n",
            "Batch: 616 Epoch: 1\n",
            "d_loss: 0.162542335985691\n",
            "g_loss: 0.10643728077411652\n",
            "Batch: 617 Epoch: 1\n",
            "d_loss: 0.16254183086069673\n",
            "g_loss: 0.10689704120159149\n",
            "Batch: 618 Epoch: 1\n",
            "d_loss: 0.1625425299306329\n",
            "g_loss: 0.10811062157154083\n",
            "Batch: 619 Epoch: 1\n",
            "d_loss: 0.16254565896950623\n",
            "g_loss: 0.10535476356744766\n",
            "Batch: 620 Epoch: 1\n",
            "d_loss: 0.16254623978862526\n",
            "g_loss: 0.10760335624217987\n",
            "Batch: 621 Epoch: 1\n",
            "d_loss: 0.16254370702386467\n",
            "g_loss: 0.10625819116830826\n",
            "Batch: 622 Epoch: 1\n",
            "d_loss: 0.16254197913033153\n",
            "g_loss: 0.10668214410543442\n",
            "Batch: 623 Epoch: 1\n",
            "d_loss: 0.16254168573967576\n",
            "g_loss: 0.10702775418758392\n",
            "Batch: 624 Epoch: 1\n",
            "d_loss: 0.16254184372012048\n",
            "g_loss: 0.1065821647644043\n",
            "Batch: 625 Epoch: 1\n",
            "d_loss: 0.1625417706093657\n",
            "g_loss: 0.10663876682519913\n",
            "Batch: 626 Epoch: 1\n",
            "d_loss: 0.16254221623102438\n",
            "g_loss: 0.10618780553340912\n",
            "Batch: 627 Epoch: 1\n",
            "d_loss: 0.16254187468554449\n",
            "g_loss: 0.10696790367364883\n",
            "Batch: 628 Epoch: 1\n",
            "d_loss: 0.16254181408142188\n",
            "g_loss: 0.10629618167877197\n",
            "Batch: 629 Epoch: 1\n",
            "d_loss: 0.16254196363224338\n",
            "g_loss: 0.10660912096500397\n",
            "Batch: 630 Epoch: 1\n",
            "d_loss: 0.16254163833350788\n",
            "g_loss: 0.10685865581035614\n",
            "Batch: 631 Epoch: 1\n",
            "d_loss: 0.16254179930267298\n",
            "g_loss: 0.10644300282001495\n",
            "Batch: 632 Epoch: 1\n",
            "d_loss: 0.16254167978222256\n",
            "g_loss: 0.10676159709692001\n",
            "Batch: 633 Epoch: 1\n",
            "d_loss: 0.1625417105867868\n",
            "g_loss: 0.10694624483585358\n",
            "Batch: 634 Epoch: 1\n",
            "d_loss: 0.16254166538560355\n",
            "g_loss: 0.10684411227703094\n",
            "Batch: 635 Epoch: 1\n",
            "d_loss: 0.16254175386544034\n",
            "g_loss: 0.10673131048679352\n",
            "Batch: 636 Epoch: 1\n",
            "d_loss: 0.16254190548280434\n",
            "g_loss: 0.10674820095300674\n",
            "Batch: 637 Epoch: 1\n",
            "d_loss: 0.16254229405886633\n",
            "g_loss: 0.10741982609033585\n",
            "Batch: 638 Epoch: 1\n",
            "d_loss: 0.16254245694376834\n",
            "g_loss: 0.10649590194225311\n",
            "Batch: 639 Epoch: 1\n",
            "d_loss: 0.16254166620493748\n",
            "g_loss: 0.10658399760723114\n",
            "Batch: 640 Epoch: 1\n",
            "d_loss: 0.16254188138236003\n",
            "g_loss: 0.10716947168111801\n",
            "Batch: 641 Epoch: 1\n",
            "d_loss: 0.16254183045633397\n",
            "g_loss: 0.10771890729665756\n",
            "Batch: 642 Epoch: 1\n",
            "d_loss: 0.1625428346790514\n",
            "g_loss: 0.10626496374607086\n",
            "Batch: 643 Epoch: 1\n",
            "d_loss: 0.1625438400709598\n",
            "g_loss: 0.10815558582544327\n",
            "Batch: 644 Epoch: 1\n",
            "d_loss: 0.16254343812828154\n",
            "g_loss: 0.10655802488327026\n",
            "Batch: 645 Epoch: 1\n",
            "d_loss: 0.16254227642322405\n",
            "g_loss: 0.10664413869380951\n",
            "Batch: 646 Epoch: 1\n",
            "d_loss: 0.16254272593840824\n",
            "g_loss: 0.10777266323566437\n",
            "Batch: 647 Epoch: 1\n",
            "d_loss: 0.1625419953116065\n",
            "g_loss: 0.10708353668451309\n",
            "Batch: 648 Epoch: 1\n",
            "d_loss: 0.16254170974278992\n",
            "g_loss: 0.10726507008075714\n",
            "Batch: 649 Epoch: 1\n",
            "d_loss: 0.16254179901928012\n",
            "g_loss: 0.10704714059829712\n",
            "Batch: 650 Epoch: 1\n",
            "d_loss: 0.16254175243835078\n",
            "g_loss: 0.10739295184612274\n",
            "Batch: 651 Epoch: 1\n",
            "d_loss: 0.16254203761184272\n",
            "g_loss: 0.1070839986205101\n",
            "Batch: 652 Epoch: 1\n",
            "d_loss: 0.1625416204818606\n",
            "g_loss: 0.10686230659484863\n",
            "Batch: 653 Epoch: 1\n",
            "d_loss: 0.16254174152809497\n",
            "g_loss: 0.10670094192028046\n",
            "Batch: 654 Epoch: 1\n",
            "d_loss: 0.16254345159488537\n",
            "g_loss: 0.10800138860940933\n",
            "Batch: 655 Epoch: 1\n",
            "d_loss: 0.1625442140277329\n",
            "g_loss: 0.10639125108718872\n",
            "Batch: 656 Epoch: 1\n",
            "d_loss: 0.16254305037870154\n",
            "g_loss: 0.10750611126422882\n",
            "Batch: 657 Epoch: 1\n",
            "d_loss: 0.16254182822729035\n",
            "g_loss: 0.10740558058023453\n",
            "Batch: 658 Epoch: 1\n",
            "d_loss: 0.1625436195411254\n",
            "g_loss: 0.10620246082544327\n",
            "Batch: 659 Epoch: 1\n",
            "d_loss: 0.1625426336181235\n",
            "g_loss: 0.10701502859592438\n",
            "Batch: 660 Epoch: 1\n",
            "d_loss: 0.16254194724756132\n",
            "g_loss: 0.10692594200372696\n",
            "Batch: 661 Epoch: 1\n",
            "d_loss: 0.1625419771689991\n",
            "g_loss: 0.10680315643548965\n",
            "Batch: 662 Epoch: 1\n",
            "d_loss: 0.16254169435264032\n",
            "g_loss: 0.10701124370098114\n",
            "Batch: 663 Epoch: 1\n",
            "d_loss: 0.16254172581450632\n",
            "g_loss: 0.10708743333816528\n",
            "Batch: 664 Epoch: 1\n",
            "d_loss: 0.16254178062154523\n",
            "g_loss: 0.10735227167606354\n",
            "Batch: 665 Epoch: 1\n",
            "d_loss: 0.1625418877884499\n",
            "g_loss: 0.10721335560083389\n",
            "Batch: 666 Epoch: 1\n",
            "d_loss: 0.16254163580382652\n",
            "g_loss: 0.1076429933309555\n",
            "Batch: 667 Epoch: 1\n",
            "d_loss: 0.16254170942413992\n",
            "g_loss: 0.10726241767406464\n",
            "Batch: 668 Epoch: 1\n",
            "d_loss: 0.16254211157007603\n",
            "g_loss: 0.1075199693441391\n",
            "Batch: 669 Epoch: 1\n",
            "d_loss: 0.16254197741384502\n",
            "g_loss: 0.10789112001657486\n",
            "Batch: 670 Epoch: 1\n",
            "d_loss: 0.16254234803219703\n",
            "g_loss: 0.10713505744934082\n",
            "Batch: 671 Epoch: 1\n",
            "d_loss: 0.1625419938664976\n",
            "g_loss: 0.10624823719263077\n",
            "Batch: 672 Epoch: 1\n",
            "d_loss: 0.1625442130254129\n",
            "g_loss: 0.1084991917014122\n",
            "Batch: 673 Epoch: 1\n",
            "d_loss: 0.16254364558528778\n",
            "g_loss: 0.10722210258245468\n",
            "Batch: 674 Epoch: 1\n",
            "d_loss: 0.16254194775803654\n",
            "g_loss: 0.10748845338821411\n",
            "Batch: 675 Epoch: 1\n",
            "d_loss: 0.1625417671629279\n",
            "g_loss: 0.1079733818769455\n",
            "Batch: 676 Epoch: 1\n",
            "d_loss: 0.16254170660683087\n",
            "g_loss: 0.1075347289443016\n",
            "Batch: 677 Epoch: 1\n",
            "d_loss: 0.16254176861031056\n",
            "g_loss: 0.10733537375926971\n",
            "Batch: 678 Epoch: 1\n",
            "d_loss: 0.16254221451166018\n",
            "g_loss: 0.10783958435058594\n",
            "Batch: 679 Epoch: 1\n",
            "d_loss: 0.1625420222004692\n",
            "g_loss: 0.10718357563018799\n",
            "Batch: 680 Epoch: 1\n",
            "d_loss: 0.16254167964847\n",
            "g_loss: 0.10670602321624756\n",
            "Batch: 681 Epoch: 1\n",
            "d_loss: 0.16254219094377476\n",
            "g_loss: 0.10741617530584335\n",
            "Batch: 682 Epoch: 1\n",
            "d_loss: 0.1625416369391317\n",
            "g_loss: 0.10727386176586151\n",
            "Batch: 683 Epoch: 1\n",
            "d_loss: 0.16254194909461006\n",
            "g_loss: 0.10690344870090485\n",
            "Batch: 684 Epoch: 1\n",
            "d_loss: 0.16254163628856588\n",
            "g_loss: 0.10698515176773071\n",
            "Batch: 685 Epoch: 1\n",
            "d_loss: 0.16254206670843985\n",
            "g_loss: 0.10771507024765015\n",
            "Batch: 686 Epoch: 1\n",
            "d_loss: 0.1625418563095451\n",
            "g_loss: 0.10787792503833771\n",
            "Batch: 687 Epoch: 1\n",
            "d_loss: 0.16254226157312957\n",
            "g_loss: 0.10679922252893448\n",
            "Batch: 688 Epoch: 1\n",
            "d_loss: 0.16254166394971747\n",
            "g_loss: 0.1066882386803627\n",
            "Batch: 689 Epoch: 1\n",
            "d_loss: 0.1625432426450928\n",
            "g_loss: 0.10805130004882812\n",
            "Batch: 690 Epoch: 1\n",
            "d_loss: 0.16254348290468812\n",
            "g_loss: 0.1067073792219162\n",
            "Batch: 691 Epoch: 1\n",
            "d_loss: 0.16254266216532187\n",
            "g_loss: 0.10736942291259766\n",
            "Batch: 692 Epoch: 1\n",
            "d_loss: 0.1625417370445632\n",
            "g_loss: 0.1076146587729454\n",
            "Batch: 693 Epoch: 1\n",
            "d_loss: 0.16254202953067676\n",
            "g_loss: 0.1070772185921669\n",
            "Batch: 694 Epoch: 1\n",
            "d_loss: 0.16254209472750603\n",
            "g_loss: 0.10728862136602402\n",
            "Batch: 695 Epoch: 1\n",
            "d_loss: 0.16254197496540712\n",
            "g_loss: 0.10671033710241318\n",
            "Batch: 696 Epoch: 1\n",
            "d_loss: 0.16254280839509505\n",
            "g_loss: 0.10804293304681778\n",
            "Batch: 697 Epoch: 1\n",
            "d_loss: 0.1625431667893693\n",
            "g_loss: 0.10655917227268219\n",
            "Batch: 698 Epoch: 1\n",
            "d_loss: 0.16254229367698514\n",
            "g_loss: 0.10761972516775131\n",
            "Batch: 699 Epoch: 1\n",
            "d_loss: 0.1625417961622162\n",
            "g_loss: 0.10724499076604843\n",
            "Batch: 700 Epoch: 1\n",
            "d_loss: 0.1625417062308756\n",
            "g_loss: 0.10745792090892792\n",
            "Batch: 701 Epoch: 1\n",
            "d_loss: 0.16254195958629936\n",
            "g_loss: 0.10714022815227509\n",
            "Batch: 702 Epoch: 1\n",
            "d_loss: 0.16254179630626453\n",
            "g_loss: 0.10737939178943634\n",
            "Batch: 703 Epoch: 1\n",
            "d_loss: 0.16254182511338655\n",
            "g_loss: 0.10699961334466934\n",
            "Batch: 704 Epoch: 1\n",
            "d_loss: 0.16254161681477797\n",
            "g_loss: 0.10708518326282501\n",
            "Batch: 705 Epoch: 1\n",
            "d_loss: 0.16254182565809572\n",
            "g_loss: 0.10722814500331879\n",
            "Batch: 706 Epoch: 1\n",
            "d_loss: 0.1625416321192361\n",
            "g_loss: 0.10727280378341675\n",
            "Batch: 707 Epoch: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-1c8b0459fc5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0md_loss_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimages_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0md_loss_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minitial_recons_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_loss_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_loss_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1729\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1730\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1731\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1732\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mreset_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1667\u001b[0m     \"\"\"\n\u001b[1;32m   1668\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m       \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m   def train_on_batch(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py\u001b[0m in \u001b[0;36mreset_states\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0mwhen\u001b[0m \u001b[0ma\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mevaluated\u001b[0m \u001b[0mduring\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \"\"\"\n\u001b[0;32m--> 253\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   3704\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly_outside_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3705\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtuples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3706\u001b[0;31m       \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3707\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3708\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m    891\u001b[0m             (tensor_name, self._shape, value_tensor.shape))\n\u001b[1;32m    892\u001b[0m       assign_op = gen_resource_variable_ops.assign_variable_op(\n\u001b[0;32m--> 893\u001b[0;31m           self.handle, value_tensor, name=name)\n\u001b[0m\u001b[1;32m    894\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mread_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_resource_variable_ops.py\u001b[0m in \u001b[0;36massign_variable_op\u001b[0;34m(resource, value, name)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m--> 142\u001b[0;31m         _ctx, \"AssignVariableOp\", name, resource, value)\n\u001b[0m\u001b[1;32m    143\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFYGumuV95ER"
      },
      "source": [
        "    \n",
        "    ## Build and compile encoder\n",
        "    encoder = build_encoder()\n",
        "    encoder.compile(loss = euclidean_distance_loss,\n",
        "                    optimizer = 'adam')\n",
        "     \n",
        "    \n",
        "    ## Load the generator network's weights\n",
        "    try:\n",
        "      generator.load_weights(\"/content/drive/MyDrive/Đại học/Năm 3 - HK2/Học Sâu/Face_Aging_Process/Model/generator.h5\")\n",
        "    except Exception as e:\n",
        "      print(\"Error: \", e)\n",
        "      \n",
        "    \n",
        "    z_i = np.random.normal(0, 1, size = (5000, z_shape))\n",
        "    \n",
        "    y = np.random.randint(low = 0, high = 6, size = (5000, ),\n",
        "                          dtype = np.int64)\n",
        "    num_classes = len(set(y))\n",
        "    y = np.reshape(np.array(y), [len(y), 1])\n",
        "    y = to_categorical(y, num_classes = num_classes)\n",
        "    \n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "      print(\"Epoch: \", epoch)\n",
        "      \n",
        "      encoder_losses = []\n",
        "      \n",
        "      number_of_batches = int(z_i.shape[0] / batch_size)\n",
        "      print(\"Number of batches: \", number_of_batches)\n",
        "      \n",
        "      for index in range(number_of_batches):\n",
        "        print(\"Batch: \", index + 1)\n",
        "        \n",
        "        z_batch = z_i[index * batch_size: (index + 1) * batch_size]\n",
        "        y_batch = y[index * batch_size: (index + 1) * batch_size]\n",
        "        \n",
        "        generated_images = generator.predict_on_batch([z_batch, y_batch])\n",
        "        \n",
        "        \n",
        "        ## Train the encoder model\n",
        "        encoder_loss = encoder.train_on_batch(generated_images, z_batch)\n",
        "        print(\"Encoder loss: \", encoder_loss)\n",
        "        \n",
        "        encoder_losses.append(encoder_loss)\n",
        "        \n",
        "        \n",
        "      ## Write the encoder loss to Tensorboard\n",
        "      # write_log(tensorboard, \"encoder_loss\", np.mean(encoder_losses), epoch)\n",
        "      \n",
        "    ## Save the encoder model\n",
        "    encoder.save_weights(\"/content/drive/MyDrive/Đại học/Năm 3 - HK2/Học Sâu/Face_Aging_Process/Model/encoder.h5\")\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "339uoAUWprcH"
      },
      "source": [
        "# if __name__ == '__main__':\n",
        "  \n",
        "#   ## Define hyperparameters\n",
        "# #   data_dir = \"data\"\n",
        "# #   wiki_dir = os.path.join(data_dir, \"wiki_crop\")\n",
        "#   wiki_dir = \"wiki_crop\"\n",
        "#   epochs = 500\n",
        "#   batch_size = 2\n",
        "#   image_shape = (64, 64, 3)\n",
        "#   z_shape = 100\n",
        "#   TRAIN_GAN = True\n",
        "#   TRAIN_ENCODER = False\n",
        "#   TRAIN_GAN_WITH_FR = False\n",
        "#   fr_image_shape = (192, 192, 3)\n",
        "  \n",
        "  \n",
        "#   ## Define optimizers\n",
        "#   dis_optimizer = Adam(lr = 0.0002, beta_1 = 0.5, beta_2 = 0.999, epsilon = 10e-8)\n",
        "#   gen_optimizer = Adam(lr = 0.0002, beta_1 = 0.5, beta_2 = 0.999, epsilon = 10e-8)\n",
        "#   adversarial_optimizer = Adam(lr = 0.0002, beta_1 = 0.5, beta_2 = 0.999, epsilon = 10e-8)\n",
        "  \n",
        "  \n",
        "#   \"\"\"\n",
        "#   Build and compile networks\n",
        "#   \"\"\"\n",
        "  \n",
        "#   ## Build and compile the discriminator network\n",
        "#   discriminator = build_discriminator()\n",
        "#   discriminator.compile(loss = ['binary_crossentropy'],\n",
        "#                         optimizer = dis_optimizer)\n",
        "  \n",
        "  \n",
        "#   ## Build and compile the generator network\n",
        "#   generator = build_generator()\n",
        "#   generator.compile(loss = ['binary_crossentropy'],\n",
        "#                     optimizer = gen_optimizer)\n",
        "  \n",
        "  \n",
        "#   ## Build and compile the adversarial model\n",
        "#   discriminator.trainable = False\n",
        "#   input_z_noise = Input(shape = (100, ))\n",
        "#   input_label = Input(shape = (6, ))\n",
        "#   recons_images = generator([input_z_noise, input_label])\n",
        "#   valid = discriminator([recons_images, input_label])\n",
        "#   adversarial_model = Model(inputs = [input_z_noise, input_label],\n",
        "#                             outputs = [valid])\n",
        "#   adversarial_model.compile(loss = ['binary_crossentropy'],\n",
        "#                             optimizer = gen_optimizer)\n",
        "  \n",
        "#   tensorboard = TensorBoard(log_dir = \"logs/{}\".format(time.time()))\n",
        "#   tensorboard.set_model(generator)\n",
        "#   tensorboard.set_model(discriminator)\n",
        "  \n",
        "  \n",
        "#   \"\"\"\n",
        "#   Load the dataset\n",
        "#   \"\"\"\n",
        "  \n",
        "#   images, age_list = load_data(wiki_dir = wiki_dir, dataset = \"wiki\")\n",
        "#   age_cat = age_to_category(age_list)\n",
        "#   final_age_cat = np.reshape(np.array(age_cat), [len(age_cat), 1])\n",
        "#   classes = len(set(age_cat))\n",
        "#   y = to_categorical(final_age_cat, num_classes = classes)\n",
        "  \n",
        "  \n",
        "# #   loaded_images = load_images(wiki_dir, images, (image_shape[0], image_shape[1]))\n",
        "# #   loaded_images = np.load(\"/content/drive/MyDrive/loaded_images.npy\")\n",
        "  \n",
        "  \n",
        "#   ## Implement label smoothing\n",
        "#   real_labels = np.ones((batch_size, 1), dtype = np.float32) * 0.9\n",
        "#   fake_labels = np.zeros((batch_size, 1), dtype = np.float32) * 0.1\n",
        "  \n",
        "  \n",
        "#   \"\"\"\n",
        "#   Train the generator and the discriminator network\n",
        "#   \"\"\"\n",
        "  \n",
        "#   if TRAIN_GAN:\n",
        "#     for epoch in range(epochs):\n",
        "#       print(\"Epoch: {}\".format(epoch))\n",
        "      \n",
        "#       gen_losses = []\n",
        "#       dis_losses = []\n",
        "      \n",
        "#       number_of_batches = int(len(loaded_images) / batch_size)\n",
        "#       print(\"Number of batches: \", number_of_batches)\n",
        "#       for index in range(number_of_batches):\n",
        "#         print(\"Batch: {}\".format(index + 1))\n",
        "        \n",
        "#         images_batch = loaded_images[index * batch_size:(index + 1) * batch_size]\n",
        "#         images_batch = images_batch / 127.5 - 1.0\n",
        "#         images_batch = images_batch.astype(np.float32)\n",
        "        \n",
        "#         y_batch = y[index * batch_size: (index + 1) * batch_size]\n",
        "#         z_noise = np.random.normal(0, 1, size = (batch_size, z_shape))\n",
        "        \n",
        "        \n",
        "#         \"\"\"\n",
        "#         Train the discriminator network\n",
        "#         \"\"\"\n",
        "        \n",
        "#         ## Generate fake images\n",
        "#         initial_recons_images = generator.predict_on_batch([z_noise, y_batch])\n",
        "        \n",
        "#         d_loss_real = discriminator.train_on_batch([images_batch, y_batch], real_labels)\n",
        "#         d_loss_fake = discriminator.train_on_batch([initial_recons_images, y_batch], fake_labels)\n",
        "        \n",
        "#         d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "#         print(\"d_loss: {}\".format(d_loss))\n",
        "        \n",
        "        \n",
        "#         \"\"\"\n",
        "#         Train the generator network\n",
        "#         \"\"\"\n",
        "        \n",
        "#         z_noise2 = np.random.normal(0, 1, size = (batch_size, z_shape))\n",
        "#         random_labels = np.random.randint(0, 6, batch_size).reshape(-1, 1)\n",
        "#         random_labels = to_categorical(random_labels, 6)\n",
        "        \n",
        "#         g_loss = adversarial_model.train_on_batch([z_noise2, random_labels], np.array([1] * batch_size))\n",
        "        \n",
        "#         print(\"g_loss: {}\".format(g_loss))\n",
        "        \n",
        "        \n",
        "#         gen_losses.append(g_loss)\n",
        "#         dis_losses.append(d_loss)\n",
        "        \n",
        "      \n",
        "#       ## Write losses to Tensorboard\n",
        "#       write_log(tensorboard, 'g_loss', np.mean(gen_losses), epoch)\n",
        "#       write_log(tensorboard, 'd_loss', np.mean(dis_losses), epoch)\n",
        "      \n",
        "      \n",
        "#       \"\"\"\n",
        "#       Generate images after every 10th epoch\n",
        "#       \"\"\"\n",
        "      \n",
        "#       if epoch % 10 == 0:\n",
        "#         images_batch = loaded_images[0:batch_size]\n",
        "#         images_batch = images_batch / 127.5 - 1.0\n",
        "#         images_batch = images_batch.astype(np.float32)\n",
        "        \n",
        "#         y_batch = y[0:batch_size]\n",
        "#         z_noise = np.random.normal(0, 1, size = (batch_size, z_shape))\n",
        "        \n",
        "#         gen_images = generator.predict_on_batch([z_noise, y_batch])\n",
        "        \n",
        "#         for i, img in enumerate(gen_images[:5]):\n",
        "#           save_rgb_img(img, path = \"results/img_{}_{}.png\".format(epoch, i))\n",
        "          \n",
        "        \n",
        "#     ## Save networks\n",
        "#     try:\n",
        "#       generator.save_weights(\"generator.h5\")\n",
        "#       discriminator.save_weights(\"discriminator.h5\")\n",
        "#     except Exception as e:\n",
        "#       print(\"Error: \", e)\n",
        "      \n",
        "  \n",
        "#   \"\"\"\n",
        "#   Train encoder\n",
        "#   \"\"\"\n",
        "  \n",
        "#   if TRAIN_ENCODER:\n",
        "    \n",
        "#     ## Build and compile encoder\n",
        "#     encoder = build_encoder()\n",
        "#     encoder.compile(loss = euclidean_distance_loss,\n",
        "#                     optimizer = 'adam')\n",
        "    \n",
        "    \n",
        "#     ## Load the generator network's weights\n",
        "#     try:\n",
        "#       generator.load_weights(\"generator.h5\")\n",
        "#     except Exception as e:\n",
        "#       print(\"Error: \", e)\n",
        "      \n",
        "    \n",
        "#     z_i = np.random.normal(0, 1, size = (5000, z_shape))\n",
        "    \n",
        "#     y = np.random.randint(low = 0, high = 6, size = (5000, ),\n",
        "#                           dtype = np.int64)\n",
        "#     num_classes = len(set(y))\n",
        "#     y = np.reshape(np.array(y), [len(y), 1])\n",
        "#     y = to_categorical(y, num_classes = num_classes)\n",
        "    \n",
        "    \n",
        "#     for epoch in range(epochs):\n",
        "#       print(\"Epoch: \", epoch)\n",
        "      \n",
        "#       encoder_losses = []\n",
        "      \n",
        "#       number_of_batches = int(z_i.shape[0] / batch_size)\n",
        "#       print(\"Number of batches: \", number_of_batches)\n",
        "      \n",
        "#       for index in range(number_of_batches):\n",
        "#         print(\"Batch: \", index + 1)\n",
        "        \n",
        "#         z_batch = z_i[index * batch_size: (index + 1) * batch_size]\n",
        "#         y_batch = y[index * batch_size: (index + 1) * batch_size]\n",
        "        \n",
        "#         generated_images = generator.predict_on_batch([z_batch, y_batch])\n",
        "        \n",
        "        \n",
        "#         ## Train the encoder model\n",
        "#         encoder_loss = encoder.train_on_batch(generated_images, z_batch)\n",
        "#         print(\"Encoder loss: \", encoder_loss)\n",
        "        \n",
        "#         encoder_losses.append(encoder_loss)\n",
        "        \n",
        "        \n",
        "#       ## Write the encoder loss to Tensorboard\n",
        "#       write_log(tensorboard, \"encoder_loss\", np.mean(encoder_losses), epoch)\n",
        "      \n",
        "#     ## Save the encoder model\n",
        "#     encoder.save_weights(\"encoder.h5\")\n",
        "    \n",
        "    \n",
        "#   \"\"\"\n",
        "#   Optimize the encoder and the generator network\n",
        "#   \"\"\"\n",
        "  \n",
        "#   if TRAIN_GAN_WITH_FR:\n",
        "    \n",
        "#     ## Load the encoder network\n",
        "#     encoder = build_encoder()\n",
        "#     encoder.load_weights(\"encoder.h5\")\n",
        "    \n",
        "    \n",
        "#     ## Load the generator network\n",
        "#     generator.load_weights(\"generator.h5\")\n",
        "    \n",
        "#     image_resizer = build_image_resizer()\n",
        "#     image_resizer.compile(loss = ['binary_crossentropy'],\n",
        "#                           optimzer = 'adam')\n",
        "    \n",
        "    \n",
        "#     ## Face recognition model\n",
        "#     fr_model = build_fr_model(input_shape = fr_image_shape)\n",
        "#     fr_model.compile(loss = ['binary_crossentropy'],\n",
        "#                      optimizer = 'adam')\n",
        "    \n",
        "#     ## Make the face recognition model as non-trainable\n",
        "#     fr_model.trainable = False\n",
        "    \n",
        "    \n",
        "#     ## Input layers\n",
        "#     input_image = Input(shape = (64, 64, 3))\n",
        "#     input_label = Input(shape = (6, ))\n",
        "    \n",
        "    \n",
        "#     ## Use the encoder and the generator network\n",
        "#     latent0 = encoder(input_image)\n",
        "#     gen_images = generator([latent0, input_label])\n",
        "    \n",
        "    \n",
        "#     ## Resize images to the desired shape\n",
        "#     resized_images = Lambda(lambda x: K.resize_images(gen_images, height_factor = 3,\n",
        "#                                                       width_factor = 3,\n",
        "#                                                       data_format = 'channels_last'))(gen_images) \n",
        "#     embeddings = fr_model(resized_images)\n",
        "    \n",
        "    \n",
        "#     ## Create a Keras model and specify the inputs and outputs for the network\n",
        "#     fr_adversarial_model = Model(inputs = [input_image, input_label],\n",
        "#                                  outputs = [embeddings])\n",
        "    \n",
        "    \n",
        "#     ## Compile the model\n",
        "#     fr_adversarial_model.compile(loss = euclidean_distance_loss,\n",
        "#                                  optimizer = adversarial_optimizer)\n",
        "    \n",
        "#     for epoch in range(epochs):\n",
        "#       print(\"Epoch: \", epoch)\n",
        "      \n",
        "#       reconstruction_losses = []\n",
        "      \n",
        "#       number_of_batches = int(len(loaded_images) / batch_size)\n",
        "#       print(\"Number of batches: \", number_of_batches)\n",
        "#       for index in range(number_of_batches):\n",
        "#         print(\"Batch: \", index + 1)\n",
        "        \n",
        "#         images_batch = loaded_images[index * batch_size: (index + 1) * batch_size]\n",
        "#         images_batch = images_batch / 127.5 - 1.0\n",
        "#         images_batch = images_batch.astype(np.float32)\n",
        "        \n",
        "#         y_batch = y[index * batch_size: (index + 1) * batch_size]\n",
        "        \n",
        "#         images_batch_resized = image_resizer.predict_on_batch(images_batch)\n",
        "        \n",
        "#         real_embeddings = fr_model.predict_on_batch(images_batch_resized)\n",
        "        \n",
        "#         reconstruction_loss = fr_adversarial_model.train_on_batch([images_batch, y_batch], real_embeddings)\n",
        "        \n",
        "#         print(\"Reconstruction loss: \", reconstruction_loss)\n",
        "        \n",
        "#         reconstruction_losses.append(reconstruction_loss)\n",
        "        \n",
        "        \n",
        "#       ## Write the reconstruction loss to Tensorboard\n",
        "#       write_log(tensorboard, \"reconstruction_loss\", np.mean(reconstruction_losses), epoch)\n",
        "      \n",
        "      \n",
        "#       \"\"\"\n",
        "#       Generate images\n",
        "#       \"\"\"\n",
        "      \n",
        "#       if epoch % 10 == 0:\n",
        "#         images_batch = loaded_images[0:batch_size]\n",
        "#         images_batch = images_batch / 127.5 - 1.0\n",
        "#         images_batch = images_batch.astype(np.float32)\n",
        "        \n",
        "#         y_batch = y[0:batch_size]\n",
        "#         z_noise = np.random.normal(0, 1, size = (batch_size, z_shape))\n",
        "        \n",
        "#         gen_images = generator.predict_on_batch([z_noise, y_batch])\n",
        "        \n",
        "#         for i, img in enumerate(gen_images[:5]):\n",
        "#           save_rgb_image(img, path = \"results/img_opt_{}_{}.png\".format(epoch, i))\n",
        "        \n",
        "        \n",
        "#     ## Save improved weights for both of the networks\n",
        "#     generator.save_weights(\"generator_optimized.h5\")\n",
        "#     encoder.save_weights(\"encoder_optimized.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gb71n33kv_FI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}